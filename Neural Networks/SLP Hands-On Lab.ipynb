{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMQmumY+Ijum11KqiWrg9Nx",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Neural%20Networks/SLP%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "source": "# **Hands-On Lab: Single-Layer Perceptrons (SLPs)**\n\n## **Learning Objectives**\n\nBy the end of this lab, you will be able to:\n- Understand what a Single-Layer Perceptron is and its limitations\n- Build SLPs for **binary classification** (Breast Cancer) and **multi-class classification** (Fashion MNIST)\n- Apply proper data preprocessing (scaling, flattening)\n- Evaluate models using accuracy, confusion matrices, and classification reports\n- Visualize learned weights to interpret what the model has learned\n- Save and load trained models for reuse\n\n## **Table of Contents**\n\n1. [Introduction & Prerequisites](#1-introduction--prerequisites)\n2. [What is a Single-Layer Perceptron?](#2-what-is-a-single-layer-perceptron)\n3. [Sigmoid vs. Softmax Activations](#3-sigmoid-vs-softmax-activations)\n4. [Data Exploration Best Practices](#4-data-exploration-best-practices)\n5. [Binary Classification: Breast Cancer Dataset](#5-binary-classification-breast-cancer-dataset)\n6. [Hyperparameter Tuning](#6-hyperparameter-tuning)\n7. [Multi-Class Classification: Fashion MNIST](#7-multi-class-classification-fashion-mnist)\n8. [Saving & Loading Models](#8-saving--loading-models)\n9. [Wrap-Up & Next Steps](#9-wrap-up--next-steps)",
   "metadata": {
    "id": "JFaZiYirgTHd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction & Prerequisites\n",
    "\n",
    "**Goal**:  \n",
    "Build a **Single-Layer Perceptron (SLP)** for **binary classification** (Breast Cancer) and **multi-class classification** (Fashion MNIST). Along the way, we will:\n",
    "- Explore data for better intuition.\n",
    "- Implement **hyperparameter tuning** (learning rates, epochs).\n",
    "- Visualize learned **weights** (for image data).\n",
    "- Perform a more **detailed error analysis**.\n",
    "- Discuss **handling class imbalance** conceptually.\n",
    "- Demonstrate **saving & loading** models for an end-to-end ML workflow.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Basic Python, NumPy, and Matplotlib.\n",
    "- Familiarity with classification tasks (binary and multi-class).\n",
    "- Libraries: `tensorflow`, `scikit-learn`, `matplotlib`, `numpy`.\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install tensorflow scikit-learn matplotlib numpy\n",
    "```"
   ],
   "metadata": {
    "id": "PcpOKc1-gpVG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. What is a Single-Layer Perceptron?\n",
    "\n",
    "A **Single-Layer Perceptron (SLP)** is one of the most fundamental neural network models. It consists of:\n",
    "- **Input Layer**: Receives features $\\{x_1, x_2, \\ldots, x_n\\}$.  \n",
    "- **Output Layer**: Produces predictions (probabilities or logits).  \n",
    "- **No Hidden Layers**: Exactly one set of weights from inputs to outputs.\n",
    "\n",
    "**Typical SLP Setup**:\n",
    "1. **Binary classification**:\n",
    "   - **1 output neuron** (sigmoid activation).  \n",
    "   - **Binary crossentropy** loss.\n",
    "2. **Multi-class classification** (e.g., 10 classes):\n",
    "   - **$k$ output neurons** (softmax activation).  \n",
    "   - **(Sparse) categorical crossentropy** loss.\n",
    "\n",
    "**Number of parameters** = $(\\text{input_dim} \\times \\text{output_dim}) + \\text{output_dim}$.  \n",
    "- If input_dim = 784 (flattened 28×28) and output_dim = 10 => $(784 \\times 10) + 10 = 7850$ parameters."
   ],
   "metadata": {
    "id": "J7yezp1UgzH7"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Sigmoid vs. Softmax Activations\n\nUnderstanding when to use each activation function is crucial:\n\n| Activation | Formula | Output Range | Use Case |\n|------------|---------|--------------|----------|\n| **Sigmoid** | $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ | $(0, 1)$ | Binary classification (1 output neuron) |\n| **Softmax** | $\\text{softmax}(z_j) = \\frac{e^{z_j}}{\\sum_{k} e^{z_k}}$ | $(0, 1)$, sums to 1 | Multi-class classification (k output neurons) |\n\n### Key Differences\n\n1. **Sigmoid**: Outputs a single probability for \"class 1\". Use with **binary crossentropy** loss.\n\n2. **Softmax**: Outputs probabilities for all classes that sum to 1. Use with **(sparse) categorical crossentropy** loss.",
   "metadata": {
    "id": "oLDjdK3chPkV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Data Exploration & Insights\n",
    "\n",
    "Before diving into modeling, a brief **data exploration** helps us understand:\n",
    "- Feature distributions.\n",
    "- Potential class imbalances.\n",
    "- Correlations or outliers.\n",
    "\n",
    "In the **Breast Cancer** dataset, we might:\n",
    "- Examine basic statistics of each feature (mean, std).\n",
    "- Count how many “malignant” vs. “benign” samples to check if it’s balanced.\n",
    "\n",
    "In **Fashion MNIST**, we might:\n",
    "- Display a few sample images to see what the data looks like.\n",
    "\n",
    "**Why do this?**  \n",
    "1. **Better Intuition**: We know whether the dataset is balanced or skewed.  \n",
    "2. **Feature Engineering**: EDA can suggest if scaling or transformations are needed.  \n",
    "3. **Detecting Anomalies**: Sometimes there are outliers or missing values.\n",
    "\n",
    "Below, we’ll incorporate minimal EDA to illustrate these points."
   ],
   "metadata": {
    "id": "Q1AN2LxRh0hk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Binary Classification: Breast Cancer (`sklearn.datasets`)\n",
    "\n",
    "### 5.1 Load & Quick Exploration"
   ],
   "metadata": {
    "id": "NgXPTCtYiVbv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data_bc = load_breast_cancer()\n",
    "\n",
    "X_bc = data_bc.data   # (569, 30) typically\n",
    "y_bc = data_bc.target # (569,) => 0 or 1\n",
    "\n",
    "print(\"Features shape:\", X_bc.shape)\n",
    "print(\"Labels shape:\", y_bc.shape)\n",
    "print(\"Feature names:\", data_bc.feature_names)\n",
    "print(\"Class distribution:\\n\",\n",
    "      {name: count for name, count in zip(data_bc.target_names, np.bincount(y_bc))})"
   ],
   "metadata": {
    "id": "JXONgE9vicKG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**What the above code does**:\n",
    "- Prints shapes, checks how many features (30).\n",
    "- Prints how many malignant vs. benign cases."
   ],
   "metadata": {
    "id": "zTEzVA2XigFC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Handling Class Imbalance (Conceptual)\n",
    "If we find significant imbalance (say 90% benign, 10% malignant), we might:\n",
    "- Use **metrics** like `precision`, `recall`, `F1-score` instead of just accuracy.  \n",
    "- Adjust **class_weights** in `model.fit()`.  \n",
    "- Perform **oversampling** or **undersampling**.  \n",
    "\n",
    "Breast Cancer is not extremely imbalanced, but it’s still important to check."
   ],
   "metadata": {
    "id": "R6qG9thYimwv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Split, Scale, and Build SLP"
   ],
   "metadata": {
    "id": "gw6qVsskgxAa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(\n",
    "    X_bc, y_bc,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler_bc = StandardScaler()\n",
    "X_train_bc_scaled = scaler_bc.fit_transform(X_train_bc)\n",
    "X_test_bc_scaled  = scaler_bc.transform(X_test_bc)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_bc = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_bc.shape[1],))\n",
    "])\n",
    "model_bc.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bc.summary()"
   ],
   "metadata": {
    "id": "Udlt8EeBiydz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 Train & Evaluate"
   ],
   "metadata": {
    "id": "w7bpmVguixOP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history_bc = model_bc.fit(\n",
    "    X_train_bc_scaled, y_train_bc,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_bc, test_acc_bc = model_bc.evaluate(X_test_bc_scaled, y_test_bc)\n",
    "print(f\"BC Test Loss: {test_loss_bc:.4f}\")\n",
    "print(f\"BC Test Accuracy: {test_acc_bc:.4f}\")"
   ],
   "metadata": {
    "id": "eTLEtR1NiwlK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Learning Curves"
   ],
   "metadata": {
    "id": "6cfLAyq4i8YI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_bc.history['loss'], label='Train Loss')\n",
    "plt.plot(history_bc.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"BC - Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_bc.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_bc.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"BC - Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "mP6Goe2Ji-XZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix & Classification Report"
   ],
   "metadata": {
    "id": "ElBHbJ3SjDKb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_bc_probs = model_bc.predict(X_test_bc_scaled)\n",
    "y_pred_bc = (y_pred_bc_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "cm_bc = confusion_matrix(y_test_bc, y_pred_bc)\n",
    "print(\"Breast Cancer Confusion Matrix:\\n\", cm_bc)\n",
    "\n",
    "print(\"Breast Cancer Classification Report:\\n\",\n",
    "      classification_report(y_test_bc, y_pred_bc))"
   ],
   "metadata": {
    "id": "WlkIeId4jFlz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.4 Handling Class Imbalance (Conceptual)",
   "metadata": {
    "id": "sxjdjolYjIsN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If, for instance, we discovered a heavy imbalance in classes,\n",
    "# we could try:\n",
    "\n",
    "# model_bc.fit(\n",
    "#    X_train_bc_scaled, y_train_bc,\n",
    "#    class_weight={0: 2.0, 1: 1.0},  # Example weighting\n",
    "#    ...\n",
    "# )"
   ],
   "metadata": {
    "id": "_RZGYITwjNyI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Why?**  \n",
    "> Giving **higher weight** to the minority class can help the network pay more attention to it, improving metrics like recall for that class.\n",
    "\n",
    "Since the Breast Cancer dataset is not severely imbalanced, we might not need this, but it’s **important** students understand how to handle imbalance if it arises."
   ],
   "metadata": {
    "id": "LD0erXuAjRGI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Hyperparameter Tuning (Learning Rates, Epochs)\n",
    "\n",
    "**Hyperparameters** such as:\n",
    "- **Learning rate** (`optimizer` parameters, e.g., `Adam(lr=0.001)`).\n",
    "- **Number of epochs**.\n",
    "- **Batch size**.\n",
    "\n",
    "significantly influence model performance."
   ],
   "metadata": {
    "id": "I1_I9u4NjVqm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Example: Adjusting Learning Rate & Epochs"
   ],
   "metadata": {
    "id": "YZxFPOkpjZEQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Let's try a smaller learning rate and more epochs\n",
    "model_bc_tuned = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_bc.shape[1],))\n",
    "])\n",
    "# e.g. learning_rate=0.0005 instead of the default 0.001\n",
    "model_bc_tuned.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_bc_tuned = model_bc_tuned.fit(\n",
    "    X_train_bc_scaled, y_train_bc,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,  # increased\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_tuned, test_acc_tuned = model_bc_tuned.evaluate(X_test_bc_scaled, y_test_bc)\n",
    "print(f\"Tuned BC Loss: {test_loss_tuned:.4f}\")\n",
    "print(f\"Tuned BC Accuracy: {test_acc_tuned:.4f}\")"
   ],
   "metadata": {
    "id": "lsXHALKkjTaL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why try smaller LR & more epochs?**  \n",
    "- A smaller learning rate helps the model converge more *gradually*, potentially avoiding overshoot.  \n",
    "- More epochs allow the model to refine its weights further.\n",
    "\n",
    "If the dataset is small and you see overfitting, you may not need too many epochs. Tuning these hyperparameters is **iterative** and often dataset-specific."
   ],
   "metadata": {
    "id": "-A22JGEUjhJM"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Multi-Class Classification: Fashion MNIST\n\n**Objective**: Classify 28×28 grayscale images into 10 clothing categories.\n\n### The 10 Classes\n\n| Label | Class Name |\n|-------|------------|\n| 0 | T-shirt/top |\n| 1 | Trouser |\n| 2 | Pullover |\n| 3 | Dress |\n| 4 | Coat |\n| 5 | Sandal |\n| 6 | Shirt |\n| 7 | Sneaker |\n| 8 | Bag |\n| 9 | Ankle boot |\n\nA Single-Layer Perceptron will serve as our baseline model for this task.",
   "metadata": {
    "id": "YYQJPWOrjnmf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Load, Inspect & Explore"
   ],
   "metadata": {
    "id": "ivlBoN-WjrI9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_fm, y_train_fm), (X_test_fm, y_test_fm) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"FM Train shape:\", X_train_fm.shape)   # (60000, 28, 28)\n",
    "print(\"FM Train labels:\", y_train_fm.shape)  # (60000,)\n",
    "print(\"Unique classes:\", np.unique(y_train_fm))"
   ],
   "metadata": {
    "id": "y9n2E1N7jj5s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Exploration**:\n",
    "- Optional: Display some sample images."
   ],
   "metadata": {
    "id": "pzZtiVN4j0jm"
   }
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\n# Class names for Fashion MNIST\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n# Display the first 5 images with class names\nplt.figure(figsize=(12, 3))\nfor i in range(5):\n    plt.subplot(1, 5, i + 1)\n    plt.imshow(X_train_fm[i], cmap='gray')\n    plt.title(class_names[y_train_fm[i]])\n    plt.axis('off')\nplt.suptitle('Sample Images from Fashion MNIST', fontsize=12)\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "id": "bPUYpViSj2_w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Preprocess & Build SLP\n",
    "\n",
    "1. **Rescale** from \\([0..255]\\) to \\([0..1]\\).  \n",
    "2. **Flatten** images to 784-dim vectors.  \n",
    "3. **Output layer** = 10 neurons (softmax).\n"
   ],
   "metadata": {
    "id": "G_AXklxxj58f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_fm = X_train_fm / 255.0\n",
    "X_test_fm  = X_test_fm / 255.0\n",
    "\n",
    "X_train_fm_flat = X_train_fm.reshape(-1, 28*28)\n",
    "X_test_fm_flat  = X_test_fm.reshape(-1, 28*28)\n",
    "\n",
    "model_fm = keras.Sequential([\n",
    "    layers.Dense(10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "model_fm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_fm.summary()"
   ],
   "metadata": {
    "id": "6Y66qKeZj8Jk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Train & Evaluate\n"
   ],
   "metadata": {
    "id": "LsxXWZNLkArN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history_fm = model_fm.fit(\n",
    "    X_train_fm_flat, y_train_fm,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_fm, test_acc_fm = model_fm.evaluate(X_test_fm_flat, y_test_fm)\n",
    "print(f\"Fashion MNIST - Test Loss: {test_loss_fm:.4f}\")\n",
    "print(f\"Fashion MNIST - Test Accuracy: {test_acc_fm:.4f}\")"
   ],
   "metadata": {
    "id": "zFzmocjUkCtW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Curves"
   ],
   "metadata": {
    "id": "0YAMt03bkGZi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_fm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_fm.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"FM - Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_fm.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_fm.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"FM - Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "AmHH7qJikIIb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix & Classification Report"
   ],
   "metadata": {
    "id": "4U53qRgckLZJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_fm_probs = model_fm.predict(X_test_fm_flat)\n",
    "y_pred_fm = np.argmax(y_pred_fm_probs, axis=1)\n",
    "\n",
    "cm_fm = confusion_matrix(y_test_fm, y_pred_fm)\n",
    "print(\"Fashion MNIST Confusion Matrix:\\n\", cm_fm)\n",
    "print(\"Fashion MNIST Classification Report:\\n\",\n",
    "      classification_report(y_test_fm, y_pred_fm))"
   ],
   "metadata": {
    "id": "D6PK6KZDkNp8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 7.4 Visualizing Weights in the SLP\n\nA unique advantage of SLPs is that we can **visualize what they've learned**!\n\nEach of the 10 output neurons has a weight vector of length 784. By reshaping these weights into 28×28 grids, we can see what \"pattern\" the model associates with each class.\n\n**Why is this useful?**\n- Provides interpretability - we can see what features the model focuses on\n- Helps debug if the model is learning sensible patterns",
   "metadata": {
    "id": "2ItPEDGrkRFb"
   }
  },
  {
   "cell_type": "code",
   "source": "weights_fm = model_fm.get_weights()[0]  # shape: (784, 10)\nbiases_fm = model_fm.get_weights()[1]   # shape: (10,)\n\nplt.figure(figsize=(14, 6))\nfor i in range(10):\n    # Extract the weight vector for class i\n    w_i = weights_fm[:, i]\n    # Reshape to 28x28\n    w_i_2d = w_i.reshape(28, 28)\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(w_i_2d, cmap='coolwarm')\n    plt.title(f\"{i}: {class_names[i]}\")\n    plt.colorbar(shrink=0.6)\n    plt.axis('off')\nplt.suptitle('Learned Weights for Each Class', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "id": "RtxLRRrFkTx6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- It’s fascinating to see if the model highlights certain regions of the image for a given class, even though it’s just a simple linear map."
   ],
   "metadata": {
    "id": "f21MWW3gkXdd"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### 7.5 Error Analysis: Understanding Misclassifications\n\nLet's examine which samples the model gets wrong. This helps us understand:\n- Which classes are commonly confused\n- Whether the model's mistakes make sense (e.g., confusing \"Shirt\" with \"T-shirt\")",
   "metadata": {
    "id": "sqiPLwgSkao0"
   }
  },
  {
   "cell_type": "code",
   "source": "incorrect_idx = np.where(y_pred_fm != y_test_fm)[0]\nprint(f\"Number of misclassified samples: {len(incorrect_idx)} out of {len(y_test_fm)}\")\nprint(f\"Error rate: {len(incorrect_idx) / len(y_test_fm) * 100:.1f}%\")\n\n# Show some misclassified images with class names\nplt.figure(figsize=(12, 4))\nfor i, idx in enumerate(incorrect_idx[:5]):\n    plt.subplot(1, 5, i + 1)\n    plt.imshow(X_test_fm[idx], cmap='gray')\n    true_label = class_names[y_test_fm[idx]]\n    pred_label = class_names[y_pred_fm[idx]]\n    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", fontsize=9)\n    plt.axis('off')\nplt.suptitle('Sample Misclassified Images', fontsize=12)\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "id": "FHh7J1_ikdCN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- Helps us understand which classes are confusing. For instance, the model might confuse “shirt” vs. “t-shirt” or “pullover” if they visually appear similar."
   ],
   "metadata": {
    "id": "mnnvalXYkf9o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Saving & Loading Models (End-to-End Workflow)\n",
    "\n",
    "After training, it’s crucial to **save** the model so you don’t have to retrain every time, or so you can **deploy** or **share** it."
   ],
   "metadata": {
    "id": "GQAh9CUikit4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the Fashion MNIST model\n",
    "model_fm.save(\"slp_fashion_mnist.h5\")\n",
    "\n",
    "# Later or in another script, load it:\n",
    "loaded_model_fm = tf.keras.models.load_model(\"slp_fashion_mnist.h5\")"
   ],
   "metadata": {
    "id": "_kROjmhokl6Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can then evaluate `loaded_model_fm` on test data again to confirm it’s the same:"
   ],
   "metadata": {
    "id": "uZNFHCu_kp9_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_loss, loaded_acc = loaded_model_fm.evaluate(X_test_fm_flat, y_test_fm)\n",
    "print(f\"Loaded Model - Test Loss: {loaded_loss:.4f}, Test Acc: {loaded_acc:.4f}\")"
   ],
   "metadata": {
    "id": "Hgs1QmbBkovD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- **Practical**: In real projects, you rarely keep your model in memory. You train it once and save it for inference later or for future fine-tuning.  \n",
    "- **Collaboration**: Team members can use your saved model for inference or production deployment."
   ],
   "metadata": {
    "id": "ckniJ3oQkuiC"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Wrap-Up & Next Steps\n\n### What We Learned\n\n| Topic | Key Takeaway |\n|-------|--------------|\n| **SLP Architecture** | Simplest neural network - just input → output with no hidden layers |\n| **Binary Classification** | Use sigmoid activation + binary crossentropy loss |\n| **Multi-Class Classification** | Use softmax activation + categorical crossentropy loss |\n| **Data Preprocessing** | Always scale features; flatten images for dense layers |\n| **Weight Visualization** | SLPs allow direct interpretation of learned patterns |\n| **Model Persistence** | Save models with `.save()`, load with `load_model()` |\n\n### SLP Limitations\n\nSingle-Layer Perceptrons can only learn **linear decision boundaries**. This means:\n- They struggle with complex patterns (e.g., CIFAR-10 images)\n- Fashion MNIST accuracy tops out around 84-85%\n- They cannot solve non-linearly separable problems (e.g., XOR)\n\n### Next Steps\n\n1. **Add hidden layers** → Create a Multi-Layer Perceptron (MLP) for better accuracy\n2. **Try CNNs** → Convolutional Neural Networks are designed for image data\n3. **Use callbacks** → `EarlyStopping`, `ReduceLROnPlateau` for smarter training\n4. **Explore regularization** → Dropout, L2 to prevent overfitting\n\n### Practice Exercise\n\nNow try the **SLP Try-It-Yourself Lab** to apply these concepts to:\n- **IMDB** (text classification with TF-IDF)\n- **CIFAR-10** (color image classification)",
   "metadata": {
    "id": "iuiTCGtpldW8"
   }
  }
 ]
}