{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyMQmumY+Ijum11KqiWrg9Nx",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Neural%20Networks/Keras%20Lab_%20Single-Layer%20Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single-Layer Perceptrons (SLPs)\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction & Prerequisites](#1-introduction-prerequisites)  \n",
    "2. [What is a Single-Layer Perceptron?](#2-what-is-a-single-layer-perceptron)  \n",
    "3. [Sigmoid vs. Softmax — Key Differences](#3-sigmoid-vs-softmax)  \n",
    "4. [Data Exploration & Insights](#4-data-exploration--insights)  \n",
    "5. [Binary Classification: Breast Cancer (`sklearn.datasets`)](#5-binary-classification)  \n",
    "   - [Handling Class Imbalance (Conceptual)](#51-handling-class-imbalance)  \n",
    "6. [Hyperparameter Tuning (Learning Rates, Epochs)](#6-hyperparameter-tuning)  \n",
    "7. [Multi-Class Classification: Fashion MNIST (`keras.datasets`)](#7-multi-class-classification)  \n",
    "   - [Visualizing Weights in the SLP](#71-visualizing-weights)  \n",
    "   - [More Detailed Error Analysis](#72-more-detailed-error-analysis)  \n",
    "8. [Saving & Loading Models (End-to-End Workflow)](#8-saving--loading-models)  \n",
    "9. [Lab Skeleton Notebook for Students](#9-lab-skeleton-notebook-for-students)  \n",
    "10. [Wrap-up & Further Study](#10-wrap-up--further-study)"
   ],
   "metadata": {
    "id": "JFaZiYirgTHd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction & Prerequisites\n",
    "\n",
    "**Goal**:  \n",
    "Build a **Single-Layer Perceptron (SLP)** for **binary classification** (Breast Cancer) and **multi-class classification** (Fashion MNIST). Along the way, we will:\n",
    "- Explore data for better intuition.\n",
    "- Implement **hyperparameter tuning** (learning rates, epochs).\n",
    "- Visualize learned **weights** (for image data).\n",
    "- Perform a more **detailed error analysis**.\n",
    "- Discuss **handling class imbalance** conceptually.\n",
    "- Demonstrate **saving & loading** models for an end-to-end ML workflow.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Basic Python, NumPy, and Matplotlib.\n",
    "- Familiarity with classification tasks (binary and multi-class).\n",
    "- Libraries: `tensorflow`, `scikit-learn`, `matplotlib`, `numpy`.\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install tensorflow scikit-learn matplotlib numpy\n",
    "```"
   ],
   "metadata": {
    "id": "PcpOKc1-gpVG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. What is a Single-Layer Perceptron?\n",
    "\n",
    "A **Single-Layer Perceptron (SLP)** is one of the most fundamental neural network models. It consists of:\n",
    "- **Input Layer**: Receives features $\\{x_1, x_2, \\ldots, x_n\\}$.  \n",
    "- **Output Layer**: Produces predictions (probabilities or logits).  \n",
    "- **No Hidden Layers**: Exactly one set of weights from inputs to outputs.\n",
    "\n",
    "**Typical SLP Setup**:\n",
    "1. **Binary classification**:\n",
    "   - **1 output neuron** (sigmoid activation).  \n",
    "   - **Binary crossentropy** loss.\n",
    "2. **Multi-class classification** (e.g., 10 classes):\n",
    "   - **$k$ output neurons** (softmax activation).  \n",
    "   - **(Sparse) categorical crossentropy** loss.\n",
    "\n",
    "**Number of parameters** = $(\\text{input_dim} \\times \\text{output_dim}) + \\text{output_dim}$.  \n",
    "- If input_dim = 784 (flattened 28×28) and output_dim = 10 => $(784 \\times 10) + 10 = 7850$ parameters."
   ],
   "metadata": {
    "id": "J7yezp1UgzH7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Sigmoid vs. Softmax — Key Differences\n",
    "\n",
    "1. **Sigmoid** $\\sigma(z)$  \n",
    "   - **Formula**: $\\sigma(z) = \\frac{1}{1 + e^{-z}}$.  \n",
    "   - **Output Range**: $(0, 1)$.  \n",
    "   - Perfect for **binary** classification: 1 output neuron yields a probability for class = 1.\n",
    "\n",
    "2. **Softmax**  \n",
    "   - **Formula**: $\\text{softmax}(z_j) = \\frac{e^{z_j}}{\\sum_{k} e^{z_k}}$.  \n",
    "   - **Output Range**: Each class probability in $(0, 1)$, summing to 1.  \n",
    "   - Perfect for **multi-class** classification: $\\text{output_dim} = \\text{#classes}$."
   ],
   "metadata": {
    "id": "oLDjdK3chPkV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Data Exploration & Insights\n",
    "\n",
    "Before diving into modeling, a brief **data exploration** helps us understand:\n",
    "- Feature distributions.\n",
    "- Potential class imbalances.\n",
    "- Correlations or outliers.\n",
    "\n",
    "In the **Breast Cancer** dataset, we might:\n",
    "- Examine basic statistics of each feature (mean, std).\n",
    "- Count how many “malignant” vs. “benign” samples to check if it’s balanced.\n",
    "\n",
    "In **Fashion MNIST**, we might:\n",
    "- Display a few sample images to see what the data looks like.\n",
    "\n",
    "**Why do this?**  \n",
    "1. **Better Intuition**: We know whether the dataset is balanced or skewed.  \n",
    "2. **Feature Engineering**: EDA can suggest if scaling or transformations are needed.  \n",
    "3. **Detecting Anomalies**: Sometimes there are outliers or missing values.\n",
    "\n",
    "Below, we’ll incorporate minimal EDA to illustrate these points."
   ],
   "metadata": {
    "id": "Q1AN2LxRh0hk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Binary Classification: Breast Cancer (`sklearn.datasets`)\n",
    "\n",
    "### 5.1 Load & Quick Exploration"
   ],
   "metadata": {
    "id": "NgXPTCtYiVbv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data_bc = load_breast_cancer()\n",
    "\n",
    "X_bc = data_bc.data   # (569, 30) typically\n",
    "y_bc = data_bc.target # (569,) => 0 or 1\n",
    "\n",
    "print(\"Features shape:\", X_bc.shape)\n",
    "print(\"Labels shape:\", y_bc.shape)\n",
    "print(\"Feature names:\", data_bc.feature_names)\n",
    "print(\"Class distribution:\\n\",\n",
    "      {name: count for name, count in zip(data_bc.target_names, np.bincount(y_bc))})"
   ],
   "metadata": {
    "id": "JXONgE9vicKG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**What the above code does**:\n",
    "- Prints shapes, checks how many features (30).\n",
    "- Prints how many malignant vs. benign cases."
   ],
   "metadata": {
    "id": "zTEzVA2XigFC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Handling Class Imbalance (Conceptual)\n",
    "If we find significant imbalance (say 90% benign, 10% malignant), we might:\n",
    "- Use **metrics** like `precision`, `recall`, `F1-score` instead of just accuracy.  \n",
    "- Adjust **class_weights** in `model.fit()`.  \n",
    "- Perform **oversampling** or **undersampling**.  \n",
    "\n",
    "Breast Cancer is not extremely imbalanced, but it’s still important to check."
   ],
   "metadata": {
    "id": "R6qG9thYimwv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Split, Scale, and Build SLP"
   ],
   "metadata": {
    "id": "gw6qVsskgxAa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(\n",
    "    X_bc, y_bc,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scaler_bc = StandardScaler()\n",
    "X_train_bc_scaled = scaler_bc.fit_transform(X_train_bc)\n",
    "X_test_bc_scaled  = scaler_bc.transform(X_test_bc)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_bc = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_bc.shape[1],))\n",
    "])\n",
    "model_bc.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_bc.summary()"
   ],
   "metadata": {
    "id": "Udlt8EeBiydz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 Train & Evaluate"
   ],
   "metadata": {
    "id": "w7bpmVguixOP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history_bc = model_bc.fit(\n",
    "    X_train_bc_scaled, y_train_bc,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_bc, test_acc_bc = model_bc.evaluate(X_test_bc_scaled, y_test_bc)\n",
    "print(f\"BC Test Loss: {test_loss_bc:.4f}\")\n",
    "print(f\"BC Test Accuracy: {test_acc_bc:.4f}\")"
   ],
   "metadata": {
    "id": "eTLEtR1NiwlK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Learning Curves"
   ],
   "metadata": {
    "id": "6cfLAyq4i8YI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_bc.history['loss'], label='Train Loss')\n",
    "plt.plot(history_bc.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"BC - Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_bc.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_bc.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"BC - Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "mP6Goe2Ji-XZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix & Classification Report"
   ],
   "metadata": {
    "id": "ElBHbJ3SjDKb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_bc_probs = model_bc.predict(X_test_bc_scaled)\n",
    "y_pred_bc = (y_pred_bc_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "cm_bc = confusion_matrix(y_test_bc, y_pred_bc)\n",
    "print(\"Breast Cancer Confusion Matrix:\\n\", cm_bc)\n",
    "\n",
    "print(\"Breast Cancer Classification Report:\\n\",\n",
    "      classification_report(y_test_bc, y_pred_bc))"
   ],
   "metadata": {
    "id": "WlkIeId4jFlz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1 Handling Class Imbalance (Conceptual)"
   ],
   "metadata": {
    "id": "sxjdjolYjIsN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If, for instance, we discovered a heavy imbalance in classes,\n",
    "# we could try:\n",
    "\n",
    "# model_bc.fit(\n",
    "#    X_train_bc_scaled, y_train_bc,\n",
    "#    class_weight={0: 2.0, 1: 1.0},  # Example weighting\n",
    "#    ...\n",
    "# )"
   ],
   "metadata": {
    "id": "_RZGYITwjNyI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Why?**  \n",
    "> Giving **higher weight** to the minority class can help the network pay more attention to it, improving metrics like recall for that class.\n",
    "\n",
    "Since the Breast Cancer dataset is not severely imbalanced, we might not need this, but it’s **important** students understand how to handle imbalance if it arises."
   ],
   "metadata": {
    "id": "LD0erXuAjRGI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Hyperparameter Tuning (Learning Rates, Epochs)\n",
    "\n",
    "**Hyperparameters** such as:\n",
    "- **Learning rate** (`optimizer` parameters, e.g., `Adam(lr=0.001)`).\n",
    "- **Number of epochs**.\n",
    "- **Batch size**.\n",
    "\n",
    "significantly influence model performance."
   ],
   "metadata": {
    "id": "I1_I9u4NjVqm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Example: Adjusting Learning Rate & Epochs"
   ],
   "metadata": {
    "id": "YZxFPOkpjZEQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Let's try a smaller learning rate and more epochs\n",
    "model_bc_tuned = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_bc.shape[1],))\n",
    "])\n",
    "# e.g. learning_rate=0.0005 instead of the default 0.001\n",
    "model_bc_tuned.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_bc_tuned = model_bc_tuned.fit(\n",
    "    X_train_bc_scaled, y_train_bc,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,  # increased\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_tuned, test_acc_tuned = model_bc_tuned.evaluate(X_test_bc_scaled, y_test_bc)\n",
    "print(f\"Tuned BC Loss: {test_loss_tuned:.4f}\")\n",
    "print(f\"Tuned BC Accuracy: {test_acc_tuned:.4f}\")"
   ],
   "metadata": {
    "id": "lsXHALKkjTaL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why try smaller LR & more epochs?**  \n",
    "- A smaller learning rate helps the model converge more *gradually*, potentially avoiding overshoot.  \n",
    "- More epochs allow the model to refine its weights further.\n",
    "\n",
    "If the dataset is small and you see overfitting, you may not need too many epochs. Tuning these hyperparameters is **iterative** and often dataset-specific."
   ],
   "metadata": {
    "id": "-A22JGEUjhJM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Multi-Class Classification: Fashion MNIST (`keras.datasets`)\n",
    "\n",
    "**Objective**:\n",
    "Classify 28×28 grayscale images into 10 classes of clothing items. A Single-Layer Perceptron will act as a simple baseline."
   ],
   "metadata": {
    "id": "YYQJPWOrjnmf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Load, Inspect & Explore"
   ],
   "metadata": {
    "id": "ivlBoN-WjrI9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_fm, y_train_fm), (X_test_fm, y_test_fm) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"FM Train shape:\", X_train_fm.shape)   # (60000, 28, 28)\n",
    "print(\"FM Train labels:\", y_train_fm.shape)  # (60000,)\n",
    "print(\"Unique classes:\", np.unique(y_train_fm))"
   ],
   "metadata": {
    "id": "y9n2E1N7jj5s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Exploration**:\n",
    "- Optional: Display some sample images."
   ],
   "metadata": {
    "id": "pzZtiVN4j0jm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the first 5 images\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X_train_fm[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train_fm[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "bPUYpViSj2_w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Preprocess & Build SLP\n",
    "\n",
    "1. **Rescale** from \\([0..255]\\) to \\([0..1]\\).  \n",
    "2. **Flatten** images to 784-dim vectors.  \n",
    "3. **Output layer** = 10 neurons (softmax).\n"
   ],
   "metadata": {
    "id": "G_AXklxxj58f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_fm = X_train_fm / 255.0\n",
    "X_test_fm  = X_test_fm / 255.0\n",
    "\n",
    "X_train_fm_flat = X_train_fm.reshape(-1, 28*28)\n",
    "X_test_fm_flat  = X_test_fm.reshape(-1, 28*28)\n",
    "\n",
    "model_fm = keras.Sequential([\n",
    "    layers.Dense(10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "model_fm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_fm.summary()"
   ],
   "metadata": {
    "id": "6Y66qKeZj8Jk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Train & Evaluate\n"
   ],
   "metadata": {
    "id": "LsxXWZNLkArN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "history_fm = model_fm.fit(\n",
    "    X_train_fm_flat, y_train_fm,\n",
    "    validation_split=0.2,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_fm, test_acc_fm = model_fm.evaluate(X_test_fm_flat, y_test_fm)\n",
    "print(f\"Fashion MNIST - Test Loss: {test_loss_fm:.4f}\")\n",
    "print(f\"Fashion MNIST - Test Accuracy: {test_acc_fm:.4f}\")"
   ],
   "metadata": {
    "id": "zFzmocjUkCtW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Curves"
   ],
   "metadata": {
    "id": "0YAMt03bkGZi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_fm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_fm.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"FM - Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_fm.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history_fm.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"FM - Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "AmHH7qJikIIb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion Matrix & Classification Report"
   ],
   "metadata": {
    "id": "4U53qRgckLZJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_fm_probs = model_fm.predict(X_test_fm_flat)\n",
    "y_pred_fm = np.argmax(y_pred_fm_probs, axis=1)\n",
    "\n",
    "cm_fm = confusion_matrix(y_test_fm, y_pred_fm)\n",
    "print(\"Fashion MNIST Confusion Matrix:\\n\", cm_fm)\n",
    "print(\"Fashion MNIST Classification Report:\\n\",\n",
    "      classification_report(y_test_fm, y_pred_fm))"
   ],
   "metadata": {
    "id": "D6PK6KZDkNp8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Visualizing Weights in the SLP\n",
    "\n",
    "A single-layer perceptron with 10 outputs has a **weight vector** of length 784 for each class. We can reshape each 784-length weight vector into a 28×28 grid to see what “pattern” the model has learned for each class."
   ],
   "metadata": {
    "id": "2ItPEDGrkRFb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "weights_fm = model_fm.get_weights()[0]  # shape: (784, 10)\n",
    "biases_fm = model_fm.get_weights()[1]   # shape: (10,)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for i in range(10):\n",
    "    # Extract the weight vector for class i\n",
    "    w_i = weights_fm[:, i]\n",
    "    # Reshape to 28x28\n",
    "    w_i_2d = w_i.reshape(28, 28)\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(w_i_2d, cmap='jet')\n",
    "    plt.title(f\"Class {i}\")\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "RtxLRRrFkTx6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- It’s fascinating to see if the model highlights certain regions of the image for a given class, even though it’s just a simple linear map."
   ],
   "metadata": {
    "id": "f21MWW3gkXdd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 More Detailed Error Analysis\n",
    "\n",
    "We can see which items get misclassified frequently. For instance:"
   ],
   "metadata": {
    "id": "sqiPLwgSkao0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "incorrect_idx = np.where(y_pred_fm != y_test_fm)[0]\n",
    "print(f\"Number of misclassified samples: {len(incorrect_idx)}\")\n",
    "\n",
    "# Show some misclassified images\n",
    "plt.figure(figsize=(10,4))\n",
    "for i, idx in enumerate(incorrect_idx[:5]):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X_test_fm[idx], cmap='gray')\n",
    "    plt.title(f\"True: {y_test_fm[idx]}, Pred: {y_pred_fm[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "FHh7J1_ikdCN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- Helps us understand which classes are confusing. For instance, the model might confuse “shirt” vs. “t-shirt” or “pullover” if they visually appear similar."
   ],
   "metadata": {
    "id": "mnnvalXYkf9o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Saving & Loading Models (End-to-End Workflow)\n",
    "\n",
    "After training, it’s crucial to **save** the model so you don’t have to retrain every time, or so you can **deploy** or **share** it."
   ],
   "metadata": {
    "id": "GQAh9CUikit4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the Fashion MNIST model\n",
    "model_fm.save(\"slp_fashion_mnist.h5\")\n",
    "\n",
    "# Later or in another script, load it:\n",
    "loaded_model_fm = tf.keras.models.load_model(\"slp_fashion_mnist.h5\")"
   ],
   "metadata": {
    "id": "_kROjmhokl6Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can then evaluate `loaded_model_fm` on test data again to confirm it’s the same:"
   ],
   "metadata": {
    "id": "uZNFHCu_kp9_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loaded_loss, loaded_acc = loaded_model_fm.evaluate(X_test_fm_flat, y_test_fm)\n",
    "print(f\"Loaded Model - Test Loss: {loaded_loss:.4f}, Test Acc: {loaded_acc:.4f}\")"
   ],
   "metadata": {
    "id": "Hgs1QmbBkovD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Why do this?**  \n",
    "- **Practical**: In real projects, you rarely keep your model in memory. You train it once and save it for inference later or for future fine-tuning.  \n",
    "- **Collaboration**: Team members can use your saved model for inference or production deployment."
   ],
   "metadata": {
    "id": "ckniJ3oQkuiC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Wrap-up & Further Study\n",
    "\n",
    "### Summary\n",
    "- **Data Exploration** helps detect issues (imbalance, anomalies) and informs choices (scaling, weighting).\n",
    "- **SLPs** are easy to understand but limited for complex tasks.\n",
    "- **Hyperparameter tuning** (learning rates, epochs) can significantly affect performance.\n",
    "- **Visualizing weights** for image tasks can provide insights.\n",
    "- **Detailed error analysis** (misclassified examples) reveals model weaknesses.\n",
    "- **Model saving/loading** is crucial for real-world workflow.\n",
    "\n",
    "### Next Steps\n",
    "1. **Add hidden layers** to see how a **multilayer perceptron (MLP)** outperforms an SLP on Fashion MNIST.  \n",
    "2. **Use callbacks** like `EarlyStopping` or `ReduceLROnPlateau` for more advanced training control.  \n",
    "3. **Experiment with other optimizers** (e.g., `SGD`, `RMSprop`), batch sizes, or epoch counts.  \n",
    "4. **Try new datasets** (MNIST, CIFAR-10, or custom data) to expand your skill set.  \n",
    "5. **Investigate more advanced error analysis** (e.g., Grad-CAM for CNN-based tasks, or SHAP for interpretability)."
   ],
   "metadata": {
    "id": "iuiTCGtpldW8"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "JB_wJgzglcbb"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}