{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWUEeQqEJ5Fmm0eQmx8dC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Lectures/13%20Deep%20Neural%20Networks/Hands-On%20Lab%3A%20Deep%20Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hands-On Lab: Deep Neural Networks**\n",
        "\n",
        "## **1. Introduction & Universal Workflow**\n",
        "\n",
        "In this notebook, we’ll demonstrate:\n",
        "\n",
        "1. The **universal workflow** of machine learning:\n",
        "   1. Define problem & gather data  \n",
        "   2. Choose metrics of success (including F1 for imbalanced data)  \n",
        "   3. Choose an evaluation protocol  \n",
        "   4. Prepare data (Bag-of-Words/TF-IDF for IMDB, flatten for Fashion MNIST)  \n",
        "   5. Build a **baseline** model (better than random)  \n",
        "   6. **Scale up** → intentionally overfit  \n",
        "   7. **Regularize** (Dropout, L2)  \n",
        "   8. **Hyperparameter tuning** with **Hyperband**  \n",
        "\n",
        "2. **Binary Classification** on **IMDB** reviews:\n",
        "   - **Bag-of-Words** / **TF-IDF** approach (using `sklearn.feature_extraction`)  \n",
        "   - **F1 score** for evaluation (since IMDB can be slightly imbalanced)  \n",
        "   - Also demonstrate **class weights**.\n",
        "\n",
        "3. **Multi-Class Classification** on **Fashion MNIST** (10 clothing classes).\n",
        "\n",
        "4. **Appendix**:\n",
        "   - EarlyStopping demonstration  \n",
        "   - Why you might still want other forms of regularization even if you have EarlyStopping.\n",
        "\n",
        "Let’s begin!"
      ],
      "metadata": {
        "id": "8_lYvUKUGJc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 1.1 SETUP & IMPORTS\n",
        "###########################################################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "\n",
        "# Keras Tuner for hyperparameter search\n",
        "!pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras Tuner version:\", kt.__version__)\n",
        "\n",
        "def plot_history(history, title=''):\n",
        "    \"\"\"\n",
        "    Plot training/validation loss & accuracy from a Keras history object.\n",
        "    Helps visualize overfitting/underfitting.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "    ax1.plot(history.history['loss'], label='Train Loss')\n",
        "    ax1.plot(history.history['val_loss'], label='Val Loss')\n",
        "    ax1.set_title(f'{title} - Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    ax2.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    ax2.set_title(f'{title} - Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"\"\"\n",
        "UNIVERSAL WORKFLOW STEPS:\n",
        "1) Define problem & gather data\n",
        "2) Choose metrics (accuracy, F1, etc.)\n",
        "3) Choose evaluation protocol\n",
        "4) Prepare data (Bag-of-Words/TF-IDF for IMDB, flatten for Fashion MNIST)\n",
        "5) Baseline model\n",
        "6) Scale up -> Overfit\n",
        "7) Regularize\n",
        "8) Hyperparameter Tuning\n",
        "(Appendix) EarlyStopping demonstration\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "fK-V3O9VGgjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Binary Classification: IMDB (with Bag-of-Words/TF-IDF and F1)**\n",
        "\n",
        "Traditionally, IMDB can be processed via:\n",
        "- **Multi-hot**: A naive bag-of-words approach.  \n",
        "- **CountVectorizer** or **TfidfVectorizer** from **scikit-learn**: A more standard approach.  \n",
        "\n",
        "We’ll do **TF-IDF** by default, but you can switch to **CountVectorizer** if desired.  \n",
        "\n",
        "We’ll measure:\n",
        "- **Accuracy** (baseline)  \n",
        "- **F1 score** for imbalanced data.  \n",
        "\n",
        "We’ll also use **class weights** to emphasize the minority class if any imbalance is present.\n",
        "\n",
        "---\n",
        "\n",
        "## 2.1 Define Problem & Load Data"
      ],
      "metadata": {
        "id": "IlO4NP1fGn3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.1 IMDB DATA\n",
        "###########################################################\n",
        "num_words = 10000\n",
        "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = keras.datasets.imdb.load_data(num_words=num_words)\n",
        "\n",
        "print(\"IMDB train samples:\", len(x_train_raw))\n",
        "print(\"IMDB test samples:\", len(x_test_raw))\n",
        "\n",
        "unique, counts = np.unique(y_train_raw, return_counts=True)\n",
        "print(\"IMDB train label distribution:\", dict(zip(unique, counts)))\n",
        "\n",
        "classes = dict(zip(unique, counts))\n",
        "print(\"Naive Baseline (Accuracy):\", max([classes[0], classes[1]]) / (classes[0] + classes[1]))"
      ],
      "metadata": {
        "id": "bFraJ0M_G8Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Choose Metrics: Accuracy + F1\n",
        "We’ll compute **accuracy** in Keras, and **F1** *after* training using `sklearn.metrics.f1_score`. We can also do a confusion matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "MMEqX4vyG-h9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Evaluation Protocol\n",
        "We’ll hold out 20% from the official training set for validation. Then we keep the official test set for the final check."
      ],
      "metadata": {
        "id": "OPYuuJP0HMu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Data Preparation: Decoding to Text & TF-IDF\n",
        "\n",
        "Keras IMDB is integer-encoded. We’ll:\n",
        "1. Decode integers to text strings.  \n",
        "2. Use **TfidfVectorizer** (or **CountVectorizer**) from scikit-learn.  \n",
        "3. Convert to **dense arrays** (since Keras typically needs dense input).  \n",
        "\n",
        "Finally, we’ll define class weights."
      ],
      "metadata": {
        "id": "qoqq5w58HJb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.4 BAG-OF-WORDS / TF-IDF FOR IMDB\n",
        "###########################################################\n",
        "# Retrieve word index from Keras\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Reverse mapping (integer -> word)\n",
        "reverse_word_index = {v: k for (k, v) in word_index.items()}\n",
        "# Indices 0..3 are special tokens in Keras IMDB\n",
        "def decode_review(int_seq):\n",
        "    return \" \".join([reverse_word_index.get(i-3, \"?\") for i in int_seq])\n",
        "\n",
        "# Convert integer sequences to raw text\n",
        "train_texts = [\" \".join([reverse_word_index.get(i-3, \"?\") for i in seq]) for seq in x_train_raw]\n",
        "test_texts  = [\" \".join([reverse_word_index.get(i-3, \"?\") for i in seq]) for seq in x_test_raw]\n",
        "\n",
        "# Use TfidfVectorizer or CountVectorizer\n",
        "# vectorizer = CountVectorizer(max_features=num_words, stop_words='english')\n",
        "vectorizer = TfidfVectorizer(max_features=num_words, stop_words='english')\n",
        "\n",
        "X_train_sparse = vectorizer.fit_transform(train_texts)\n",
        "X_test_sparse  = vectorizer.transform(test_texts)\n",
        "\n",
        "# Convert sparse -> dense (can be memory-heavy; consider partial approaches for large data)\n",
        "X_train = X_train_sparse.toarray()\n",
        "X_test  = X_test_sparse.toarray()\n",
        "\n",
        "y_train = y_train_raw\n",
        "y_test  = y_test_raw\n",
        "\n",
        "print(\"TF-IDF train shape:\", X_train.shape)\n",
        "print(\"TF-IDF test shape: \", X_test.shape)\n",
        "\n",
        "# Class weighting\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "neg_count, pos_count = counts[0], counts[1]\n",
        "total_count = neg_count + pos_count\n",
        "weight_for_0 = (1.0 / neg_count) * (total_count / 2.0)\n",
        "weight_for_1 = (1.0 / pos_count) * (total_count / 2.0)\n",
        "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
        "print(\"IMDB class weights:\", class_weights)"
      ],
      "metadata": {
        "id": "GwF2wn2uGPp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split out some of the training set for validation\n",
        "X_train_imdb, X_val_imdb, y_train_imdb, y_val_imdb = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(\"Train samples after splitting:\", X_train_imdb.shape[0])\n",
        "print(\"Validation samples:\", X_val_imdb.shape[0])"
      ],
      "metadata": {
        "id": "dn-6TsI7HWQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Baseline Model (Single-Layer Perceptron)\n",
        "\n",
        "We do a single `Dense(1, sigmoid)`. We measure **accuracy** during training, and after training we’ll compute the **F1** on the validation set (and test set)."
      ],
      "metadata": {
        "id": "OIQ-g1RGHanx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.5 BASELINE MODEL\n",
        "###########################################################\n",
        "baseline_model = keras.Sequential([\n",
        "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_imdb.shape[1],))\n",
        "])\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_base = baseline_model.fit(\n",
        "    X_train_imdb, y_train_imdb,\n",
        "    validation_data=(X_val_imdb, y_val_imdb),\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_base, \"IMDB Baseline (TF-IDF)\")\n",
        "\n",
        "# Evaluate on test\n",
        "test_loss_base, test_acc_base = baseline_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Baseline Test Accuracy: {test_acc_base:.4f}\")\n",
        "\n",
        "# Let's also compute F1 on test\n",
        "y_test_preds_base = (baseline_model.predict(X_test) > 0.5).astype(int).ravel()\n",
        "test_f1_base = f1_score(y_test, y_test_preds_base)\n",
        "print(f\"Baseline Test F1 score: {test_f1_base:.4f}\")"
      ],
      "metadata": {
        "id": "yxR4Ef6UHcrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Overfit (More Layers)\n",
        "\n",
        "We add more layers/units. We expect training accuracy to rise, but if we do enough epochs, the validation might degrade. We’ll measure both accuracy and F1 after training."
      ],
      "metadata": {
        "id": "UlZcX0IgHh9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overfit_model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(X_train_imdb.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "overfit_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_overfit = overfit_model.fit(\n",
        "    X_train_imdb, y_train_imdb,\n",
        "    validation_data=(X_val_imdb, y_val_imdb),\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_overfit, \"IMDB Overfit (TF-IDF)\")\n",
        "\n",
        "# Evaluate on test\n",
        "test_loss_over, test_acc_over = overfit_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Overfit Model Test Accuracy: {test_acc_over:.4f}\")\n",
        "\n",
        "y_test_preds_over = (overfit_model.predict(X_test) > 0.5).astype(int).ravel()\n",
        "test_f1_over = f1_score(y_test, y_test_preds_over)\n",
        "print(f\"Overfit Model Test F1: {test_f1_over:.4f}\")"
      ],
      "metadata": {
        "id": "2k4OWkLbHkbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Regularize (Dropout + L2) + F1\n",
        "\n",
        "Dropout and L2 penalize large weights and randomize neuron outputs, hopefully improving generalization. We’ll check both accuracy and F1."
      ],
      "metadata": {
        "id": "CO7tOD8DHqCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train_imdb.shape[1],)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "reg_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_reg = reg_model.fit(\n",
        "    X_train_imdb, y_train_imdb,\n",
        "    validation_data=(X_val_imdb, y_val_imdb),\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_reg, \"IMDB Regularized (TF-IDF)\")\n",
        "\n",
        "# Evaluate test\n",
        "test_loss_reg, test_acc_reg = reg_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Regularized Model Test Accuracy: {test_acc_reg:.4f}\")\n",
        "\n",
        "y_test_preds_reg = (reg_model.predict(X_test) > 0.5).astype(int).ravel()\n",
        "test_f1_reg = f1_score(y_test, y_test_preds_reg)\n",
        "print(f\"Regularized Model Test F1: {test_f1_reg:.4f}\")"
      ],
      "metadata": {
        "id": "DP0oyV-oHt1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Hyperparameter Tuning (Hyperband) with F1 Score\n",
        "\n",
        "We’ll define a tuner that tries different layer counts, dropout, L2, and learning rates. We’ll optimize for **validation accuracy** in Keras, but after we find the best model, we’ll also measure **F1** on the test set.\n",
        "\n",
        "You can attempt to incorporate a custom F1-based objective. However, it’s simpler to just optimize accuracy in Keras, then compute F1 externally."
      ],
      "metadata": {
        "id": "ZihWl2_pH3De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_imdb_model_tuner(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    n_layers = hp.Int('n_layers', 1, 3)\n",
        "    for i in range(n_layers):\n",
        "        units = hp.Choice(f'units_{i}', [64,128,256])\n",
        "        l2_factor = hp.Float(f'l2_{i}', 1e-4, 1e-2, sampling='log')\n",
        "        model.add(layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(l2_factor),\n",
        "                               input_shape=(X_train_imdb.shape[1],) if i==0 else ()))\n",
        "        drop = hp.Float(f'drop_{i}', 0.0, 0.5, step=0.1)\n",
        "        model.add(layers.Dropout(drop))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    lr = hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner_imdb = kt.Hyperband(\n",
        "    build_imdb_model_tuner,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=5,\n",
        "    factor=3,\n",
        "    directory='imdb_tfidf_hyperband',\n",
        "    project_name='imdb_f1_demo'\n",
        ")\n",
        "\n",
        "tuner_imdb.search(\n",
        "    X_train_imdb, y_train_imdb,\n",
        "    validation_data=(X_val_imdb, y_val_imdb),\n",
        "    epochs=5,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "best_hp_imdb = tuner_imdb.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best hyperparams (IMDB):\", best_hp_imdb.values)\n",
        "\n",
        "best_model_imdb = tuner_imdb.hypermodel.build(best_hp_imdb)\n",
        "history_imdb_tuned = best_model_imdb.fit(\n",
        "    X_train_imdb, y_train_imdb,\n",
        "    validation_data=(X_val_imdb, y_val_imdb),\n",
        "    epochs=10,\n",
        "    batch_size=512,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "plot_history(history_imdb_tuned, \"IMDB Tuner (TF-IDF)\")\n",
        "\n",
        "# Evaluate final\n",
        "test_loss_tuned, test_acc_tuned = best_model_imdb.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Tuned Model Test Accuracy: {test_acc_tuned:.4f}\")\n",
        "\n",
        "y_test_preds_tuned = (best_model_imdb.predict(X_test) > 0.5).astype(int).ravel()\n",
        "test_f1_tuned = f1_score(y_test, y_test_preds_tuned)\n",
        "print(f\"Tuned Model Test F1 Score: {test_f1_tuned:.4f}\")"
      ],
      "metadata": {
        "id": "60dg8QwOH6FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Multi-Class: Fashion MNIST**\n",
        "\n",
        "We keep the previous approach for Fashion MNIST (flatten 28×28 images). We'll measure accuracy (and skip F1 because it's multi-class, though we could do macro/micro average F1)."
      ],
      "metadata": {
        "id": "MKa54FCRILGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 3.1 LOAD FASHION MNIST\n",
        "###########################################################\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train_fm, y_train_fm), (x_test_fm, y_test_fm) = fashion_mnist.load_data()\n",
        "\n",
        "x_train_fm = x_train_fm / 255.0\n",
        "x_test_fm  = x_test_fm  / 255.0\n",
        "\n",
        "X_train_fm_flat = x_train_fm.reshape(-1, 28*28)\n",
        "X_test_fm_flat  = x_test_fm.reshape(-1, 28*28)\n",
        "\n",
        "print(\"FashionMNIST train shape:\", x_train_fm.shape)\n",
        "print(\"FashionMNIST test shape: \",  x_test_fm.shape)"
      ],
      "metadata": {
        "id": "wXgf20gsH6yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Baseline (Single-Layer)"
      ],
      "metadata": {
        "id": "nVtFz93wISWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_fm = keras.Sequential([\n",
        "    layers.Dense(10, activation='softmax', input_shape=(784,))\n",
        "])\n",
        "baseline_fm.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fm_base = baseline_fm.fit(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_fm_base, 'FashionMNIST Baseline')\n",
        "test_loss_fm_base, test_acc_fm_base = baseline_fm.evaluate(X_test_fm_flat, y_test_fm, verbose=0)\n",
        "print(f\"FashionMNIST Baseline Test Accuracy: {test_acc_fm_base:.4f}\")"
      ],
      "metadata": {
        "id": "nMG72rUJIU0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Overfit (More Layers)"
      ],
      "metadata": {
        "id": "gXYDEP3LIbKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overfit_fm = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "overfit_fm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_fm_over = overfit_fm.fit(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_fm_over, 'FashionMNIST Overfit')\n",
        "test_loss_fm_over, test_acc_fm_over = overfit_fm.evaluate(X_test_fm_flat, y_test_fm, verbose=0)\n",
        "print(f\"Overfit Model Test Accuracy: {test_acc_fm_over:.4f}\")"
      ],
      "metadata": {
        "id": "ihRSW5taIdcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Regularize (Dropout + L2)"
      ],
      "metadata": {
        "id": "in50csDHIgsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_fm = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(784,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "reg_fm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_fm_reg = reg_fm.fit(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=15,\n",
        "    batch_size=512,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "plot_history(history_fm_reg, 'FashionMNIST Regularized')\n",
        "test_loss_fm_reg, test_acc_fm_reg = reg_fm.evaluate(X_test_fm_flat, y_test_fm, verbose=0)\n",
        "print(f\"FashionMNIST Regularized Test Accuracy: {test_acc_fm_reg:.4f}\")"
      ],
      "metadata": {
        "id": "-e6-_CQaIisA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Hyperparameter Tuning (Hyperband)"
      ],
      "metadata": {
        "id": "APtLPf1gIlwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fm_model_tuner(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(784,)))\n",
        "\n",
        "    n_layers = hp.Int('n_layers', 1, 3)\n",
        "    for i in range(n_layers):\n",
        "        units = hp.Choice(f'units_{i}', [128, 256])\n",
        "        l2_factor = hp.Float(f'l2_{i}', 1e-4, 1e-2, sampling='log')\n",
        "        model.add(layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(l2_factor)))\n",
        "        drop_rate = hp.Float(f'drop_{i}', 0.0, 0.5, step=0.1)\n",
        "        model.add(layers.Dropout(drop_rate))\n",
        "\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    lr = hp.Float('lr', 1e-4, 1e-2, sampling='log')\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner_fm = kt.Hyperband(\n",
        "    build_fm_model_tuner,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=5,\n",
        "    factor=3,\n",
        "    directory='fashion_hyperband',\n",
        "    project_name='fm_tfidf_demo'\n",
        ")\n",
        "\n",
        "tuner_fm.search(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=512\n",
        ")\n",
        "\n",
        "best_hp_fm = tuner_fm.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best Hyperparams (Fashion MNIST):\", best_hp_fm.values)\n",
        "\n",
        "best_model_fm = tuner_fm.hypermodel.build(best_hp_fm)\n",
        "history_fm_tuned = best_model_fm.fit(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=512\n",
        ")\n",
        "\n",
        "plot_history(history_fm_tuned, \"FashionMNIST Tuner\")\n",
        "test_loss_fm_tuned, test_acc_fm_tuned = best_model_fm.evaluate(X_test_fm_flat, y_test_fm, verbose=0)\n",
        "print(f\"Tuned Model Test Accuracy: {test_acc_fm_tuned:.4f}\")"
      ],
      "metadata": {
        "id": "AwC4acafIown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Appendix: EarlyStopping & Why Regularize Anyway?**\n",
        "\n",
        "## 4.1 EarlyStopping Example + Plot\n",
        "\n",
        "Below is how we might apply EarlyStopping for, say, the IMDB or FashionMNIST data. We can then see the training stops early to avoid overfitting. We’ll also plot the history to see how many epochs it trained."
      ],
      "metadata": {
        "id": "ARSDJsH-IxyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model_es_demo = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_es_demo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_es_demo = model_es_demo.fit(\n",
        "    X_train_fm_flat, y_train_fm,\n",
        "    validation_split=0.2,\n",
        "    epochs=20,        # set a big number\n",
        "    batch_size=512,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# Plot\n",
        "plot_history(history_es_demo, title=\"EarlyStopping Demo\")\n",
        "\n",
        "test_loss_es, test_acc_es = model_es_demo.evaluate(X_test_fm_flat, y_test_fm, verbose=0)\n",
        "print(f\"EarlyStopping Demo - Test Accuracy: {test_acc_es:.4f}\")"
      ],
      "metadata": {
        "id": "zVIWqV1yI0JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 If EarlyStopping is Enough, Why Bother with Regularization?\n",
        "\n",
        "- **EarlyStopping** halts training when validation performance stops improving, preventing “late-stage overfitting.”\n",
        "- However, you can still overfit **within** the earlier epochs. EarlyStopping only stops after some damage might be done.\n",
        "- **Regularization** (like dropout, L2) actively shapes the learning trajectory from the start, often leading to **better** generalization and improved final metrics.\n",
        "- Combining both:\n",
        "  - Use L2/Dropout to reduce overfitting potential  \n",
        "  - Use EarlyStopping to avoid extra epochs where no val improvement occurs  \n",
        "  - Typically yields the **best** final results."
      ],
      "metadata": {
        "id": "MOYCgJDfI4G4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Observations & Further Improvements**\n",
        "\n",
        "1. **IMDB with TF-IDF**:  \n",
        "   - Replaces naive multi-hot, leading to more standard text features.  \n",
        "   - We measured **F1** to handle potential class imbalance.  \n",
        "   - Class weighting can also shift the decision boundary.  \n",
        "\n",
        "2. **Fashion MNIST**:  \n",
        "   - Flatten + Dense ~80% baseline.  \n",
        "   - Overfit soared with big layers.  \n",
        "   - Dropout + L2 improved generalization.  \n",
        "   - Hyperband found better combos of hyperparams.  \n",
        "\n",
        "3. **Hyperband** vs. RandomSearch**:  \n",
        "   - Hyperband adaptively focuses on promising hyperparam sets, often converging faster.  "
      ],
      "metadata": {
        "id": "2C_2KQCEJBMH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qW-3pVuOI_oK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
