{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPbkXaqdMC8Ixyj0u708tt8",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Neural%20Networks/SLP%20Try-It-Yourself%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
  },
  {
   "cell_type": "markdown",
   "source": "# **Try-It-Yourself: Single-Layer Perceptron Lab**\n\n## **Learning Objectives**\n\nIn this lab, you will practice:\n- Loading and preprocessing different data types (text and images)\n- Building Single-Layer Perceptrons from scratch\n- Evaluating models with confusion matrices and classification reports\n- Visualizing learned weights (for image data)\n- (Optional) Hyperparameter tuning and model saving\n\n## **Datasets**\n\n| Dataset | Task | Input Size | Classes | Expected SLP Accuracy |\n|---------|------|------------|---------|----------------------|\n| **IMDB** | Sentiment Analysis | 10,000 (TF-IDF features) | 2 (pos/neg) | ~85% |\n| **CIFAR-10** | Image Classification | 3,072 (32×32×3 flattened) | 10 | ~25-30% |\n\n> **Note**: SLPs are intentionally limited for these tasks. The goal is to learn the fundamentals, not achieve state-of-the-art results!\n\n## **Contents**\n\n1. **IMDB (Binary Classification)**\n   - 1.1 Data Loading & TF-IDF Encoding\n   - 1.2 Build & Train SLP\n   - 1.3 Evaluate (Confusion Matrix, Classification Report)\n   - 1.4 (Optional) Hyperparameter Tuning\n   - 1.5 (Optional) Saving & Loading\n\n2. **CIFAR-10 (Multi-Class Classification)**\n   - 2.1 Data Loading & Flattening\n   - 2.2 Build & Train SLP\n   - 2.3 Evaluate (Confusion Matrix, Classification Report)\n   - 2.4 Weight Visualization\n   - 2.5 (Optional) Hyperparameter Tuning\n   - 2.6 (Optional) Saving & Loading\n\n---\n\nLet's get started!",
   "metadata": {
    "id": "nsDXdmmJr-up"
   }
  },
  {
   "cell_type": "code",
   "source": "#############################################\n# SETUP & IMPORTS\n#############################################\n# TODO: Import the necessary libraries\n\n# Hint: You'll need:\n# - numpy (as np)\n# - matplotlib.pyplot (as plt)\n# - tensorflow (as tf)\n# - keras from tensorflow\n# - layers from tensorflow.keras\n# - confusion_matrix, classification_report from sklearn.metrics\n# - TfidfVectorizer from sklearn.feature_extraction.text\n\n# Your code here:\n",
   "metadata": {
    "id": "jTsSG-hZr_Fu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## **1. IMDB (Binary Classification)**\n\n### About the Dataset\n\nThe **IMDB dataset** contains 50,000 movie reviews:\n- **25,000 training** reviews\n- **25,000 test** reviews\n- Labels: **positive (1)** or **negative (0)**\n\n### Your Task\n\n1. **Load** the IMDB data from `keras.datasets.imdb`\n2. **Convert** integer sequences to text, then to TF-IDF vectors\n3. **Build** an SLP with 1 output neuron (sigmoid activation)\n4. **Train** and **evaluate** the model\n\n> **No weight visualization** for text data - it doesn't reshape into meaningful images.\n\n---\n\n### 1.1 Data Loading & TF-IDF Encoding",
   "metadata": {
    "id": "I4LtGVZMr45l"
   }
  },
  {
   "cell_type": "code",
   "source": "#############################################\n# 1.1 DATA LOADING & TF-IDF ENCODING\n#############################################\n# TODO: Complete the following steps\n\n# Step 1: Load IMDB data\n# Hint: (x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n\n\n# Step 2: Get word index and create reverse mapping\n# Hint: word_index = keras.datasets.imdb.get_word_index()\n#       reverse_word_index = {value: key for (key, value) in word_index.items()}\n\n\n# Step 3: Decode integer sequences to text\n# Hint: Use a function like:\n# def decode_review(seq):\n#     return ' '.join([reverse_word_index.get(i - 3, '?') for i in seq])\n# train_texts = [decode_review(seq) for seq in x_train]\n\n\n# Step 4: Apply TF-IDF vectorization\n# Hint: vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n#       X_train = vectorizer.fit_transform(train_texts).toarray()\n#       X_test = vectorizer.transform(test_texts).toarray()\n\n\n# Step 5: Print shapes to verify\n# Expected: X_train shape (25000, 10000), X_test shape (25000, 10000)\n",
   "metadata": {
    "id": "Fj5Ex0RUr153"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Build & Train SLP\n",
    "\n",
    "**Instructions**:\n",
    "- Create `model_imdb = keras.Sequential([...])` with `Dense(1, activation='sigmoid')`.\n",
    "- Compile with `'adam'` and `'binary_crossentropy'`.\n",
    "- Train for ~5 epochs with `validation_split=0.2`.\n"
   ],
   "metadata": {
    "id": "LM9OC89Xx7jR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1.2 TODO: Build & Train SLP\n",
    "\n",
    "# Example:\n",
    "# model_imdb = keras.Sequential([\n",
    "#     layers.Dense(1, activation='sigmoid', input_shape=(X_train_imdb_bow.shape[1],))\n",
    "# ])\n",
    "# model_imdb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# history_imdb = model_imdb.fit(X_train_imdb_bow, y_train_imdb, ...)\n"
   ],
   "metadata": {
    "id": "wFbfnBwnxnb3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Evaluate (Confusion Matrix, Classification Report)\n",
    "\n",
    "**Instructions**:\n",
    "1. Evaluate on the test set.\n",
    "2. Generate predictions (probabilities), threshold at 0.5 to get binary labels.\n",
    "3. Print confusion matrix & classification report.\n"
   ],
   "metadata": {
    "id": "gVnfh-0Jx37N"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1.3 TODO: Evaluate IMDB SLP\n",
    "\n",
    "# test_loss_imdb, test_acc_imdb = model_imdb.evaluate(...)\n",
    "# y_pred_imdb_probs = model_imdb.predict(...)\n",
    "# y_pred_imdb = ...\n",
    "# cm_imdb = confusion_matrix(...)\n",
    "# cr_imdb = classification_report(...)\n",
    "# print(...)\n"
   ],
   "metadata": {
    "id": "h69c6LEaxqsL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (Optional) Plot Training Curves\n",
    "\n",
    "From `history_imdb.history`, you can plot `'loss'`, `'val_loss'`, `'accuracy'`, and `'val_accuracy'`.\n"
   ],
   "metadata": {
    "id": "3G5-cLDpruC3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Optional: plot training curves\n",
    "# plt.figure(...)\n",
    "# plt.plot(...)\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "id": "zqAqtQolrzLI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 (Optional) Hyperparameter Tuning\n",
    "\n",
    "Try changing:\n",
    "- Learning rate (e.g., `learning_rate=0.0005`)\n",
    "- Number of epochs\n",
    "- Batch size\n",
    "\n",
    "Compare results to your baseline SLP.\n"
   ],
   "metadata": {
    "id": "PyJwDEiCsfSd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1.4 (Optional) TODO: Hyperparameter Tuning\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# model_imdb_tuned = ...\n",
    "# model_imdb_tuned.compile(optimizer=Adam(learning_rate=0.0005), ...)\n",
    "# history_imdb_tuned = ...\n",
    "# Evaluate, compare\n"
   ],
   "metadata": {
    "id": "3BWx5R151aEc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 (Optional) Saving & Loading\n",
    "\n",
    "Demonstrate how to save the model to `\"slp_imdb.h5\"` and reload it with `keras.models.load_model()`.\n"
   ],
   "metadata": {
    "id": "hmg5cHMk1geB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1.5 (Optional) TODO: Saving & Loading\n",
    "# model_imdb.save(\"slp_imdb.h5\")\n",
    "# loaded_model_imdb = keras.models.load_model(\"slp_imdb.h5\")\n",
    "# Evaluate loaded_model_imdb on test set\n"
   ],
   "metadata": {
    "id": "w0jfvzHv1jBj"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## **2. CIFAR-10 (Multi-Class Classification)**\n\n### About the Dataset\n\n**CIFAR-10** contains 60,000 color images (32×32×3):\n- **50,000 training** images\n- **10,000 test** images\n- **10 classes**: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n\n### The 10 Classes\n\n| Label | Class Name |\n|-------|------------|\n| 0 | Airplane |\n| 1 | Automobile |\n| 2 | Bird |\n| 3 | Cat |\n| 4 | Deer |\n| 5 | Dog |\n| 6 | Frog |\n| 7 | Horse |\n| 8 | Ship |\n| 9 | Truck |\n\n### Your Task\n\n1. **Load & flatten** images to 3,072 features (32×32×3)\n2. **Build** an SLP with 10 outputs (softmax activation)\n3. **Train & evaluate** the model\n4. **Visualize weights** by reshaping to (32, 32, 3)\n\n> **Note**: Expect ~25-30% accuracy. This is normal for an SLP on complex images!\n\n---\n\n### 2.1 Data Loading & Flattening",
   "metadata": {
    "id": "lyPQx1hysr3t"
   }
  },
  {
   "cell_type": "code",
   "source": "#############################################\n# 2.1 CIFAR-10 LOADING & FLATTENING\n#############################################\n# TODO: Complete the following steps\n\n# Class names for reference\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Step 1: Load CIFAR-10 data\n# Hint: from tensorflow.keras.datasets import cifar10\n#       (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\n\n# Step 2: Print shapes and display some sample images\n# Expected: X_train shape (50000, 32, 32, 3)\n\n\n# Step 3: Flatten labels (they come as shape (n, 1))\n# Hint: y_train = y_train.ravel()\n\n\n# Step 4: Scale pixel values to [0, 1]\n# Hint: X_train = X_train / 255.0\n\n\n# Step 5: Flatten images to (n, 3072)\n# Hint: X_train_flat = X_train.reshape(-1, 32*32*3)\n\n",
   "metadata": {
    "id": "rV9FXpIDr0nB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Build & Train SLP\n",
    "\n",
    "**Instructions**:\n",
    "- Create `Dense(10, activation='softmax')`.\n",
    "- Compile with `optimizer='adam'` and `loss='sparse_categorical_crossentropy'`.\n",
    "- Train for about 5 epochs, `validation_split=0.2`.\n"
   ],
   "metadata": {
    "id": "6mm3H1HSs1h7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.2 TODO: Build & Train SLP for CIFAR-10\n",
    "\n",
    "# model_cifar = keras.Sequential([\n",
    "#     layers.Dense(10, activation='softmax', input_shape=(3072,))\n",
    "# ])\n",
    "# model_cifar.compile(...)\n",
    "# history_cifar = model_cifar.fit(...)\n"
   ],
   "metadata": {
    "id": "KUVt9uixyf-e"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Evaluate (Confusion Matrix, Classification Report)\n",
    "\n",
    "**Instructions**:\n",
    "- Evaluate test accuracy & loss.\n",
    "- Convert probabilities to class predictions via `argmax`.\n",
    "- Print confusion matrix & classification report.\n"
   ],
   "metadata": {
    "id": "cztAMUvHyj85"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.3 TODO: Evaluate CIFAR-10 SLP\n",
    "\n",
    "# test_loss_cifar, test_acc_cifar = model_cifar.evaluate(...)\n",
    "# y_pred_cifar_probs = model_cifar.predict(...)\n",
    "# y_pred_cifar = np.argmax(y_pred_cifar_probs, axis=1)\n",
    "# cm_cifar = confusion_matrix(...)\n",
    "# cr_cifar = classification_report(...)\n",
    "# print(...)\n",
    "\n"
   ],
   "metadata": {
    "id": "iuqHr6wtyisP"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Weight Visualization (reshape 32×32×3)\n",
    "\n",
    "**Instructions**:\n",
    "1. Extract the model’s weight matrix: `weights_cifar = model_cifar.get_weights()[0]` (shape: `(3072, 10)`).\n",
    "2. For each class `i`, reshape `weights_cifar[:, i]` from `(3072,)` => `(32, 32, 3)`.\n",
    "3. Display as an “image.” Optional: normalize for better visibility.\n"
   ],
   "metadata": {
    "id": "8VYwW-bNypCd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.4 TODO: Weight Visualization\n",
    "# weights_cifar = model_cifar.get_weights()[0]  # (3072, 10)\n",
    "# for i in range(10):\n",
    "#     w_i = weights_cifar[:, i]\n",
    "#     w_i_3d = w_i.reshape(32,32,3)\n",
    "#     # optional normalization\n",
    "#     plt.imshow(...)\n",
    "#     plt.title(f\"Class {i}\")\n",
    "#     plt.axis('off')\n",
    "# plt.show()\n",
    "\n"
   ],
   "metadata": {
    "id": "FhcyyS4nynmj"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 (Optional) Hyperparameter Tuning\n",
    "\n",
    "As before, try adjusting learning rate, epochs, or batch size and compare results.\n",
    "\n"
   ],
   "metadata": {
    "id": "_1qFqyzzyxRC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.5 (Optional) TODO: Hyperparameter Tuning\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# model_cifar_tuned = ...\n",
    "# model_cifar_tuned.compile(optimizer=Adam(learning_rate=...), ...)\n",
    "# history_cifar_tuned = ...\n",
    "# Evaluate & compare\n"
   ],
   "metadata": {
    "id": "3aa5nP_tys6g"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 (Optional) Saving & Loading\n",
    "\n",
    "Just like IMDB, we can save the model to `\"slp_cifar.h5\"` and reload it with `keras.models.load_model`.\n"
   ],
   "metadata": {
    "id": "YzRGGH8ky1yo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2.6 (Optional) TODO: Saving & Loading\n",
    "# model_cifar.save(\"slp_cifar.h5\")\n",
    "# loaded_model_cifar = keras.models.load_model(\"slp_cifar.h5\")\n",
    "# Evaluate loaded_model_cifar on test data\n"
   ],
   "metadata": {
    "id": "XfLEtQUny0oA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## **Wrap-Up & Reflection**\n\n### Expected Results\n\n| Dataset | Metric | Expected Range |\n|---------|--------|----------------|\n| IMDB | Test Accuracy | 83-87% |\n| CIFAR-10 | Test Accuracy | 25-32% |\n\n### Key Takeaways\n\n1. **IMDB**: TF-IDF + SLP works reasonably well for sentiment analysis because many words have clear sentiment associations.\n\n2. **CIFAR-10**: SLPs struggle with images because they can only learn linear patterns - no edges, textures, or shapes.\n\n3. **Weight Visualization**: For CIFAR-10, the visualized weights show what \"average\" pattern the SLP associates with each class.\n\n### Reflection Questions\n\n- Why does IMDB perform so much better than CIFAR-10 with an SLP?\n- What patterns do you see in the CIFAR-10 weight visualizations?\n- How might adding hidden layers improve performance?\n\n### Next Steps\n\n1. Compare your results with the **Solutions notebook**\n2. Try the **Deep Neural Networks Lab** to see how adding hidden layers helps\n3. Experiment with CNNs for image tasks",
   "metadata": {
    "id": "y-7DOtmIy94U"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "ajN1FTszy8tv"
   }
  }
 ]
}