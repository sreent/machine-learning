{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhHkAKWhOk4+GX/3bv7762",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Lectures/12%20Single-Layer%20Perceptron/Solution%3A%20Try-It-Yourself%20SLP%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOLUTION: Try-It-Yourself SLP Lab**\n",
        "\n",
        "## **Contents**\n",
        "\n",
        "1. **IMDB (Binary Classification)**  \n",
        "   **1.1** Data Loading & Multi-hot (Bag-of-Words) Encoding  \n",
        "   **1.2** Build & Train SLP  \n",
        "   **1.3** Evaluate (Confusion Matrix, Classification Report)  \n",
        "   **1.4** (Optional) Hyperparameter Tuning  \n",
        "   **1.5** (Optional) Saving & Loading  \n",
        "\n",
        "2. **CIFAR-10 (Multi-Class Classification)**  \n",
        "   **2.1** Data Loading & Flattening  \n",
        "   **2.2** Build & Train SLP  \n",
        "   **2.3** Evaluate (Confusion Matrix, Classification Report)  \n",
        "   **2.4** Weight Visualization (reshape 32×32×3)  \n",
        "   **2.5** (Optional) Hyperparameter Tuning  \n",
        "   **2.6** (Optional) Saving & Loading  \n",
        "\n",
        "> **Note**: A Single-Layer Perceptron (SLP) is **very limited** for these datasets; we do **not** expect high accuracy. The goal is to **learn fundamentals** of data loading, preprocessing, model building, training, evaluation, and basic weight interpretation. Let’s get started!\n"
      ],
      "metadata": {
        "id": "nsDXdmmJr-up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# SETUP & IMPORTS\n",
        "###########################################################\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "jTsSG-hZr_Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. IMDB (Binary Classification)**\n",
        "\n",
        "The **IMDB dataset** contains 50,000 movie reviews labeled as **positive (1)** or **negative (0)**. In this lab:\n",
        "\n",
        "1. We **load** the IMDB data from `keras.datasets.imdb`.  \n",
        "2. We use a **multi-hot encoding** (a simple bag-of-words approach) to convert each review into a vector of size `num_words` (often 10,000).  \n",
        "3. We **build** a Single-Layer Perceptron with **1 output neuron** (sigmoid) for binary classification.  \n",
        "4. We **train** the SLP and **evaluate** the results (accuracy, confusion matrix, classification report).  \n",
        "\n",
        "> **No weight visualization** is done for IMDB, as text does not naturally reshape into a 2D/3D format the way images do.\n",
        "\n",
        "Let’s walk through these steps now.\n"
      ],
      "metadata": {
        "id": "I4LtGVZMr45l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Imports & Loading Data"
      ],
      "metadata": {
        "id": "iOmqCQ_cx-6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Load the IMDB dataset from Keras (integer-encoded reviews)\n",
        "(x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "print(\"Number of training samples (IMDB):\", len(x_train_imdb))\n",
        "print(\"Number of test samples (IMDB):\", len(x_test_imdb))\n",
        "\n",
        "# Quick check of class balance (0 = negative, 1 = positive)\n",
        "unique, counts = np.unique(y_train_imdb, return_counts=True)\n",
        "print(\"Train labels distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "id": "Fj5Ex0RUr153"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Decode Integer Sequences to Text\n",
        "\n",
        "Keras provides a mapping of words to integer indices via `get_word_index()`. However, note that the first few indices are reserved for special tokens.\n"
      ],
      "metadata": {
        "id": "LM9OC89Xx7jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the word index dictionary\n",
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Create a reverse mapping from integer indices to words\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_review(sequence):\n",
        "    \"\"\"\n",
        "    Decodes a list of integer indices into a string (review).\n",
        "    Indices 1,2,3 are special tokens in the raw IMDB dataset,\n",
        "    so we map them to '?' if not found.\n",
        "    \"\"\"\n",
        "    # The offset of 3 is because 0,1,2 are special indices in IMDB\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in sequence])\n",
        "\n",
        "# Convert each integer sequence into a raw text string\n",
        "train_texts = [decode_review(seq) for seq in x_train_imdb]\n",
        "test_texts  = [decode_review(seq) for seq in x_test_imdb]\n",
        "\n",
        "print(\"Example decoded review:\\n\", train_texts[0][:300], \"...\")"
      ],
      "metadata": {
        "id": "wFbfnBwnxnb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why decode to text first?**  \n",
        "- We can then use standard text vectorizers (bag-of-words, TF-IDF) from scikit-learn.  \n",
        "- This step can be somewhat slow, but it’s more flexible and standard than a custom “multi-hot” approach."
      ],
      "metadata": {
        "id": "0GV6arwI1A0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Choose Bag-of-Words *or* TF-IDF\n",
        "\n",
        "We can pick either **`CountVectorizer`** for a pure bag-of-words representation (counts of words) or **`TfidfVectorizer`** for TF-IDF weighting."
      ],
      "metadata": {
        "id": "gVnfh-0Jx37N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick TF-IDF for demonstration\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,  # restrict to top 10k features\n",
        "    stop_words='english' # optionally remove English stopwords\n",
        ")\n",
        "\n",
        "# Fit on training texts and transform\n",
        "X_train_imdb_bow = vectorizer.fit_transform(train_texts)  # scipy sparse matrix\n",
        "# Transform test texts\n",
        "X_test_imdb_bow  = vectorizer.transform(test_texts)\n",
        "\n",
        "print(\"TF-IDF train shape:\", X_train_imdb_bow.shape)\n",
        "print(\"TF-IDF test shape:\", X_test_imdb_bow.shape)\n",
        "\n",
        "# We typically need a dense representation for Keras input\n",
        "X_train_imdb_bow = X_train_imdb_bow.toarray()\n",
        "X_test_imdb_bow  = X_test_imdb_bow.toarray()\n",
        "\n",
        "print(\"Converted to dense arrays, shape:\", X_train_imdb_bow.shape)"
      ],
      "metadata": {
        "id": "h69c6LEaxqsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:  \n",
        "- Using `.toarray()` can be **memory-intensive** for large feature sets and data sizes. Some solutions keep a sparse format, but Keras doesn’t natively handle sparse input.  \n",
        "- If your system is memory-limited, consider using a smaller `max_features` or a partial training approach."
      ],
      "metadata": {
        "id": "trn7RjTs1Kll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Build the SLP (Sigmoid for Binary Classification)"
      ],
      "metadata": {
        "id": "3G5-cLDpruC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_imdb = keras.Sequential([\n",
        "    layers.Dense(1, activation='sigmoid', input_shape=(X_train_imdb_bow.shape[1],))\n",
        "])\n",
        "\n",
        "model_imdb.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_imdb.summary()"
      ],
      "metadata": {
        "id": "zqAqtQolrzLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Train & Evaluate"
      ],
      "metadata": {
        "id": "PyJwDEiCsfSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_imdb = model_imdb.fit(\n",
        "    X_train_imdb_bow, y_train_imdb,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss_imdb, test_acc_imdb = model_imdb.evaluate(X_test_imdb_bow, y_test_imdb, verbose=0)\n",
        "print(f\"\\nIMDB Test Loss: {test_loss_imdb:.4f}\")\n",
        "print(f\"IMDB Test Accuracy: {test_acc_imdb:.4f}\")"
      ],
      "metadata": {
        "id": "3BWx5R151aEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Training Curves"
      ],
      "metadata": {
        "id": "hmg5cHMk1geB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_imdb.history['loss'], label='Train Loss')\n",
        "plt.plot(history_imdb.history['val_loss'], label='Val Loss')\n",
        "plt.title(\"IMDB - Loss (TF-IDF)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_imdb.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_imdb.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title(\"IMDB - Accuracy (TF-IDF)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w0jfvzHv1jBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix & Classification Report"
      ],
      "metadata": {
        "id": "F0LffZl21ozs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_imdb_probs = model_imdb.predict(X_test_imdb_bow)\n",
        "y_pred_imdb = (y_pred_imdb_probs > 0.5).astype(int).ravel()\n",
        "\n",
        "cm_imdb = confusion_matrix(y_test_imdb, y_pred_imdb)\n",
        "print(\"\\nIMDB Confusion Matrix:\\n\", cm_imdb)\n",
        "\n",
        "print(\"\\nIMDB Classification Report:\\n\", classification_report(y_test_imdb, y_pred_imdb))"
      ],
      "metadata": {
        "id": "TVolV3ap1mKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. CIFAR-10 (Multi-Class Classification) + Weight Visualization\n",
        "\n",
        "Now, we move to **CIFAR-10**, which has 10 classes of 32×32 color images.  \n",
        "1. Load & flatten each image to 3,072 features.  \n",
        "2. Build an SLP with 10 outputs (softmax).  \n",
        "3. Train & Evaluate.  \n",
        "4. **Weight Visualization**: each of the 10 class neurons has 3,072 weights, which we reshape to (32,32,3) to see the “pattern.”\n",
        "\n",
        "**Note**: Performance is generally low (~25–30% accuracy) for an SLP on CIFAR-10, because it’s a purely linear model with no hidden layers.\n"
      ],
      "metadata": {
        "id": "lyPQx1hysr3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 LOAD & FLATTEN CIFAR-10"
      ],
      "metadata": {
        "id": "Sq7QgzXByJr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.1 LOAD & FLATTEN CIFAR-10\n",
        "###########################################################\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = cifar10.load_data()\n",
        "\n",
        "print(\"CIFAR Train shape:\", X_train_cifar.shape)    # (50000, 32, 32, 3)\n",
        "print(\"CIFAR Train labels shape:\", y_train_cifar.shape)  # (50000, 1)\n",
        "print(\"CIFAR Test shape:\", X_test_cifar.shape)      # (10000, 32, 32, 3)\n",
        "print(\"CIFAR Test labels shape:\", y_test_cifar.shape)    # (10000, 1)\n",
        "\n",
        "# Flatten label arrays\n",
        "y_train_cifar = y_train_cifar.ravel()\n",
        "y_test_cifar  = y_test_cifar.ravel()\n",
        "print(\"Unique classes:\", np.unique(y_train_cifar))\n",
        "\n",
        "# Let's show some images\n",
        "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "plt.figure(figsize=(10,2))\n",
        "for i in range(5):\n",
        "    plt.subplot(1,5,i+1)\n",
        "    plt.imshow(X_train_cifar[i])\n",
        "    plt.title(class_names[y_train_cifar[i]])\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# SCALE & FLATTEN\n",
        "X_train_cifar = X_train_cifar / 255.0\n",
        "X_test_cifar  = X_test_cifar  / 255.0\n",
        "\n",
        "num_pixels = 32*32*3  # 3072\n",
        "X_train_cifar_flat = X_train_cifar.reshape(-1, num_pixels)\n",
        "X_test_cifar_flat  = X_test_cifar.reshape(-1, num_pixels)\n",
        "\n",
        "print(\"Train flattened shape:\", X_train_cifar_flat.shape)\n",
        "print(\"Test flattened shape:\", X_test_cifar_flat.shape)\n"
      ],
      "metadata": {
        "id": "rV9FXpIDr0nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 BUILD & TRAIN SLP (SOFTMAX)"
      ],
      "metadata": {
        "id": "6mm3H1HSs1h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.2 BUILD & TRAIN SLP (SOFTMAX)\n",
        "###########################################################\n",
        "model_cifar = keras.Sequential([\n",
        "    layers.Dense(10, activation='softmax', input_shape=(num_pixels,))\n",
        "])\n",
        "\n",
        "model_cifar.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_cifar.summary()\n",
        "\n",
        "history_cifar = model_cifar.fit(\n",
        "    X_train_cifar_flat,\n",
        "    y_train_cifar,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "KUVt9uixyf-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.3 EVALUATE CIFAR-10 SLP"
      ],
      "metadata": {
        "id": "cztAMUvHyj85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# 2.3 EVALUATE CIFAR-10 SLP\n",
        "###########################################################\n",
        "test_loss_cifar, test_acc_cifar = model_cifar.evaluate(X_test_cifar_flat, y_test_cifar)\n",
        "print(f\"\\nCIFAR-10 - Test Loss: {test_loss_cifar:.4f}\")\n",
        "print(f\"CIFAR-10 - Test Accuracy: {test_acc_cifar:.4f}\")\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_cifar.history['loss'], label='Train Loss')\n",
        "plt.plot(history_cifar.history['val_loss'], label='Val Loss')\n",
        "plt.title(\"CIFAR-10 SLP - Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_cifar.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history_cifar.history['val_accuracy'], label='Val Acc')\n",
        "plt.title(\"CIFAR-10 SLP - Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix & Classification Report\n",
        "y_pred_cifar_probs = model_cifar.predict(X_test_cifar_flat)\n",
        "y_pred_cifar = np.argmax(y_pred_cifar_probs, axis=1)\n",
        "\n",
        "cm_cifar = confusion_matrix(y_test_cifar, y_pred_cifar)\n",
        "print(\"CIFAR-10 Confusion Matrix:\\n\", cm_cifar)\n",
        "\n",
        "print(\"\\nCIFAR-10 Classification Report:\\n\",\n",
        "      classification_report(y_test_cifar, y_pred_cifar, target_names=class_names))\n"
      ],
      "metadata": {
        "id": "iuqHr6wtyisP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Weight Visualization\n",
        "\n",
        "Now, we visualize the weights for each of the 10 output neurons.\n",
        "\n",
        "**Process**:\n",
        "1. Extract the weight matrix: shape = (3072, 10).  \n",
        "2. For each class neuron, reshape the 3072 weights into (32, 32, 3).  \n",
        "3. Plot each reshaped array as an “image.”  \n",
        "\n",
        "**Caveat**:  \n",
        "- The pixel-scale might be negative or large. We might apply some normalization or offset.  \n",
        "- The pattern can be noisy because a single linear layer tries to separate complex images.\n",
        "\n",
        "We’ll do a direct plot for demonstration.\n",
        "python\n",
        "Copy code\n"
      ],
      "metadata": {
        "id": "8VYwW-bNypCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_cifar = model_cifar.get_weights()[0]  # shape (3072, 10)\n",
        "biases_cifar  = model_cifar.get_weights()[1]  # shape (10,)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "for i in range(10):\n",
        "    # Extract weights for class i\n",
        "    w_i = weights_cifar[:, i]  # shape: (3072,)\n",
        "    # Reshape to (32,32,3)\n",
        "    w_i_3d = w_i.reshape(32, 32, 3)\n",
        "\n",
        "    # We'll normalize to 0..1 for better visualization\n",
        "    # (This is optional, purely for display)\n",
        "    min_val = w_i_3d.min()\n",
        "    max_val = w_i_3d.max()\n",
        "    w_i_3d_norm = (w_i_3d - min_val) / (max_val - min_val + 1e-9)\n",
        "\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(w_i_3d_norm)\n",
        "    plt.title(f\"Class {i}: {class_names[i]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FhcyyS4nynmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation\n",
        "Each “image” is a visualization of how the single-layer perceptron weights each pixel channel for a specific class.\n",
        "- Bright (or darker) regions might indicate the SLP has assigned higher (or lower) weight.\n",
        "- Since it’s a purely linear model, these weight maps can be quite noisy and not very “intuitive,” but it’s still a neat look under the hood of a single-layer approach!\n"
      ],
      "metadata": {
        "id": "FPUP5R1yyubu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 (Optional) Hyperparameter Tuning (CIFAR-10)\n",
        "\n",
        "We can similarly adjust learning rate, epochs, or batch size. The single-layer limitation means we might not see a huge jump in accuracy, but it’s still instructive to try.\n"
      ],
      "metadata": {
        "id": "_1qFqyzzyxRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model_cifar_tuned = keras.Sequential([\n",
        "    layers.Dense(10, activation='softmax', input_shape=(num_pixels,))\n",
        "])\n",
        "model_cifar_tuned.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_cifar_tuned = model_cifar_tuned.fit(\n",
        "    X_train_cifar_flat, y_train_cifar,\n",
        "    validation_split=0.2,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss_ct, test_acc_ct = model_cifar_tuned.evaluate(X_test_cifar_flat, y_test_cifar)\n",
        "print(f\"Tuned CIFAR-10 Loss: {test_loss_ct:.4f}\")\n",
        "print(f\"Tuned CIFAR-10 Accuracy: {test_acc_ct:.4f}\")\n"
      ],
      "metadata": {
        "id": "3aa5nP_tys6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 (Optional) Saving & Loading (CIFAR SLP)\n",
        "\n",
        "Finally, we can save our model for later use or analysis.\n"
      ],
      "metadata": {
        "id": "YzRGGH8ky1yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "model_cifar.save(\"slp_cifar.h5\")\n",
        "print(\"SLP CIFAR model saved as slp_cifar.h5\")\n",
        "\n",
        "# Load\n",
        "loaded_model_cifar = keras.models.load_model(\"slp_cifar.h5\")\n",
        "loaded_loss_cifar, loaded_acc_cifar = loaded_model_cifar.evaluate(X_test_cifar_flat, y_test_cifar, verbose=0)\n",
        "print(f\"Loaded CIFAR model - Test Accuracy: {loaded_acc_cifar:.4f}\")\n"
      ],
      "metadata": {
        "id": "XfLEtQUny0oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Wrap-Up**\n",
        "\n",
        "1. **IMDB**:  \n",
        "   - Binary classification with a single-layer perceptron using **multi-hot** vectors of top 10k words.  \n",
        "   - Performance is moderate compared to advanced text models (embeddings, RNNs, or Transformers).\n",
        "\n",
        "2. **CIFAR-10**:  \n",
        "   - Flattened images to (32×32×3 = 3072) features.  \n",
        "   - Single-layer perceptron with 10 outputs is typically insufficient for complex image data => ~25-30% accuracy.  \n",
        "   - Weight visualization shows how each class neuron is assigning positive/negative importance to each pixel channel in a purely linear way.\n",
        "\n",
        "3. **Hyperparameter Tuning**:  \n",
        "   - Adjusting learning rate, epochs, or batch size can yield small improvements.  \n",
        "   - Real breakthroughs often need deeper networks or specialized architectures (e.g., CNNs for images, embeddings/RNNs for text).\n",
        "\n",
        "4. **Saving & Loading**:  \n",
        "   - Demonstrated how to persist models to `.h5` files and reload them for inference or sharing.\n",
        "\n",
        "**Next Steps**:\n",
        "- Add **hidden layers** to create a **multi-layer perceptron** and see how accuracy changes.  \n",
        "- Use advanced architectures (CNNs, RNNs, or Transformers) for these tasks to get better performance.  \n",
        "- Experiment with **callbacks** (EarlyStopping, etc.), or different initializations, or advanced regularization techniques.\n"
      ],
      "metadata": {
        "id": "y-7DOtmIy94U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJpeI7m-y7JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ajN1FTszy8tv"
      }
    }
  ]
}
