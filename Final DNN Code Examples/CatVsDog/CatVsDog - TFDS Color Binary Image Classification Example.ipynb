{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Final%20DNN%20Code%20Examples/CatVsDog/CatVsDog%20-%20TFDS%20Color%20Binary%20Image%20Classification%20Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# CatVsDog - TFDS Colour Binary Image Classification Example\n",
    "\n",
    "This notebook demonstrates the **Universal ML Workflow** for binary image classification using TensorFlow Datasets.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Load image datasets from TensorFlow Datasets\n",
    "- Apply binary classification to image data\n",
    "- Preprocess colour images: Resize → Grayscale → Flatten → Normalise\n",
    "- Compare binary image classification with multi-class approaches\n",
    "\n",
    "---\n",
    "\n",
    "## Technique Scope\n",
    "\n",
    "| Aspect | What We Use | What We Don't Use (Yet) |\n",
    "|--------|-------------|------------------------|\n",
    "| **Architecture** | Dense layers only | CNNs, pooling, feature extractors |\n",
    "| **Regularisation** | L2 + Dropout | Early stopping, data augmentation |\n",
    "| **Optimiser** | Adam | SGD with momentum, learning rate schedules |\n",
    "| **Tuning** | Hyperband | Bayesian optimisation, neural architecture search |\n",
    "\n",
    "> **Note**: Dense networks applied to flattened images serve as a baseline. CNNs (Chapter 8) are the standard approach for image classification and would significantly improve performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "| Attribute | Description |\n",
    "|-----------|-------------|\n",
    "| **Source** | [TensorFlow Datasets - cats_vs_dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) |\n",
    "| **Problem Type** | Binary Classification (Cat vs Dog) |\n",
    "| **Data Balance** | Nearly Balanced (~50:50) |\n",
    "| **Total Images** | ~23,000 images |\n",
    "| **Preprocessing** | Resize to 16×16 → Grayscale → Flatten (256 features) |\n",
    "\n",
    "### Binary Image Classification vs Multi-class\n",
    "\n",
    "| Aspect | Binary (CatVsDog) | Multi-class (Fashion MNIST) |\n",
    "|--------|-------------------|----------------------------|\n",
    "| **Output Layer** | 1 neuron, sigmoid | K neurons, softmax |\n",
    "| **Loss Function** | binary_crossentropy | categorical_crossentropy |\n",
    "| **Prediction** | Threshold at 0.5 | argmax of probabilities |\n",
    "| **Primary Metric** | Accuracy (balanced) | Accuracy |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Reuse Philosophy\n",
    "\n",
    "This notebook follows a **\"Same Code, Different Data\"** philosophy. The core ML pipeline remains consistent across different classification tasks:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                    UNIVERSAL ML PIPELINE                        │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│  Data Loading → Preprocessing → Train/Val/Test Split → Model   │\n",
    "│  → Baseline → Overfitting → Regularisation → Evaluation        │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**What changes:** Data source, preprocessing, output configuration  \n",
    "**What stays the same:** Model architecture pattern, training loop, evaluation code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the Problem and Assembling a Dataset\n",
    "\n",
    "**Problem:** Classify images as either cats or dogs - a classic binary image classification task.\n",
    "\n",
    "**Why this dataset?** Cats vs. Dogs is one of the most well-known binary image classification benchmarks. It's challenging because:\n",
    "- High intra-class variation (many breeds, poses, backgrounds)\n",
    "- Requires distinguishing subtle features between two similar-looking animals\n",
    "- Real-world photographs with varying quality and composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing a Measure of Success\n",
    "\n",
    "### Data-Driven Metric Selection\n",
    "\n",
    "| Criterion | This Dataset | Decision |\n",
    "|-----------|--------------|----------|\n",
    "| **Class Balance** | ~50:50 (Cat:Dog) | Balanced |\n",
    "| **Imbalance Ratio** | ~1:1 | < 3:1 threshold |\n",
    "| **Primary Metric** | Accuracy | Standard for balanced data |\n",
    "| **Secondary Metrics** | Precision, Recall, AUC | Additional insight |\n",
    "\n",
    "**Decision:** Since the dataset is balanced, **Accuracy** is an appropriate primary metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deciding on an Evaluation Protocol\n",
    "\n",
    "### Data-Driven Protocol Selection\n",
    "\n",
    "| Criterion | This Dataset | Decision |\n",
    "|-----------|--------------|----------|\n",
    "| **Sample Size** | ~23,000 images | Large |\n",
    "| **Threshold** | > 10,000 | Use Hold-Out |\n",
    "| **Protocol** | Train/Validation/Test | 80%/10%/10% split |\n",
    "\n",
    "**Decision:** With ~23,000 samples, **Hold-Out validation** is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing Your Data\n",
    "\n",
    "### 4.1 Import Libraries and Load TFDS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Keras Tuner for hyperparameter search\n",
    "%pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# RANDOM SEED - Set once, use everywhere\n",
    "# ============================================================\n",
    "SEED = 204\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET CONFIGURATION\n",
    "# ============================================================\n",
    "DATASET = 'cats_vs_dogs'\n",
    "RESIZE = (16, 16)  # Smaller size for dense network\n",
    "GRAY_SCALE = True  # Convert to grayscale for simplicity\n",
    "\n",
    "# ============================================================\n",
    "# CLASS NAMES\n",
    "# ============================================================\n",
    "CLASS_NAMES = ['Cat', 'Dog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from TensorFlow Datasets\n",
    "ds = tfds.load(DATASET, split='train', shuffle_files=True)\n",
    "\n",
    "# Process images\n",
    "images, labels = [], []\n",
    "for entry in ds:\n",
    "    image, label = entry['image'].numpy(), entry['label'].numpy()\n",
    "    \n",
    "    # Resize to target size\n",
    "    image = resize(image, (*RESIZE, 3), anti_aliasing=True)\n",
    "    \n",
    "    # Convert to grayscale if specified\n",
    "    if GRAY_SCALE:\n",
    "        image = rgb2gray(image)\n",
    "    \n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Flatten images: (N, 16, 16) -> (N, 256)\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Verify Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "class_dist = dict(zip([CLASS_NAMES[i] for i in unique], counts))\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "for class_name, count in class_dist.items():\n",
    "    print(f\"  {class_name}: {count} ({100*count/len(y):.1f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "imbalance_ratio = max(counts) / min(counts)\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Decision: {'Use Accuracy (balanced)' if imbalance_ratio < 3 else 'Use F1-Score (imbalanced)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN/TEST SPLIT (90%/10%)\n",
    "# ============================================================\n",
    "TEST_SIZE = 0.10\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=y,\n",
    "    random_state=SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training + Validation: {X_train_full.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Normalise Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NORMALISE PIXEL VALUES [0, 1]\n",
    "# ============================================================\n",
    "# Note: skimage resize already normalises to [0, 1], but we ensure it\n",
    "X_train_full = X_train_full.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Verify normalisation\n",
    "print(f\"Feature range: [{X_train_full.min():.3f}, {X_train_full.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN/VALIDATION SPLIT\n",
    "# ============================================================\n",
    "# Use same number of samples for validation as test\n",
    "VALIDATION_SIZE = X_test.shape[0]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full,\n",
    "    test_size=VALIDATION_SIZE,\n",
    "    stratify=y_train_full,\n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Visualise Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle('Sample Images (16×16 Grayscale)', fontsize=14)\n",
    "\n",
    "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
    "    # Get indices for this class\n",
    "    class_indices = np.where(y_train == class_idx)[0][:5]\n",
    "    \n",
    "    for i, idx in enumerate(class_indices):\n",
    "        ax = axes[class_idx, i]\n",
    "        # Reshape flattened image back to 2D\n",
    "        img = X_train[idx].reshape(RESIZE)\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(class_name, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Developing a Model That Does Better Than a Baseline\n",
    "\n",
    "**Baseline for balanced binary classification:** 50% accuracy (random guessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL CONFIGURATION\n",
    "# ============================================================\n",
    "INPUT_DIMENSION = X_train.shape[1]  # 256 features (16x16)\n",
    "OUTPUT_DIMENSION = 1  # Binary classification\n",
    "\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS_FUNC = 'binary_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "# Training configuration\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS_BASELINE = 100\n",
    "EPOCHS_REGULARIZED = 150\n",
    "\n",
    "print(f\"Input Dimension: {INPUT_DIMENSION}\")\n",
    "print(f\"Output Dimension: {OUTPUT_DIMENSION}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ESTABLISH BASELINE\n",
    "# ============================================================\n",
    "# For balanced binary classification, random guessing = 50%\n",
    "baseline_accuracy = 0.5\n",
    "\n",
    "print(f\"Baseline Accuracy (random guessing): {baseline_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLASS WEIGHTS (for balanced training)\n",
    "# ============================================================\n",
    "weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "CLASS_WEIGHTS = dict(enumerate(weights))\n",
    "\n",
    "print(\"Class Weights:\")\n",
    "for class_idx, weight in CLASS_WEIGHTS.items():\n",
    "    print(f\"  {CLASS_NAMES[class_idx]}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SINGLE LAYER PERCEPTRON (SLP) - Simplest possible model\n",
    "# ============================================================\n",
    "slp_model = Sequential(name='Single_Layer_Perceptron')\n",
    "slp_model.add(Dense(OUTPUT_DIMENSION, activation='sigmoid', input_shape=(INPUT_DIMENSION,)))\n",
    "slp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n",
    "\n",
    "slp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SLP\n",
    "slp_history = slp_model.fit(\n",
    "    X_train, y_train,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS_BASELINE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "slp_val_acc = slp_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"SLP Validation Accuracy: {slp_val_acc:.4f} (baseline: {baseline_accuracy:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT TRAINING HISTORY\n",
    "# ============================================================\n",
    "def plot_training_history(history, title='Training History'):\n",
    "    \"\"\"Plot training and validation loss/accuracy curves.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], 'b-', label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], 'r-', label='Validation Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], 'b-', label='Training Accuracy')\n",
    "    axes[1].plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(slp_history, 'Single Layer Perceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scaling Up: Developing a Model That Overfits\n",
    "\n",
    "Adding a hidden layer to learn more complex features for distinguishing cats from dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MULTI-LAYER PERCEPTRON (MLP) - Standard architecture\n",
    "# ============================================================\n",
    "HIDDEN_NEURONS = 64\n",
    "\n",
    "mlp_model = Sequential(name='Multi_Layer_Perceptron')\n",
    "mlp_model.add(Dense(HIDDEN_NEURONS, activation='relu', input_shape=(INPUT_DIMENSION,)))\n",
    "mlp_model.add(Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n",
    "mlp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP\n",
    "mlp_history = mlp_model.fit(\n",
    "    X_train, y_train,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS_BASELINE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "mlp_val_acc = mlp_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"MLP Validation Accuracy: {mlp_val_acc:.4f} (baseline: {baseline_accuracy:.2f})\")\n",
    "print(f\"Improvement over SLP: {(mlp_val_acc - slp_val_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(mlp_history, 'Multi-Layer Perceptron (1 Hidden Layer)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regularising Your Model and Tuning Hyperparameters\n",
    "\n",
    "Using **Hyperband** for efficient hyperparameter tuning with L2 regularisation and Dropout.\n",
    "\n",
    "### Why Hyperband?\n",
    "\n",
    "**Hyperband** is more efficient than grid search because it:\n",
    "1. Starts training many configurations for a few epochs\n",
    "2. Eliminates poor performers early\n",
    "3. Allocates more resources to promising configurations\n",
    "\n",
    "### Regularisation Strategy\n",
    "\n",
    "| Technique | Purpose | How It Works |\n",
    "|-----------|---------|-------------|\n",
    "| **L2 Regularisation** | Prevent large weights | Adds penalty term to loss |\n",
    "| **Dropout** | Prevent co-adaptation | Randomly zeros neurons during training |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HYPERBAND MODEL BUILDER\n",
    "# ============================================================\n",
    "def build_model_hyperband(hp):\n",
    "    \"\"\"\n",
    "    Build CatVsDog model with FROZEN architecture (1 hidden layer, 64 neurons).\n",
    "    Tunes: L2 regularisation, Dropout rate, Learning rate.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(INPUT_DIMENSION,)))\n",
    "    \n",
    "    # Hyperparameters to tune\n",
    "    l2_reg = hp.Float('l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    # Hidden layer with L2 regularisation\n",
    "    model.add(layers.Dense(\n",
    "        HIDDEN_NEURONS,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    ))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=LOSS_FUNC,\n",
    "        metrics=METRICS\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURE AND RUN HYPERBAND TUNER\n",
    "# ============================================================\n",
    "tuner = kt.Hyperband(\n",
    "    build_model_hyperband,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='catvsdog_hyperband',\n",
    "    project_name='catvsdog_tuning',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Run search\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GET BEST HYPERPARAMETERS\n",
    "# ============================================================\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(f\"  L2 Regularisation: {best_hp.get('l2_reg'):.6f}\")\n",
    "print(f\"  Dropout Rate: {best_hp.get('dropout_rate'):.2f}\")\n",
    "print(f\"  Learning Rate: {best_hp.get('learning_rate'):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD AND TRAIN BEST MODEL\n",
    "# ============================================================\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model with more epochs\n",
    "best_history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS_REGULARIZED,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=CLASS_WEIGHTS,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "best_val_acc = best_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(f\"Best Model Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Improvement over MLP: {(best_val_acc - mlp_val_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(best_history, 'Regularised Model (L2 + Dropout)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Evaluation\n",
    "\n",
    "Evaluate the best model on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TEST SET EVALUATION\n",
    "# ============================================================\n",
    "# Get predictions\n",
    "y_pred_proba = best_model.predict(X_test, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype('int32').flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"FINAL TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {test_accuracy:.4f} (baseline: {baseline_accuracy:.2f})\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall:    {test_recall:.4f}\")\n",
    "print(f\"AUC:       {test_auc:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================================\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# Print detailed breakdown\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"  True Cats correctly classified: {cm[0,0]}\")\n",
    "print(f\"  True Dogs correctly classified: {cm[1,1]}\")\n",
    "print(f\"  Cats misclassified as Dogs: {cm[0,1]}\")\n",
    "print(f\"  Dogs misclassified as Cats: {cm[1,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL COMPARISON\n",
    "# ============================================================\n",
    "print(\"\\nModel Comparison (Validation Accuracy):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Model':<30} {'Accuracy':>10}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Baseline (random)':<30} {baseline_accuracy:>10.4f}\")\n",
    "print(f\"{'Single Layer Perceptron':<30} {slp_val_acc:>10.4f}\")\n",
    "print(f\"{'Multi-Layer Perceptron':<30} {mlp_val_acc:>10.4f}\")\n",
    "print(f\"{'Regularised (L2 + Dropout)':<30} {best_val_acc:>10.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Binary Image Classification:** Uses sigmoid output with a single neuron and binary cross-entropy loss\n",
    "\n",
    "2. **Preprocessing Pipeline:** Resize → Grayscale → Flatten → Normalise converts images to vectors for dense networks\n",
    "\n",
    "3. **Balanced Data:** With ~50:50 class distribution, accuracy is an appropriate metric\n",
    "\n",
    "4. **Dense Network Limitations:** DNNs struggle with complex image features - CNNs would significantly improve performance\n",
    "\n",
    "5. **Regularisation Helps:** L2 + Dropout reduces overfitting and improves generalisation\n",
    "\n",
    "### Next Steps for Better Performance\n",
    "\n",
    "- **Use CNNs** (Chapter 8) - preserves spatial structure\n",
    "- **Data augmentation** - artificially increase training data\n",
    "- **Transfer learning** - use pre-trained models (VGG, ResNet)\n",
    "- **Higher resolution** - more detail, but requires more compute"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
