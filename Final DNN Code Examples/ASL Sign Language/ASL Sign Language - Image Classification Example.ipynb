{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eL2poACo9Lf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Final%20DNN%20Code%20Examples/ASL%20Sign%20Language/ASL%20Sign%20Language%20-%20Image%20Classification%20Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# ASL Sign Language - Image Classification Example\n",
        "\n",
        "This notebook demonstrates the **Universal ML Workflow** applied to image classification using American Sign Language (ASL) hand gesture images.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "- Load and extract image data from a zip archive\n",
        "- Preprocess images for neural network input: **Colour → Grayscale → Flatten**\n",
        "- Build neural networks for multi-class **image classification**\n",
        "- Apply the Universal ML Workflow to computer vision problems\n",
        "- Evaluate classification performance with accuracy and confusion matrices\n",
        "\n",
        "---\n",
        "\n",
        "## Technique Scope\n",
        "\n",
        "| Aspect | What We Use | What We Don't Use (Yet) |\n",
        "|--------|-------------|------------------------|\n",
        "| **Architecture** | Dense layers only | CNNs, pooling, feature extractors |\n",
        "| **Regularisation** | L2 + Dropout | Early stopping, data augmentation |\n",
        "| **Optimiser** | Adam | SGD with momentum, learning rate schedules |\n",
        "| **Tuning** | Hyperband | Bayesian optimisation, neural architecture search |\n",
        "\n",
        "> **Note**: Dense networks applied to flattened images serve as a baseline. CNNs (Chapter 8) are the standard approach for image classification and would preserve spatial structure.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Overview\n",
        "\n",
        "| Attribute | Description |\n",
        "|-----------|-------------|\n",
        "| **Source** | ASL Sign Language Dataset (3 classes: A, B, C) |\n",
        "| **Problem Type** | Multi-Class Classification |\n",
        "| **Data Balance** | Perfectly Balanced (3,000 samples per class) |\n",
        "| **Data Type** | Unstructured (Images) |\n",
        "| **Preprocessing** | Resize to 32×32 → Grayscale → Flatten (1024 features) |\n",
        "\n",
        "### Image Preprocessing Pipeline\n",
        "\n",
        "```\n",
        "Original Image        Grayscale          Flattened\n",
        "[H x W x 3]    →    [32 x 32]    →    [1024]\n",
        "(Colour RGB)        (Single channel)   (1D array for NN)\n",
        "```\n",
        "\n",
        "**Why flatten?** Dense neural networks expect 1D input vectors. We sacrifice spatial relationships for simplicity. (CNNs preserve spatial structure but are covered in Chapter 8.)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sbOWB8fo9Lj"
      },
      "source": [
        "## Code Reuse Philosophy\n",
        "\n",
        "This notebook follows a **\"Same Code, Different Data\"** philosophy. The core ML pipeline remains consistent across different classification tasks:\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────────┐\n",
        "│                    UNIVERSAL ML PIPELINE                        │\n",
        "├─────────────────────────────────────────────────────────────────┤\n",
        "│  Data Loading → Preprocessing → Train/Val/Test Split → Model   │\n",
        "│  → Baseline → Overfitting → Regularisation → Evaluation        │\n",
        "└─────────────────────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "**What changes:** Data source, preprocessing, number of output classes  \n",
        "**What stays the same:** Model architecture pattern, training loop, evaluation code\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yJ4uw2o9Lj"
      },
      "source": [
        "## 1. Defining the Problem and Assembling a Dataset\n",
        "\n",
        "**Problem Statement:** Classify images of hand gestures into ASL letters (A, B, or C).\n",
        "\n",
        "**Why this matters:**\n",
        "- ASL recognition can help bridge communication gaps\n",
        "- Image classification is foundational to computer vision\n",
        "- This simplified 3-class problem demonstrates key concepts before tackling the full 26-letter alphabet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nkcOJako9Lj"
      },
      "source": [
        "## 2. Choosing a Measure of Success\n",
        "\n",
        "### Data-Driven Metric Selection\n",
        "\n",
        "| Criterion | This Dataset | Decision |\n",
        "|-----------|--------------|----------|\n",
        "| **Class Balance** | Equal across 3 classes | Balanced |\n",
        "| **Number of Classes** | 3 (A, B, C) | Multi-class |\n",
        "| **Primary Metric** | Accuracy | Standard for balanced multi-class |\n",
        "| **Secondary Metrics** | Precision, Recall, AUC | Per-class performance |\n",
        "\n",
        "**Why these thresholds?**\n",
        "- **Balanced data (< 3:1 ratio):** When classes are roughly equal, accuracy is meaningful and interpretable\n",
        "- **Imbalanced data (> 3:1 ratio):** Accuracy becomes misleading; F1-Score provides a fairer evaluation\n",
        "\n",
        "### References\n",
        "\n",
        "- Branco, P., Torgo, L. and Ribeiro, R.P. (2016) 'A survey of predictive modelling on imbalanced domains', *ACM Computing Surveys*, 49(2), pp. 1–50.\n",
        "\n",
        "- He, H. and Garcia, E.A. (2009) 'Learning from imbalanced data', *IEEE Transactions on Knowledge and Data Engineering*, 21(9), pp. 1263–1284.\n",
        "\n",
        "**Decision:** Since the dataset is balanced, **Accuracy** is the primary metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHd_YTKko9Lj"
      },
      "source": [
        "## 3. Deciding on an Evaluation Protocol\n",
        "\n",
        "### Data-Driven Protocol Selection\n",
        "\n",
        "The choice between hold-out validation and k-fold cross-validation is a trade-off between estimate stability and computational cost. For model selection, k-fold cross-validation is widely used because it averages performance over multiple splits; Kohavi (1995) reports stratified 10-fold cross-validation as a strong general default for model selection. However, k-fold cross-validation requires training the model k times, which can be computationally expensive, especially for larger datasets and heavier models.\n",
        "\n",
        "| Situation        | Recommended method                                   | Rationale |\n",
        "|-----------------|--------------------------------------------------------|-----------|\n",
        "| Smaller datasets | Stratified k-fold cross-validation (commonly 5 or 10 folds) | A single hold-out split may be unstable when the validation set is small; averaging across folds typically provides a more reliable model-selection signal. |\n",
        "| Larger datasets  | Hold-out validation + separate test set                | With sufficient data, a single validation split is often adequate while avoiding the k× training cost of k-fold; a held-out test set supports final unbiased reporting. |\n",
        "\n",
        "\n",
        "*Note:* This table summarises a rule-of-thumb stability–cost trade-off rather than fixed numeric cut-offs.\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "- Chollet, F. (2021) *Deep learning with Python*. 2nd edn. Shelter Island, NY: Manning Publications.\n",
        "\n",
        "- Kohavi, R. (1995) 'A study of cross-validation and bootstrap for accuracy estimation and model selection', *Proceedings of the 14th International Joint Conference on Artificial Intelligence*, 2, pp. 1137–1145.\n",
        "\n",
        "### References\n",
        "\n",
        "- Chollet, F. (2021) *Deep learning with Python*. 2nd edn. Shelter Island, NY: Manning Publications.\n",
        "\n",
        "- Hastie, T., Tibshirani, R. and Friedman, J. (2009) *The elements of statistical learning: data mining, inference, and prediction*. 2nd edn. New York: Springer.\n",
        "\n",
        "- Kohavi, R. (1995) 'A study of cross-validation and bootstrap for accuracy estimation and model selection', *Proceedings of the 14th International Joint Conference on Artificial Intelligence*, 2, pp. 1137–1145.\n",
        "\n",
        "**Decision:** With ~9,000 samples (below the 10,000 threshold), **K-Fold Cross-Validation** provides more robust performance estimates.\n",
        "\n",
        "```\n",
        "Original Data (~9,000 samples)\n",
        "├── Test Set (10% = ~900 samples) - Final evaluation only\n",
        "└── Training Pool (90% = ~8,100 samples)\n",
        "    └── 5-Fold Stratified Cross-Validation\n",
        "        ├── Fold 1: Train on folds 2-5, validate on fold 1\n",
        "        ├── Fold 2: Train on folds 1,3-5, validate on fold 2\n",
        "        ├── ...\n",
        "        └── Fold 5: Train on folds 1-4, validate on fold 5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkCOh9oMo9Lk"
      },
      "source": [
        "## 4. Preparing Your Data\n",
        "\n",
        "### 4.1 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3KPOerYo9Lk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Keras Tuner for hyperparameter search\n",
        "%pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# RANDOM SEED - Set once, use everywhere\n",
        "# ============================================================\n",
        "SEED = 204\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsSetav7o9Ll"
      },
      "source": [
        "### 4.2 Download and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuTw6aj0o9Ll"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# DATASET CONFIGURATION\n",
        "# ============================================================\n",
        "GDRIVE_FILE_ID = '1Df0wlpvKUSD12RAYihBI-slI1zbz-Vjj'\n",
        "DATA_URL = f'https://drive.google.com/uc?id={GDRIVE_FILE_ID}&export=download'\n",
        "ZIP_FILE = 'asl.zip'\n",
        "EXTRACT_DIR = 'asl'\n",
        "\n",
        "# Image configuration\n",
        "RESIZE = (32, 32)  # Resize to 32x32 - balance between preserving detail and dimensionality\n",
        "SAMPLE_SIZE = 3000  # Max samples per class\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = ['A', 'B', 'C']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqfdXSAEo9Ll"
      },
      "outputs": [],
      "source": [
        "# Download dataset from Google Drive\n",
        "import gdown\n",
        "\n",
        "if not os.path.exists(ZIP_FILE):\n",
        "    print(f\"Downloading ASL dataset from Google Drive...\")\n",
        "    gdown.download(DATA_URL, ZIP_FILE, quiet=False)\n",
        "else:\n",
        "    print(f\"Dataset already downloaded: {ZIP_FILE}\")\n",
        "\n",
        "# Extract the zip file\n",
        "if not os.path.exists(EXTRACT_DIR):\n",
        "    print(f\"Extracting {ZIP_FILE}...\")\n",
        "    with zipfile.ZipFile(ZIP_FILE, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    print(f\"Extracted to: {EXTRACT_DIR}\")\n",
        "else:\n",
        "    print(f\"Directory already exists: {EXTRACT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJUkGyd5o9Lm"
      },
      "source": [
        "### 4.3 Load and Preprocess Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSxMD6PTo9Lm"
      },
      "outputs": [],
      "source": [
        "def load_image(file_path, target_size=(16, 16), grayscale=True):\n",
        "    \"\"\"\n",
        "    Load and preprocess an image file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to image file\n",
        "        target_size: Target size for resizing (width, height)\n",
        "        grayscale: Convert to grayscale if True\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed image as numpy array\n",
        "    \"\"\"\n",
        "    # Load image using PIL\n",
        "    img = Image.open(file_path)\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Resize using skimage (consistent with other notebooks)\n",
        "    img_resized = resize(img_array, (*target_size, 3), anti_aliasing=True)\n",
        "\n",
        "    # Convert to grayscale if specified\n",
        "    if grayscale:\n",
        "        img_resized = rgb2gray(img_resized)\n",
        "\n",
        "    return img_resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xMr3Si6o9Lm"
      },
      "outputs": [],
      "source": [
        "# Load images from directory structure\n",
        "images, labels = [], []\n",
        "\n",
        "for class_name in CLASS_NAMES:\n",
        "    class_dir = os.path.join(EXTRACT_DIR, class_name)\n",
        "    if not os.path.exists(class_dir):\n",
        "        print(f\"Warning: Directory not found: {class_dir}\")\n",
        "        continue\n",
        "\n",
        "    files = os.listdir(class_dir)[:SAMPLE_SIZE]\n",
        "    print(f\"Loading class '{class_name}': {len(files)} images\")\n",
        "\n",
        "    for file in files:\n",
        "        file_path = os.path.join(class_dir, file)\n",
        "        try:\n",
        "            img = load_image(file_path, target_size=RESIZE, grayscale=True)\n",
        "            images.append(img)\n",
        "            labels.append(class_name)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal images loaded: {len(images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoB3pl5Wo9Lm"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy arrays\n",
        "X = np.array(images)\n",
        "y_labels = np.array(labels)\n",
        "\n",
        "# Flatten images: (N, 16, 16) -> (N, 256)\n",
        "X = X.reshape((X.shape[0], -1))\n",
        "\n",
        "# Create label mapping\n",
        "label_to_idx = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
        "y_raw = np.array([label_to_idx[label] for label in y_labels])\n",
        "\n",
        "# One-hot encode labels\n",
        "y = to_categorical(y_raw)\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Number of classes: {y.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIwZW3_fo9Lm"
      },
      "source": [
        "### 4.4 Verify Class Balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzlPWPz5o9Lm"
      },
      "outputs": [],
      "source": [
        "# Check class distribution\n",
        "unique, counts = np.unique(y_raw, return_counts=True)\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "for class_idx, count in zip(unique, counts):\n",
        "    print(f\"  {CLASS_NAMES[class_idx]}: {count} ({100*count/len(y_raw):.1f}%)\")\n",
        "\n",
        "# Calculate imbalance ratio\n",
        "imbalance_ratio = max(counts) / min(counts)\n",
        "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "print(f\"Decision: {'Use Accuracy (balanced)' if imbalance_ratio < 3 else 'Use F1-Score (imbalanced)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg2OTR0co9Lm"
      },
      "source": [
        "### 4.5 Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRcH_kUUo9Lm"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# TRAIN/TEST SPLIT (90%/10%)\n",
        "# ============================================================\n",
        "TEST_SIZE = 0.10\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=y_raw,\n",
        "    random_state=SEED,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Also keep raw labels for test set\n",
        "_, _, y_train_full_raw, y_test_raw = train_test_split(\n",
        "    X, y_raw,\n",
        "    test_size=TEST_SIZE,\n",
        "    stratify=y_raw,\n",
        "    random_state=SEED,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"Training + Validation: {X_train_full.shape[0]} samples\")\n",
        "print(f\"Test: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCAddhHLo9Ln"
      },
      "source": [
        "### 4.6 Normalise Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4SjPCHxo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# NORMALISE PIXEL VALUES [0, 1]\n",
        "# ============================================================\n",
        "# Note: skimage resize already normalises to [0, 1], but we ensure it\n",
        "X_train_full = X_train_full.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Verify normalisation\n",
        "print(f\"Feature range: [{X_train_full.min():.3f}, {X_train_full.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF0xXm3Vo9Ln"
      },
      "source": [
        "### 4.7 Configure K-Fold Cross-Validation\n",
        "\n",
        "Since our dataset has ~9,000 samples (below the 10,000 threshold), we use **5-Fold Stratified Cross-Validation** instead of a simple hold-out validation split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1aWc8XEo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# K-FOLD CROSS-VALIDATION SETUP\n",
        "# ============================================================\n",
        "N_FOLDS = 5\n",
        "\n",
        "# Use StratifiedKFold to preserve class balance in each fold\n",
        "skfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "print(f\"K-Fold Configuration:\")\n",
        "print(f\"  Number of folds: {N_FOLDS}\")\n",
        "print(f\"  Training pool: {X_train_full.shape[0]:,} samples\")\n",
        "print(f\"  Samples per fold: ~{X_train_full.shape[0] // N_FOLDS:,}\")\n",
        "print(f\"  Test set (held out): {X_test.shape[0]:,} samples\")\n",
        "\n",
        "# For initial model development, we use the first fold\n",
        "# Final evaluation will use all folds\n",
        "first_fold = list(skfold.split(X_train_full, y_train_full.argmax(axis=1)))[0]\n",
        "train_idx, val_idx = first_fold\n",
        "\n",
        "X_train = X_train_full[train_idx]\n",
        "X_val = X_train_full[val_idx]\n",
        "y_train = y_train_full[train_idx]\n",
        "y_val = y_train_full[val_idx]\n",
        "\n",
        "# Keep raw labels for train set (for class weights)\n",
        "y_train_raw = y_train.argmax(axis=1)\n",
        "\n",
        "print(f\"\\nFirst fold (for initial development):\")\n",
        "print(f\"  Training: {X_train.shape[0]:,} samples\")\n",
        "print(f\"  Validation: {X_val.shape[0]:,} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjS5OCLPo9Ln"
      },
      "source": [
        "### 4.8 Visualise Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdqQ9TnBo9Ln"
      },
      "outputs": [],
      "source": [
        "# Display sample images from each class\n",
        "fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
        "fig.suptitle('Sample Images (32×32 Grayscale)', fontsize=14)\n",
        "\n",
        "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    # Get first sample of this class\n",
        "    sample_idx = np.where(y_train_raw == class_idx)[0][0]\n",
        "\n",
        "    ax = axes[class_idx]\n",
        "    # Reshape flattened image back to 2D\n",
        "    img = X_train[sample_idx].reshape(RESIZE)\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f\"Letter '{class_name}'\", fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lJc5b8Jo9Ln"
      },
      "source": [
        "## 5. Developing a Model That Does Better Than a Baseline\n",
        "\n",
        "**Baseline for 3-class balanced problem:** 33.3% accuracy (random guessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtLc-HJLo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODEL CONFIGURATION\n",
        "# ============================================================\n",
        "INPUT_DIMENSION = X_train.shape[1]  # 1024 features (32x32)\n",
        "OUTPUT_CLASSES = y_train.shape[1]   # 3 classes\n",
        "\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS_FUNC = 'categorical_crossentropy'\n",
        "METRICS = ['accuracy']\n",
        "\n",
        "# Training configuration\n",
        "# Batch Size Selection:\n",
        "# - Large datasets (>10,000 samples): Use 512 for efficient GPU utilisation\n",
        "# - Small datasets (<10,000 samples): Use 32-64 for better gradient estimates\n",
        "# ASL has ~9,000 samples → Use batch size 64 (below threshold, prioritise gradient quality)\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS_BASELINE = 100\n",
        "EPOCHS_REGULARIZED = 150\n",
        "\n",
        "print(f\"Input Dimension: {INPUT_DIMENSION}\")\n",
        "print(f\"Output Classes: {OUTPUT_CLASSES}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRe8AC8Go9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ESTABLISH BASELINE\n",
        "# ============================================================\n",
        "# For balanced 3-class classification, random guessing = 33.3%\n",
        "baseline_accuracy = 1.0 / OUTPUT_CLASSES\n",
        "\n",
        "print(f\"Baseline Accuracy (random guessing): {baseline_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUf_juZCo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CLASS WEIGHTS - Not needed for balanced dataset\n",
        "# ============================================================\n",
        "# Note: ASL dataset is perfectly balanced (3,000 samples per class)\n",
        "# Class weights are not necessary for balanced datasets.\n",
        "# We keep this cell for consistency with other notebooks and\n",
        "# to demonstrate when class weights would be used.\n",
        "\n",
        "print(\"Class Distribution (balanced - no class weights needed):\")\n",
        "for class_idx, class_name in enumerate(CLASS_NAMES):\n",
        "    count = np.sum(y_train_raw == class_idx)\n",
        "    print(f\"  {class_name}: {count} ({100*count/len(y_train_raw):.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UBZgxVTo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SINGLE LAYER PERCEPTRON (SLP) - Simplest possible model\n",
        "# ============================================================\n",
        "slp_model = Sequential(name='Single_Layer_Perceptron')\n",
        "slp_model.add(Dense(OUTPUT_CLASSES, activation='softmax', input_shape=(INPUT_DIMENSION,)))\n",
        "slp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n",
        "\n",
        "slp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DuHq9Bvo9Ln"
      },
      "outputs": [],
      "source": [
        "# Train SLP\n",
        "slp_history = slp_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS_BASELINE,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "slp_val_acc = slp_model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "print(f\"SLP Validation Accuracy: {slp_val_acc:.4f} (baseline: {baseline_accuracy:.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-PyPBYDo9Ln"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PLOT TRAINING HISTORY\n",
        "# ============================================================\n",
        "def plot_training_history(history, title='Training History'):\n",
        "    \"\"\"Plot training and validation loss/accuracy curves.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(history.history['loss'], 'b-', label='Training Loss')\n",
        "    axes[0].plot(history.history['val_loss'], 'r-', label='Validation Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    axes[1].plot(history.history['accuracy'], 'b-', label='Training Accuracy')\n",
        "    axes[1].plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy')\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(slp_history, 'Single Layer Perceptron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfwauUbdo9Lo"
      },
      "source": [
        "## 6. Scaling Up: Developing a Model That Overfits\n",
        "\n",
        "Adding a hidden layer to learn more complex features for distinguishing hand gestures.\n",
        "\n",
        "**No regularisation applied:** We intentionally train this model **without any regularisation** (no dropout, no L2, no early stopping) to observe overfitting behaviour.\n",
        "\n",
        "---\n",
        "\n",
        "### Architecture Design Decisions\n",
        "\n",
        "**Why 64 neurons in the hidden layer?**\n",
        "\n",
        "This is a practical starting point that balances capacity and efficiency:\n",
        "- **Too few (e.g., 16):** May not have enough capacity to distinguish subtle hand gesture differences\n",
        "- **Too many (e.g., 512):** Increases overfitting risk and training time without proportional benefit\n",
        "- **64 neurons:** A common choice that provides sufficient capacity for most classification tasks\n",
        "\n",
        "**Why only 1 hidden layer instead of 2-3?**\n",
        "\n",
        "Per the **Universal ML Workflow**, the goal of this step is to demonstrate that the model *can* overfit—proving it has sufficient capacity to capture the underlying patterns. Once overfitting is observed:\n",
        "\n",
        "1. **Capacity is proven sufficient:** If the model overfits, it can learn the training data's complexity\n",
        "2. **No need for more depth:** Adding layers would increase overfitting further without benefit\n",
        "3. **Regularise, don't expand:** The next step (Section 7) is to *reduce* overfitting through regularisation\n",
        "\n",
        "*\"The right question is not 'How many layers?' but 'Can it overfit?' If yes, regularise. If no, add capacity.\"*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUo-d_BFo9Lo"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MULTI-LAYER PERCEPTRON (MLP) - Standard architecture\n",
        "# ============================================================\n",
        "HIDDEN_NEURONS = 64\n",
        "\n",
        "mlp_model = Sequential(name='Multi_Layer_Perceptron')\n",
        "mlp_model.add(Dense(HIDDEN_NEURONS, activation='relu', input_shape=(INPUT_DIMENSION,)))\n",
        "mlp_model.add(Dense(OUTPUT_CLASSES, activation='softmax'))\n",
        "mlp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n",
        "\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtixAlSBo9Lo"
      },
      "outputs": [],
      "source": [
        "# Train MLP\n",
        "mlp_history = mlp_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS_BASELINE,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "mlp_val_acc = mlp_model.evaluate(X_val, y_val, verbose=0)[1]\n",
        "print(f\"MLP Validation Accuracy: {mlp_val_acc:.4f} (baseline: {baseline_accuracy:.2f})\")\n",
        "print(f\"Improvement over SLP: {(mlp_val_acc - slp_val_acc)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyjyPd6So9Lo"
      },
      "outputs": [],
      "source": [
        "plot_training_history(mlp_history, 'Multi-Layer Perceptron (1 Hidden Layer)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_cmFu-0o9Lo"
      },
      "source": [
        "## 7. Regularising Your Model and Tuning Hyperparameters\n",
        "\n",
        "Using **Hyperband** for efficient hyperparameter tuning with L2 regularisation and Dropout.\n",
        "\n",
        "### Why Hyperband?\n",
        "\n",
        "**Hyperband** is more efficient than grid search because it:\n",
        "1. Starts training many configurations for a few epochs\n",
        "2. Eliminates poor performers early\n",
        "3. Allocates more resources to promising configurations\n",
        "\n",
        "### Regularisation Strategy\n",
        "\n",
        "| Technique | Purpose | How It Works |\n",
        "|-----------|---------|-------------|\n",
        "| **L2 Regularisation** | Prevent large weights | Adds penalty term to loss |\n",
        "| **Dropout** | Prevent co-adaptation | Randomly zeros neurons during training |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeUCcs9Po9Lo"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# HYPERBAND MODEL BUILDER\n",
        "# ============================================================\n",
        "def build_model_hyperband(hp):\n",
        "    \"\"\"\n",
        "    Build ASL model with FROZEN architecture (1 hidden layer, 64 neurons).\n",
        "    Tunes: L2 regularisation, Dropout rate, Learning rate.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(INPUT_DIMENSION,)))\n",
        "\n",
        "    # Hyperparameters to tune\n",
        "    l2_reg = hp.Float('l2_reg', min_value=1e-5, max_value=1e-2, sampling='log')\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
        "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "\n",
        "    # Hidden layer with L2 regularisation\n",
        "    model.add(layers.Dense(\n",
        "        HIDDEN_NEURONS,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(l2_reg)\n",
        "    ))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(OUTPUT_CLASSES, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=LOSS_FUNC,\n",
        "        metrics=METRICS\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oiR2Mkpo9Lo"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURE AND RUN HYPERBAND TUNER\n",
        "# ============================================================\n",
        "tuner = kt.Hyperband(\n",
        "    build_model_hyperband,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=50,\n",
        "    factor=3,\n",
        "    directory='asl_hyperband',\n",
        "    project_name='asl_tuning',\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# Run search\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBCCIc6so9Lo"
      },
      "outputs": [],
      "source": [
        "# Get best hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Best hyperparameters found by Hyperband:\")\n",
        "print(f\"  L2 Regularisation: {best_hp.get('l2_reg'):.6f}\")\n",
        "print(f\"  Dropout Rate: {best_hp.get('dropout_rate')}\")\n",
        "print(f\"  Learning Rate: {best_hp.get('learning_rate'):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Sanity Check and Final Retraining\n",
        "\n",
        "After finding the best hyperparameters, we follow a two-step process:\n",
        "\n",
        "1. **Sanity Check:** Retrain with the best hyperparameters using training and validation data to visually confirm the model is not overfitting. This validates that Hyperband found hyperparameters that generalise well.\n",
        "\n",
        "2. **Final Refit:** Combine training and validation sets and retrain without validation. Since the hyperparameters have been validated, we maximise the data available for the final model.\n",
        "\n",
        "---\n",
        "\n",
        "#### Why This Two-Step Approach?\n",
        "\n",
        "| Step | Purpose | Validation Data |\n",
        "|------|---------|-----------------|\n",
        "| **Sanity Check** | Confirm hyperparameters prevent overfitting | ✓ Used for monitoring |\n",
        "| **Final Refit** | Maximise training data for production model | ✗ Merged into training |\n",
        "\n",
        "Once the sanity check confirms no overfitting, we can confidently combine all available data for the final model."
      ],
      "metadata": {
        "id": "5L4Djy94o9L0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBwitnBDo9L0"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 1: SANITY CHECK - Retrain with validation to confirm no overfitting\n",
        "# =============================================================================\n",
        "\n",
        "# Extract the number of epochs from the best trial\n",
        "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "best_epochs = best_trial.best_step + 1  # best_step is 0-indexed\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SANITY CHECK: Retraining with Validation\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training for {best_epochs} epochs (matched from Hyperband's best trial)\")\n",
        "print(\"Purpose: Visually confirm the hyperparameters prevent overfitting\\n\")\n",
        "\n",
        "# Build a fresh model with the best hyperparameters\n",
        "sanity_model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "history_sanity = sanity_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=best_epochs,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_val, y_val),  # Include validation for monitoring\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Sanity check training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aFxYaqdo9L0"
      },
      "outputs": [],
      "source": [
        "# Plot sanity check training history (with validation curves)\n",
        "plot_training_history(history_sanity, title=f'Sanity Check - Best Hyperparameters ({best_epochs} epochs)')\n",
        "\n",
        "# Verify no overfitting: validation loss should not increase significantly\n",
        "val_losses = history_sanity.history['val_loss']\n",
        "min_val_loss_epoch = val_losses.index(min(val_losses)) + 1\n",
        "final_val_loss = val_losses[-1]\n",
        "min_val_loss = min(val_losses)\n",
        "\n",
        "print(f\"\\nSanity Check Results:\")\n",
        "print(f\"  Minimum validation loss: {min_val_loss:.4f} at epoch {min_val_loss_epoch}\")\n",
        "print(f\"  Final validation loss: {final_val_loss:.4f}\")\n",
        "if final_val_loss <= min_val_loss * 1.1:  # Within 10% of minimum\n",
        "    print(\"  ✓ No significant overfitting detected - hyperparameters are validated\")\n",
        "else:\n",
        "    print(\"  ⚠ Some overfitting detected - consider adjusting epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX8-vsNIo9L0"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 2: FINAL REFIT - Combine data and retrain for production\n",
        "# =============================================================================\n",
        "\n",
        "# Combine training and validation sets for final model\n",
        "X_combined = np.vstack([X_train, X_val])\n",
        "y_combined = np.vstack([y_train, y_val])  # One-hot encoded labels\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL REFIT: Training on Combined Data\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training data: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Validation data: {X_val.shape[0]:,} samples\")\n",
        "print(f\"Combined data: {X_combined.shape[0]:,} samples\")\n",
        "print(f\"  → {(X_combined.shape[0] / X_train.shape[0] - 1) * 100:.1f}% more training data\")\n",
        "\n",
        "# Build and train final model on combined data\n",
        "print(f\"\\nRetraining for {best_epochs} epochs on combined data...\")\n",
        "\n",
        "best_model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "best_model.fit(\n",
        "    X_combined, y_combined,\n",
        "    epochs=best_epochs,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=0\n",
        "    # No validation_data - merged into training\n",
        "    # No plotting needed - sanity check already validated the hyperparameters\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Final model training complete on combined dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# K-FOLD CROSS-VALIDATION EVALUATION\n",
        "# ============================================================\n",
        "def evaluate_with_kfold(build_fn, X, y, y_raw, skfold, epochs, batch_size):\n",
        "    \"\"\"\n",
        "    Evaluate a model using Stratified K-Fold cross-validation.\n",
        "    \"\"\"\n",
        "    fold_metrics = {'accuracy': [], 'precision': [], 'recall': []}\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skfold.split(X, y_raw)):\n",
        "        X_train_fold = X[train_idx]\n",
        "        X_val_fold = X[val_idx]\n",
        "        y_train_fold = y[train_idx]\n",
        "        y_val_fold = y[val_idx]\n",
        "        y_val_raw_fold = y_raw[val_idx]\n",
        "\n",
        "        # Build fresh model for each fold\n",
        "        model = build_fn()\n",
        "\n",
        "        # Train (no class weights - dataset is balanced)\n",
        "        model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            epochs=epochs, batch_size=batch_size,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        preds = model.predict(X_val_fold, verbose=0).argmax(axis=1)\n",
        "        fold_metrics['accuracy'].append(accuracy_score(y_val_raw_fold, preds))\n",
        "        fold_metrics['precision'].append(precision_score(y_val_raw_fold, preds, average='macro'))\n",
        "        fold_metrics['recall'].append(recall_score(y_val_raw_fold, preds, average='macro'))\n",
        "\n",
        "        print(f\"  Fold {fold+1}: Accuracy={fold_metrics['accuracy'][-1]:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'acc_mean': np.mean(fold_metrics['accuracy']),\n",
        "        'acc_std': np.std(fold_metrics['accuracy']),\n",
        "        'prec_mean': np.mean(fold_metrics['precision']),\n",
        "        'prec_std': np.std(fold_metrics['precision']),\n",
        "        'rec_mean': np.mean(fold_metrics['recall']),\n",
        "        'rec_std': np.std(fold_metrics['recall'])\n",
        "    }\n",
        "\n",
        "# Build function using best hyperparameters\n",
        "def build_best_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(INPUT_DIMENSION,)))\n",
        "    model.add(layers.Dense(HIDDEN_NEURONS, activation='relu',\n",
        "                           kernel_regularizer=regularizers.l2(best_hp.get('l2_reg'))))\n",
        "    model.add(layers.Dropout(best_hp.get('dropout_rate')))\n",
        "    model.add(layers.Dense(OUTPUT_CLASSES, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=best_hp.get('learning_rate')),\n",
        "        loss=LOSS_FUNC, metrics=METRICS\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"Evaluating best model with 5-Fold Stratified Cross-Validation...\")\n",
        "kfold_results = evaluate_with_kfold(\n",
        "    build_best_model, X_train_full, y_train_full, y_train_full_raw,\n",
        "    skfold, EPOCHS_REGULARIZED, BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"K-FOLD CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Accuracy:  {kfold_results['acc_mean']:.4f} ± {kfold_results['acc_std']:.4f}\")\n",
        "print(f\"Precision: {kfold_results['prec_mean']:.4f} ± {kfold_results['prec_std']:.4f}\")\n",
        "print(f\"Recall:    {kfold_results['rec_mean']:.4f} ± {kfold_results['rec_std']:.4f}\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "lfvssamyo9L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSDMhD02o9L0"
      },
      "source": [
        "## 8. Final Evaluation\n",
        "\n",
        "Train the final model on the **entire training pool** and evaluate on the held-out test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7G9rYABo9L0"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FINAL MODEL: Train on ALL training data, evaluate on test set\n",
        "# ============================================================\n",
        "# Build final model with best hyperparameters\n",
        "final_model = build_best_model()\n",
        "\n",
        "# Train on entire training pool (no class weights - dataset is balanced)\n",
        "final_model.fit(\n",
        "    X_train_full, y_train_full,\n",
        "    epochs=EPOCHS_REGULARIZED,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Evaluate on held-out test set\n",
        "y_pred_proba = final_model.predict(X_test, verbose=0)\n",
        "y_pred = y_pred_proba.argmax(axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "test_accuracy = accuracy_score(y_test_raw, y_pred)\n",
        "test_precision = precision_score(y_test_raw, y_pred, average='macro')\n",
        "test_recall = recall_score(y_test_raw, y_pred, average='macro')\n",
        "test_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"FINAL TEST SET RESULTS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy:  {test_accuracy:.4f} (baseline: {baseline_accuracy:.2f})\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall:    {test_recall:.4f}\")\n",
        "print(f\"AUC:       {test_auc:.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv7rXQlSo9L0"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFUSION MATRIX\n",
        "# ============================================================\n",
        "cm = confusion_matrix(y_test_raw, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(ax=ax, cmap='Blues')\n",
        "plt.title('Confusion Matrix - Test Set')\n",
        "plt.show()\n",
        "\n",
        "# Print detailed breakdown\n",
        "print(\"\\nConfusion Matrix Breakdown:\")\n",
        "for i, class_name in enumerate(CLASS_NAMES):\n",
        "    correct = cm[i, i]\n",
        "    total = cm[i, :].sum()\n",
        "    print(f\"  {class_name}: {correct}/{total} correct ({100*correct/total:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9azXV3do9L0"
      },
      "source": [
        "## Model Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejsHqPIso9L1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODEL COMPARISON\n",
        "# ============================================================\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Model':<35} {'Accuracy':>15} {'Dataset':>10}\")\n",
        "print(\"-\"*60)\n",
        "print(f\"{'Baseline (random)':<35} {baseline_accuracy:>15.4f} {'N/A':>10}\")\n",
        "print(f\"{'Single Layer Perceptron':<35} {slp_val_acc:>15.4f} {'Fold 1':>10}\")\n",
        "print(f\"{'Multi-Layer Perceptron':<35} {mlp_val_acc:>15.4f} {'Fold 1':>10}\")\n",
        "print(f\"{'Regularised (L2+Dropout) K-Fold':<35} {kfold_results['acc_mean']:.4f} +/- {kfold_results['acc_std']:.4f}  {'5-Fold CV':>10}\")\n",
        "print(f\"{'Final Model - Test Set':<35} {test_accuracy:>15.4f} {'Test':>10}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nKey Observations:\")\n",
        "print(f\"  - All models significantly outperform random baseline ({baseline_accuracy:.2%})\")\n",
        "print(f\"  - Final model trained on combined train+val data ({X_train_full.shape[0]:,} samples)\")\n",
        "print(f\"  - K-Fold CV accuracy: {kfold_results['acc_mean']:.2%} +/- {kfold_results['acc_std']:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hW5VpI9o9L1"
      },
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "### Decision Framework Summary\n",
        "\n",
        "| Decision | Threshold | This Dataset | Choice | Reference |\n",
        "|----------|-----------|--------------|--------|-----------|\n",
        "| **Hold-Out vs K-Fold** | > 10,000 samples | ~9,000 samples | **K-Fold (5 folds)** | Kohavi (1995) |\n",
        "| **Primary Metric** | Balanced multi-class | Equal distribution | Accuracy | Standard choice |\n",
        "| **Class Weights** | Imbalance > 3:1 | 1:1 (balanced) | Not needed | He and Garcia (2009) |\n",
        "\n",
        "### Lessons Learned\n",
        "\n",
        "1. **K-Fold for Medium Datasets:** With ~9,000 samples (below the 10,000 threshold), K-Fold cross-validation provides more robust performance estimates.\n",
        "\n",
        "2. **K-Fold Reports Mean +/- Std:** Unlike hold-out (single number), K-Fold gives us confidence intervals.\n",
        "\n",
        "3. **No Class Weights for Balanced Data:** Since each class has exactly 3,000 samples, class weights are unnecessary.\n",
        "\n",
        "4. **Image Preprocessing:** Resize → Grayscale → Flatten → Normalise converts images to vectors for dense networks.\n",
        "\n",
        "5. **Flattening loses spatial information:** Dense networks treat pixels as independent features, ignoring spatial relationships.\n",
        "\n",
        "6. **Maximise Data for Final Model:** After hyperparameter tuning, we combine training and validation sets for the final model. The validation set's job is done (model selection), so we use all available data to maximise learning.\n",
        "\n",
        "7. **High accuracy on ASL:** The 3-class problem (A, B, C) is relatively easy for neural networks due to distinct hand shapes.\n",
        "\n",
        "8. **Final Model Uses All Training Data:** After K-Fold validation, the final model is trained on the entire training pool.\n",
        "\n",
        "### Next Steps for Better Performance\n",
        "\n",
        "- **Expand to full alphabet** (26 classes) - more challenging\n",
        "- **Use CNNs** (Chapter 8) - preserves spatial structure\n",
        "- **Higher resolution** - 32×32 is still relatively small\n",
        "- **Data augmentation** - artificial variations for robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Appendix: Modular Helper Functions\n",
        "\n",
        "For cleaner code organisation, you can wrap the model building and training patterns into reusable functions."
      ],
      "metadata": {
        "id": "wbDo80Apo9L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODULAR HELPER FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def build_image_classifier(input_dim, num_classes, hidden_units=None, dropout=0.0, l2_reg=0.0,\n",
        "                           optimizer='adam', learning_rate=None, name=None):\n",
        "    \"\"\"\n",
        "    Build a multi-class image classification neural network.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    input_dim : int\n",
        "        Number of input features (flattened image size)\n",
        "    num_classes : int\n",
        "        Number of output classes\n",
        "    hidden_units : list of int, optional\n",
        "        Neurons per hidden layer, e.g., [64] or [128, 64]\n",
        "        None or [] creates a single-layer perceptron\n",
        "    dropout : float\n",
        "        Dropout rate (0.0 to 0.5)\n",
        "    l2_reg : float\n",
        "        L2 regularisation strength\n",
        "    optimizer : str\n",
        "        Optimiser name\n",
        "    learning_rate : float, optional\n",
        "        Custom learning rate (uses default if None)\n",
        "    name : str, optional\n",
        "        Model name\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    keras.Sequential : Compiled model ready for training\n",
        "    \"\"\"\n",
        "    model = Sequential(name=name)\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "\n",
        "    hidden_units = hidden_units or []\n",
        "    kernel_reg = regularizers.l2(l2_reg) if l2_reg > 0 else None\n",
        "\n",
        "    for units in hidden_units:\n",
        "        model.add(Dense(units, activation='relu', kernel_regularizer=kernel_reg))\n",
        "        if dropout > 0:\n",
        "            model.add(Dropout(dropout))\n",
        "\n",
        "    # Output layer for multi-class classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Configure optimizer\n",
        "    if learning_rate is not None:\n",
        "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        opt = optimizer\n",
        "\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val,\n",
        "                batch_size=64, epochs=100, verbose=0):\n",
        "    \"\"\"\n",
        "    Train a model and return training history.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : keras.Model\n",
        "        Compiled Keras model\n",
        "    X_train, y_train : array-like\n",
        "        Training data and labels\n",
        "    X_val, y_val : array-like\n",
        "        Validation data and labels\n",
        "    batch_size : int\n",
        "        Training batch size\n",
        "    epochs : int\n",
        "        Number of training epochs\n",
        "    verbose : int\n",
        "        Verbosity mode\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    keras.callbacks.History : Training history object\n",
        "    \"\"\"\n",
        "    return model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "\n",
        "def evaluate_multiclass_model(model, X, y_true_onehot, class_names=None):\n",
        "    \"\"\"\n",
        "    Evaluate multi-class classification model.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : keras.Model\n",
        "        Trained Keras model\n",
        "    X : array-like\n",
        "        Input features\n",
        "    y_true_onehot : array-like\n",
        "        True labels (one-hot encoded)\n",
        "    class_names : list, optional\n",
        "        Names of classes for display\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary containing all metrics\n",
        "    \"\"\"\n",
        "    y_pred_proba = model.predict(X, verbose=0)\n",
        "    y_pred = y_pred_proba.argmax(axis=1)\n",
        "    y_true = y_true_onehot.argmax(axis=1)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred, average='macro'),\n",
        "        'recall': recall_score(y_true, y_pred, average='macro'),\n",
        "        'auc': roc_auc_score(y_true_onehot, y_pred_proba, multi_class='ovr', average='macro'),\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# USAGE EXAMPLES\n",
        "# =============================================================================\n",
        "#\n",
        "# # Build models\n",
        "# slp = build_image_classifier(INPUT_DIMENSION, OUTPUT_CLASSES, name='SLP')\n",
        "# mlp = build_image_classifier(INPUT_DIMENSION, OUTPUT_CLASSES, hidden_units=[64], name='MLP')\n",
        "# mlp_reg = build_image_classifier(INPUT_DIMENSION, OUTPUT_CLASSES, hidden_units=[64],\n",
        "#                                  dropout=0.3, l2_reg=0.001, learning_rate=0.001,\n",
        "#                                  name='MLP_Regularized')\n",
        "#\n",
        "# # Train\n",
        "# history = train_model(mlp, X_train, y_train, X_val, y_val)\n",
        "#\n",
        "# # Evaluate\n",
        "# metrics = evaluate_multiclass_model(mlp, X_val, y_val, CLASS_NAMES)\n",
        "# print(f\"Accuracy: {metrics['accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "C-ilfGaMo9L1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}