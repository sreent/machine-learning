{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Final%20DNN%20Code%20Examples/Rain%20in%20Australia/Rain%20in%20Australia%20-%20Mixed%20Feature%20Type%20%26%20Missing%20Value%20Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n\n# Rain in Australia - Mixed Feature Type & Missing Value Example\n\nThis notebook demonstrates the **Universal ML Workflow** applied to a binary classification problem with **mixed feature types** (categorical and numerical) and **missing values**.\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n- Handle **mixed feature types** (categorical + numerical) in a single model\n- Apply appropriate preprocessing: **One-Hot Encoding** for categorical, **Standardization** for numerical\n- Handle **missing values** using different strategies (kNN imputation, \"Unknown\" category)\n- Address **class imbalance** using class weights during training\n- Build and evaluate a binary classification neural network\n- Use Grid Search with Cross-Validation for hyperparameter tuning\n\n---\n\n## Dataset Overview\n\n| Attribute | Description |\n|-----------|-------------|\n| **Source** | [Kaggle Weather Dataset](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package) |\n| **Problem Type** | Binary Classification |\n| **Target Variable** | RainTomorrow (Yes/No) |\n| **Data Balance** | Imbalanced (~78% No, ~22% Yes) |\n| **Data Type** | Structured (Mixed Categorical & Numerical) |\n| **Missing Data** | Significant missing values in many columns |\n| **Features** | 16 numerical + 5 categorical variables |\n\n---"
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Defining the Problem and Assembling a Dataset\n\n**Problem Statement:** Given weather observations from various Australian locations, predict whether it will rain tomorrow.\n\n**Why this problem is interesting:**\n- Requires handling **mixed feature types** - we have both categorical (Location, WindDirection) and numerical (Temperature, Humidity) features\n- Contains **missing values** that must be handled appropriately\n- Features **class imbalance** - rain days are less common than non-rain days\n- Real-world application: agricultural planning, event scheduling, water resource management\n\n**Data Source:** This dataset contains about 10 years of daily weather observations from numerous Australian weather stations.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Choosing a Measure of Success\n\nFor this imbalanced binary classification problem, we need metrics that account for the class imbalance.\n\n**Metrics we'll use:**\n\n| Metric | Description | Why We Use It |\n|--------|-------------|---------------|\n| **Balanced Accuracy** | Average of sensitivity and specificity | Not fooled by class imbalance |\n| **Precision** | True Positives / (True Positives + False Positives) | How reliable are rain predictions? |\n| **Recall** | True Positives / (True Positives + False Negatives) | How many rainy days do we catch? |\n| **AUC-ROC** | Area under the ROC curve | Overall discrimination ability |\n\n**Note:** Since missing a rainy day prediction (false negative) might have different costs than a false alarm (false positive), we track both precision and recall."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Deciding on an Evaluation Protocol\n\n**Evaluation Strategy:**\n1. **Hold-out Test Set (15%)**: Reserved for final model evaluation\n2. **Validation Set**: Used for early stopping and model monitoring  \n3. **K-Fold Cross-Validation (K=5)**: Used during hyperparameter tuning\n\n**Important Considerations:**\n- All splits use stratification to maintain the ~78:22 class ratio\n- Preprocessing (imputation, encoding, scaling) is fit only on training data to prevent data leakage"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Preparing Your Data\n\n### 4.1 Import Libraries and Set Random Seed\n\nThis example requires additional imports for handling missing values (KNNImputer) and mixed data types (ColumnTransformer)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4S0tiStcOxV"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\n# Keras Tuner for hyperparameter search\n!pip install -q -U keras-tuner\nimport keras_tuner as kt\n\nimport itertools\nimport matplotlib.pyplot as plt\n\nSEED = 204\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv('weatherAUS.csv')\n",
    "\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.2 Load and Explore the Dataset\n\nThe dataset contains weather observations from various Australian locations. Notice the many NaN (missing) values in several columns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143975.000000</td>\n",
       "      <td>144199.000000</td>\n",
       "      <td>142199.000000</td>\n",
       "      <td>82670.000000</td>\n",
       "      <td>75625.000000</td>\n",
       "      <td>135197.000000</td>\n",
       "      <td>143693.000000</td>\n",
       "      <td>142398.000000</td>\n",
       "      <td>142806.000000</td>\n",
       "      <td>140953.000000</td>\n",
       "      <td>130395.00000</td>\n",
       "      <td>130432.000000</td>\n",
       "      <td>89572.000000</td>\n",
       "      <td>86102.000000</td>\n",
       "      <td>143693.000000</td>\n",
       "      <td>141851.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.194034</td>\n",
       "      <td>23.221348</td>\n",
       "      <td>2.360918</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>40.035230</td>\n",
       "      <td>14.043426</td>\n",
       "      <td>18.662657</td>\n",
       "      <td>68.880831</td>\n",
       "      <td>51.539116</td>\n",
       "      <td>1017.64994</td>\n",
       "      <td>1015.255889</td>\n",
       "      <td>4.447461</td>\n",
       "      <td>4.509930</td>\n",
       "      <td>16.990631</td>\n",
       "      <td>21.68339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.398495</td>\n",
       "      <td>7.119049</td>\n",
       "      <td>8.478060</td>\n",
       "      <td>4.193704</td>\n",
       "      <td>3.785483</td>\n",
       "      <td>13.607062</td>\n",
       "      <td>8.915375</td>\n",
       "      <td>8.809800</td>\n",
       "      <td>19.029164</td>\n",
       "      <td>20.795902</td>\n",
       "      <td>7.10653</td>\n",
       "      <td>7.037414</td>\n",
       "      <td>2.887159</td>\n",
       "      <td>2.720357</td>\n",
       "      <td>6.488753</td>\n",
       "      <td>6.93665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-4.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>980.50000</td>\n",
       "      <td>977.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.200000</td>\n",
       "      <td>-5.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.600000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1012.90000</td>\n",
       "      <td>1010.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>16.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1017.60000</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>21.10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>28.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1022.40000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>26.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1041.00000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>46.70000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
       "count  143975.000000  144199.000000  142199.000000  82670.000000   \n",
       "mean       12.194034      23.221348       2.360918      5.468232   \n",
       "std         6.398495       7.119049       8.478060      4.193704   \n",
       "min        -8.500000      -4.800000       0.000000      0.000000   \n",
       "25%         7.600000      17.900000       0.000000      2.600000   \n",
       "50%        12.000000      22.600000       0.000000      4.800000   \n",
       "75%        16.900000      28.200000       0.800000      7.400000   \n",
       "max        33.900000      48.100000     371.000000    145.000000   \n",
       "\n",
       "           Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\n",
       "count  75625.000000  135197.000000  143693.000000  142398.000000   \n",
       "mean       7.611178      40.035230      14.043426      18.662657   \n",
       "std        3.785483      13.607062       8.915375       8.809800   \n",
       "min        0.000000       6.000000       0.000000       0.000000   \n",
       "25%        4.800000      31.000000       7.000000      13.000000   \n",
       "50%        8.400000      39.000000      13.000000      19.000000   \n",
       "75%       10.600000      48.000000      19.000000      24.000000   \n",
       "max       14.500000     135.000000     130.000000      87.000000   \n",
       "\n",
       "         Humidity9am    Humidity3pm   Pressure9am    Pressure3pm  \\\n",
       "count  142806.000000  140953.000000  130395.00000  130432.000000   \n",
       "mean       68.880831      51.539116    1017.64994    1015.255889   \n",
       "std        19.029164      20.795902       7.10653       7.037414   \n",
       "min         0.000000       0.000000     980.50000     977.100000   \n",
       "25%        57.000000      37.000000    1012.90000    1010.400000   \n",
       "50%        70.000000      52.000000    1017.60000    1015.200000   \n",
       "75%        83.000000      66.000000    1022.40000    1020.000000   \n",
       "max       100.000000     100.000000    1041.00000    1039.600000   \n",
       "\n",
       "           Cloud9am      Cloud3pm        Temp9am       Temp3pm  \n",
       "count  89572.000000  86102.000000  143693.000000  141851.00000  \n",
       "mean       4.447461      4.509930      16.990631      21.68339  \n",
       "std        2.887159      2.720357       6.488753       6.93665  \n",
       "min        0.000000      0.000000      -7.200000      -5.40000  \n",
       "25%        1.000000      2.000000      12.300000      16.60000  \n",
       "50%        5.000000      5.000000      16.700000      21.10000  \n",
       "75%        7.000000      7.000000      21.600000      26.40000  \n",
       "max        9.000000      9.000000      40.200000      46.70000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_VARIABLES = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', \n",
    "                       'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm',\n",
    "                       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm',\n",
    "                       'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>145460</td>\n",
       "      <td>145460</td>\n",
       "      <td>135134</td>\n",
       "      <td>134894</td>\n",
       "      <td>141232</td>\n",
       "      <td>142199</td>\n",
       "      <td>142193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3436</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>Canberra</td>\n",
       "      <td>W</td>\n",
       "      <td>N</td>\n",
       "      <td>SE</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>49</td>\n",
       "      <td>3436</td>\n",
       "      <td>9915</td>\n",
       "      <td>11758</td>\n",
       "      <td>10838</td>\n",
       "      <td>110319</td>\n",
       "      <td>110316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date  Location WindGustDir WindDir9am WindDir3pm RainToday  \\\n",
       "count       145460    145460      135134     134894     141232    142199   \n",
       "unique        3436        49          16         16         16         2   \n",
       "top     2013-11-12  Canberra           W          N         SE        No   \n",
       "freq            49      3436        9915      11758      10838    110319   \n",
       "\n",
       "       RainTomorrow  \n",
       "count        142193  \n",
       "unique            2  \n",
       "top              No  \n",
       "freq         110316  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.drop(NUMERICAL_VARIABLES, axis=1).describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_VARIABLES = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where target variables are missing or the locations are missing\n",
    "weather = weather[~weather['RainTomorrow'].isnull() & ~weather['Location'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = CATEGORICAL_VARIABLES + NUMERICAL_VARIABLES\n",
    "\n",
    "features = weather[COLUMNS]\n",
    "\n",
    "TARGET_VARIABLE = 'RainTomorrow'\n",
    "target = weather[TARGET_VARIABLE]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.3 Handle Missing Values\n\n**Missing Value Strategies:**\n\n| Feature Type | Strategy | Rationale |\n|--------------|----------|-----------|\n| **Numerical** | kNN Imputation | Estimates missing values based on similar observations |\n| **Categorical** | Fill with \"Unknown\" | Creates an explicit category for missing data |\n\n**Why kNN Imputation?** It preserves relationships between features better than simple mean/median imputation.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.15\n",
    "\n",
    "(XF_train, XF_test, \n",
    " yf_train, yf_test) = train_test_split(features, \n",
    "                                       target, \n",
    "                                       test_size=TEST_SIZE, stratify=target,\n",
    "                                       shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing value for numerical features\n",
    "knn_imp = KNNImputer(n_neighbors=5).fit(XF_train[NUMERICAL_VARIABLES])\n",
    "\n",
    "NF_train = knn_imp.transform(XF_train[NUMERICAL_VARIABLES])\n",
    "NF_test = knn_imp.transform(XF_test[NUMERICAL_VARIABLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF_train = XF_train[CATEGORICAL_VARIABLES].fillna('Unknown')\n",
    "CF_test = XF_test[CATEGORICAL_VARIABLES].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 4.4 Preprocessing Pipeline with ColumnTransformer\n\nWe use `ColumnTransformer` to apply different preprocessing to different feature types simultaneously:\n\n```\nColumnTransformer\n├── Categorical Features → One-Hot Encoding\n│   (Creates binary columns for each category)\n└── Numerical Features → Standard Scaling\n    (Mean=0, Std=1)\n```\n\nThis is a common pattern for mixed-type datasets.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_train = pd.DataFrame(data = np.hstack((NF_train, CF_train)), \n",
    "                        columns = NUMERICAL_VARIABLES + CATEGORICAL_VARIABLES)\n",
    "\n",
    "XC_test = pd.DataFrame(data = np.hstack((NF_test, CF_test)), \n",
    "                        columns = NUMERICAL_VARIABLES + CATEGORICAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', OneHotEncoder(handle_unknown=\"ignore\"), CATEGORICAL_VARIABLES),\n",
    "    ('standard_scaler', StandardScaler(), NUMERICAL_VARIABLES)])\n",
    "\n",
    "_ = preprocessor.fit(XC_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = preprocessor.transform(XC_train), preprocessor.transform(XC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. Developing a Model That Does Better Than a Baseline\n\n### 5.1 Examine Class Distribution and Baselines"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Encode target variable to numeric (0/1)\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(yf_train)\n\ny_train = label_encoder.transform(yf_train)\ny_val_raw = label_encoder.transform(yf_test)  # Keep for later use\n\nVALIDATION_SIZE = X_test.shape[0]\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size=VALIDATION_SIZE, stratify=y_train,\n                                                  shuffle=True, random_state=SEED)\n\n# Also prepare test set labels\ny_test = label_encoder.transform(yf_test)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Developing a model that does better than a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate class distribution and baseline\ncounts = pd.Series(y_train).value_counts().sort_index()\nprint(\"Class distribution in training data:\")\nprint(counts)\n\n# Baseline = majority class proportion\nbaseline = counts.iloc[0] / counts.sum()\nprint(f\"\\nBaseline accuracy (always predict majority): {baseline:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_train, np.zeros(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMENSION = X_train.shape[1]\n",
    "OUTPUT_DIMENSION = 1\n",
    "\n",
    "OPTIMIZER = 'rmsprop'\n",
    "LOSS_FUNC = 'binary_crossentropy'\n",
    "METRICS = ['accuracy', \n",
    "           tf.keras.metrics.Precision(name='precision'), \n",
    "           tf.keras.metrics.Recall(name='recall'),\n",
    "           tf.keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Single Layer Perceptron - Binary Classification\nslp_model = Sequential(name='Single_Layer_Perceptron')\nslp_model.add(Dense(1, activation='sigmoid', input_shape=(INPUT_DIMENSION,)))\nslp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n\nslp_model.summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "batch_size = 512\nEPOCHS = 100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute class weights for imbalanced data\nweights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nCLASS_WEIGHTS = dict(enumerate(weights))\n\nprint(\"Class weights:\", CLASS_WEIGHTS)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train SLP model\nslp_history = slp_model.fit(X_train, y_train, class_weight=CLASS_WEIGHTS, batch_size=batch_size, epochs=EPOCHS, validation_data=(X_val, y_val), verbose=0)\nslp_val_score = slp_model.evaluate(X_val, y_val, verbose=0)[1:]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Balanced accuracy baseline\nbalanced_accuracy_baseline = balanced_accuracy_score(y_train, np.zeros(len(y_train)))\nprint(f\"Balanced accuracy baseline: {balanced_accuracy_baseline:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Print SLP validation results\nprint('Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(slp_val_score[0], baseline))\nprint('Precision (Validation): {:.2f}'.format(slp_val_score[1]))\nprint('Recall (Validation): {:.2f}'.format(slp_val_score[2]))\nprint('AUC (Validation): {:.2f}'.format(slp_val_score[3]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNzQH9Srwt5R"
   },
   "outputs": [],
   "source": "print('Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(slp_val_score[0], baseline))\nprint('Precision (Validation): {:.2f}'.format(slp_val_score[1]))\nprint('Recall (Validation): {:.2f}'.format(slp_val_score[2]))\nprint('AUC (Validation): {:.2f}'.format(slp_val_score[3]))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "xT6SBVGW0dEA",
    "outputId": "55f3b135-788f-4741-b1f9-5882bbada568"
   },
   "outputs": [],
   "source": "# Define plot helper function\ndef plot_training_history(history, monitors=['loss', 'auc']):\n    \"\"\"Plot training and validation metrics over epochs.\"\"\"\n    fig, axs = plt.subplots(1, 2, sharex='all', figsize=(15, 5))\n    \n    for ax, monitor in zip(axs.flat, monitors):\n        train_vals = history.history[monitor]\n        val_vals = history.history['val_' + monitor]\n        \n        display_name = monitor.capitalize() if monitor == 'loss' else monitor.upper()\n        epochs = range(1, len(train_vals) + 1)\n        \n        ax.plot(epochs, train_vals, 'b.', label=f'Training {display_name}')\n        ax.plot(epochs, val_vals, 'r.', label=f'Validation {display_name}')\n        ax.set_xlim([0, len(train_vals)])\n        ax.set_title(f'Training and Validation {display_name}')\n        ax.set_xlabel('Epochs')\n        ax.set_ylabel(display_name)\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot SLP training history\nplot_training_history(slp_history, monitors=['loss', 'auc'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Multi-Layer Perceptron - 2 hidden layers with 80 neurons each\nmlp_model = Sequential(name='Multi_Layer_Perceptron')\nmlp_model.add(Dense(80, activation='relu', input_shape=(INPUT_DIMENSION,)))\nmlp_model.add(Dense(80, activation='relu'))\nmlp_model.add(Dense(1, activation='sigmoid'))\nmlp_model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNC, metrics=METRICS)\n\nmlp_model.summary()\n\n# Train MLP model\nmlp_history = mlp_model.fit(X_train, y_train, class_weight=CLASS_WEIGHTS, batch_size=batch_size, epochs=EPOCHS, validation_data=(X_val, y_val), verbose=0)\nmlp_val_score = mlp_model.evaluate(X_val, y_val, verbose=0)[1:]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot MLP training history\nplot_training_history(mlp_history, monitors=['loss', 'auc'])\n\n# Print MLP validation results\nprint('Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(mlp_val_score[0], baseline))\nprint('Precision (Validation): {:.2f}'.format(mlp_val_score[1]))\nprint('Recall (Validation): {:.2f}'.format(mlp_val_score[2]))\nprint('AUC (Validation): {:.2f}'.format(mlp_val_score[3]))"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 7. Regularizing Your Model and Tuning Hyperparameters\n\nUsing **Hyperband** for efficient hyperparameter tuning with a frozen architecture.\n\n### Why Hyperband?\n\n**Hyperband** is more efficient than grid search because it:\n1. Starts training many configurations for a few epochs\n2. Eliminates poor performers early\n3. Allocates more resources to promising configurations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "preds = (mlp_model.predict(X_val, verbose=0) > 0.5).astype('int32')\n\nprint('Balanced Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(\n    balanced_accuracy_score(y_val, preds), balanced_accuracy_baseline))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Regularizing your model and tuning your hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Hyperband Model Builder for Rain Prediction\ndef build_model_hyperband(hp):\n    \"\"\"\n    Build Rain in Australia model with FROZEN architecture (2 layers: 80 -> 40 neurons).\n    Only tunes regularization (Dropout) and learning rate.\n    \"\"\"\n    model = keras.Sequential()\n    model.add(layers.Input(shape=(INPUT_DIMENSION,)))\n\n    # Fixed architecture: 2 hidden layers with 80 and 40 neurons\n    # Layer 1: 80 neurons\n    model.add(layers.Dense(80, activation='relu'))\n    drop_0 = hp.Float('drop_0', 0.0, 0.5, step=0.1)\n    model.add(layers.Dropout(drop_0))\n\n    # Layer 2: 40 neurons\n    model.add(layers.Dense(40, activation='relu'))\n    drop_1 = hp.Float('drop_1', 0.0, 0.5, step=0.1)\n    model.add(layers.Dropout(drop_1))\n\n    # Output layer for binary classification\n    model.add(layers.Dense(OUTPUT_DIMENSION, activation='sigmoid'))\n\n    lr = hp.Float('lr', 1e-4, 1e-2, sampling='log')\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=lr),\n        loss=LOSS_FUNC,\n        metrics=METRICS\n    )\n    return model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure Hyperband tuner\ntuner = kt.Hyperband(\n    build_model_hyperband,\n    objective='val_auc',\n    max_epochs=20,\n    factor=3,\n    directory='rain_australia_hyperband',\n    project_name='rain_australia_tuning'\n)\n\n# Run Hyperband search\ntuner.search(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=20,\n    batch_size=batch_size,\n    class_weight=CLASS_WEIGHTS\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get best hyperparameters and build best model\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(\"Best hyperparameters:\")\nprint(f\"  Dropout Layer 1: {best_hp.get('drop_0')}\")\nprint(f\"  Dropout Layer 2: {best_hp.get('drop_1')}\")\nprint(f\"  Learning Rate: {best_hp.get('lr')}\")\n\nopt_model = tuner.hypermodel.build(best_hp)\nopt_model.summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train optimized model\nopt_history = opt_model.fit(X_train, y_train, class_weight=CLASS_WEIGHTS, batch_size=batch_size, epochs=EPOCHS, validation_data=(X_val, y_val), verbose=0)\nopt_val_score = opt_model.evaluate(X_val, y_val, verbose=0)[1:]\n\n# Plot training history\nplot_training_history(opt_history, monitors=['loss', 'auc'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Print optimized model validation results\nprint('Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(opt_val_score[0], baseline))\nprint('Precision (Validation): {:.2f}'.format(opt_val_score[1]))\nprint('Recall (Validation): {:.2f}'.format(opt_val_score[2]))\nprint('AUC (Validation): {:.2f}'.format(opt_val_score[3]))\n\n# Balanced accuracy\npreds = opt_model.predict(X_val, verbose=0)\nprint('Balanced Accuracy (Validation): {:.2f} (baseline={:.2f})'.format(\n    balanced_accuracy_score(y_val, (preds > 0.5).astype('int32')), balanced_accuracy_baseline))"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Test Set Evaluation\n\nFinal evaluation on the held-out test set to assess generalization."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate on test set\ntest_preds = opt_model.predict(X_test, verbose=0)\ntest_preds_binary = (test_preds > 0.5).astype('int32')\n\nprint('Test Set Results:')\nprint('Accuracy (Test): {:.2f} (baseline={:.2f})'.format(accuracy_score(y_test, test_preds_binary), baseline))\nprint('Precision (Test): {:.2f}'.format(precision_score(y_test, test_preds_binary)))\nprint('Recall (Test): {:.2f}'.format(recall_score(y_test, test_preds_binary)))\nprint('AUC (Test): {:.2f}'.format(roc_auc_score(y_test, test_preds)))\nprint('Balanced Accuracy (Test): {:.2f} (baseline={:.2f})'.format(\n    balanced_accuracy_score(y_test, test_preds_binary), balanced_accuracy_baseline))\n\n# Confusion Matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix(y_test, test_preds_binary))\n_ = disp.plot()"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# MODULAR FUNCTIONS FOR BINARY CLASSIFICATION\n# ============================================================================\n\ndef create_binary_classifier(input_dim, hidden_layers=None, hidden_neurons=None, \n                             dropout=None, optimizer='rmsprop', \n                             loss='binary_crossentropy', metrics=None, name=None):\n    \"\"\"\n    Create a binary classification neural network.\n    \n    Parameters:\n    -----------\n    input_dim : int\n        Number of input features\n    hidden_layers : int, optional\n        Number of hidden layers (0 for single-layer perceptron)\n    hidden_neurons : int or list, optional\n        Neurons per hidden layer (int applies to all layers, list for per-layer)\n    dropout : float, optional\n        Dropout rate (0.0 to 1.0) applied after each hidden layer\n    optimizer : str or keras.optimizers.Optimizer\n        Optimizer for training\n    loss : str or keras.losses.Loss\n        Loss function\n    metrics : list\n        List of metrics to track\n    name : str, optional\n        Model name\n        \n    Returns:\n    --------\n    keras.Sequential : Compiled model ready for training\n    \n    Example Usage:\n    --------------\n    # Single Layer Perceptron (no hidden layers)\n    # slp = create_binary_classifier(input_dim=100, name='SLP')\n    \n    # MLP with 2 hidden layers of 64 neurons each\n    # mlp = create_binary_classifier(input_dim=100, hidden_layers=2, \n    #                                hidden_neurons=64, dropout=0.3, name='MLP')\n    \n    # MLP with different neurons per layer\n    # mlp = create_binary_classifier(input_dim=100, hidden_layers=2,\n    #                                hidden_neurons=[128, 64], name='MLP')\n    \"\"\"\n    from keras.models import Sequential\n    from keras.layers import Dense, Dropout\n    \n    if metrics is None:\n        metrics = ['accuracy']\n    \n    model = Sequential()\n    \n    # Add hidden layers if specified\n    if hidden_layers and hidden_layers > 0:\n        # Handle both int and list for hidden_neurons\n        if isinstance(hidden_neurons, int):\n            neurons_list = [hidden_neurons] * hidden_layers\n        else:\n            neurons_list = hidden_neurons\n            \n        for i, neurons in enumerate(neurons_list):\n            if i == 0:\n                model.add(Dense(neurons, activation='relu', input_shape=(input_dim,)))\n            else:\n                model.add(Dense(neurons, activation='relu'))\n            \n            if dropout is not None and dropout > 0:\n                model.add(Dropout(dropout))\n    \n    # Output layer for binary classification\n    if hidden_layers and hidden_layers > 0:\n        model.add(Dense(1, activation='sigmoid'))\n    else:\n        model.add(Dense(1, activation='sigmoid', input_shape=(input_dim,)))\n    \n    if name:\n        model._name = name\n    \n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    \n    return model\n\n\ndef train_binary_classifier(model, X_train, y_train, X_val, y_val,\n                            class_weights=None, batch_size=32, epochs=100):\n    \"\"\"\n    Train a binary classification model and return results.\n    \n    Parameters:\n    -----------\n    model : keras.Model\n        Compiled Keras model\n    X_train, y_train : array-like\n        Training data and labels\n    X_val, y_val : array-like\n        Validation data and labels\n    class_weights : dict, optional\n        Class weights for imbalanced data\n    batch_size : int\n        Batch size for training\n    epochs : int\n        Number of training epochs\n        \n    Returns:\n    --------\n    tuple : (history, val_score)\n        - history: Training history object\n        - val_score: Validation metrics (excludes loss)\n        \n    Example Usage:\n    --------------\n    # history, val_score = train_binary_classifier(\n    #     model, X_train, y_train, X_val, y_val,\n    #     class_weights=CLASS_WEIGHTS, batch_size=512, epochs=100\n    # )\n    # print(f'Validation Accuracy: {val_score[0]:.2f}')\n    \"\"\"\n    history = model.fit(\n        X_train, y_train,\n        class_weight=class_weights,\n        batch_size=batch_size,\n        epochs=epochs,\n        validation_data=(X_val, y_val),\n        verbose=0\n    )\n    \n    val_score = model.evaluate(X_val, y_val, verbose=0)[1:]\n    \n    return history, val_score",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}