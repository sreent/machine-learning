{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/K-Nearest%20Neighbours%20Regression/KNN%20Regression%20Code%20Walk%20Through.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# K-Nearest Neighbors Regression: Code Walk Through\n",
        "\n",
        "This notebook walks through the **computational steps** of the K-Nearest Neighbors (KNN) regression algorithm.\n",
        "\n",
        "## What We'll Cover:\n",
        "1. **Visualize the data** - understand the dataset\n",
        "2. **Calculate distances** - measure similarity between points\n",
        "3. **Find K nearest neighbors** - identify closest training points\n",
        "4. **Make prediction** - use **averaging** (not voting!)\n",
        "\n",
        "We'll show **both loop versions** (to understand the logic) and **vectorized NumPy versions** (for efficiency).\n",
        "\n",
        "### Key Difference from Classification:\n",
        "- **Classification:** Use majority **voting** among neighbors\n",
        "- **Regression:** Use **averaging** of neighbors' values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries\n",
        "\n",
        "We need:\n",
        "- **NumPy** for numerical operations\n",
        "- **Matplotlib** for visualization\n",
        "- **sklearn.metrics.pairwise_distances** for efficient distance calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import pairwise_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Training Data\n",
        "\n",
        "We have:\n",
        "- **10 training points** with **2 features** each\n",
        "- **Continuous target values** (not classes!)\n",
        "- Target values range from approximately 1.6 to 4.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training data: 10 points with 2 features\n",
        "X_train = np.array( [ [1.536, 3.554],   # Point 0\n",
        "                      [1.771, 2.783],   # Point 1\n",
        "                      [2.506, 2.880],   # Point 2\n",
        "                      [2.652, 4.545],   # Point 3\n",
        "                      [3.590, 3.784],   # Point 4\n",
        "                      [1.279, 1.443],   # Point 5\n",
        "                      [2.000, 2.325],   # Point 6\n",
        "                      [2.096, 0.583],   # Point 7\n",
        "                      [2.539, 1.541],   # Point 8\n",
        "                      [3.251, 0.080] ] ) # Point 9\n",
        "\n",
        "# Target values: continuous numbers (not discrete classes)\n",
        "y_train = np.array( [2.728, 2.456, 2.641, 3.520, 3.667,\n",
        "                     1.612, 2.136, 1.591, 2.143, 1.827] )\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)  # (10, 2) = 10 points, 2 features\n",
        "print(\"Target values shape:\", y_train.shape)   # (10,) = 10 target values\n",
        "print(\"\\nFirst few training points:\")\n",
        "print(X_train[:3])\n",
        "print(\"\\nCorresponding target values:\")\n",
        "print(y_train[:3])\n",
        "print(f\"\\nTarget value range: [{y_train.min():.3f}, {y_train.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Visualize the Data\n",
        "\n",
        "Let's plot our training data to see how it's distributed in 2D space.\n",
        "\n",
        "**Note:** We start by just looking at the data points, **without worrying about their target values yet**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple scatter plot of all training points\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train[:,0], X_train[:,1],\n",
        "           c='steelblue', s=100, alpha=0.6,\n",
        "           edgecolors='black', linewidths=1.5)\n",
        "plt.xlabel('Feature 1 ($x_1$)', fontsize=12)\n",
        "plt.ylabel('Feature 2 ($x_2$)', fontsize=12)\n",
        "plt.title('Training Data Visualization', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis([0, 5, 0, 5])\n",
        "plt.show()\n",
        "\n",
        "print(f\"We have {len(X_train)} training points in 2D space\")\n",
        "print(f\"Each point has an associated target value (continuous)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Define Test Point\n",
        "\n",
        "Now we have a new point **[2.0, 2.0]** that we want to predict a value for.\n",
        "\n",
        "**Question:** What target value should we predict for this point?\n",
        "\n",
        "KNN will answer this by finding the K nearest training points and **averaging their target values**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test point: a new point we want to predict for\n",
        "X_test = np.array([[2.0, 2.0]])\n",
        "\n",
        "print(\"Test point:\", X_test[0])\n",
        "print(\"Shape:\", X_test.shape)  # (1, 2) = 1 point, 2 features\n",
        "\n",
        "# Visualize test point with training data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train[:,0], X_train[:,1],\n",
        "           c='steelblue', s=100, alpha=0.6,\n",
        "           edgecolors='black', linewidths=1.5,\n",
        "           label='Training points')\n",
        "plt.scatter(X_test[:,0], X_test[:,1],\n",
        "           c='red', s=300, marker='*',\n",
        "           edgecolors='black', linewidths=2,\n",
        "           label='Test point')\n",
        "plt.xlabel('Feature 1 ($x_1$)', fontsize=12)\n",
        "plt.ylabel('Feature 2 ($x_2$)', fontsize=12)\n",
        "plt.title('Test Point to Predict', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis([0, 5, 0, 5])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Calculate Distances\n",
        "\n",
        "To find nearest neighbors, we need to calculate the distance from the test point to each training point.\n",
        "\n",
        "We'll use **Euclidean distance**:\n",
        "\n",
        "$$d = \\sqrt{(x_1 - x_1')^2 + (x_2 - x_2')^2}$$\n",
        "\n",
        "### Manual Calculation Example\n",
        "\n",
        "Let's manually calculate the distance from test point **[2.0, 2.0]** to the **first training point [1.536, 3.554]**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual calculation for first training point\n",
        "test_point = X_test[0]       # [2.0, 2.0]\n",
        "first_train_point = X_train[0]  # [1.536, 3.554]\n",
        "\n",
        "print(\"Test point:         \", test_point)\n",
        "print(\"First training point:\", first_train_point)\n",
        "print()\n",
        "\n",
        "# Step 1: Calculate differences\n",
        "diff_1 = test_point[0] - first_train_point[0]\n",
        "diff_2 = test_point[1] - first_train_point[1]\n",
        "print(f\"Step 1 - Differences:\")\n",
        "print(f\"  Feature 1: {test_point[0]:.3f} - {first_train_point[0]:.3f} = {diff_1:.3f}\")\n",
        "print(f\"  Feature 2: {test_point[1]:.3f} - {first_train_point[1]:.3f} = {diff_2:.3f}\")\n",
        "print()\n",
        "\n",
        "# Step 2: Square the differences\n",
        "squared_1 = diff_1 ** 2\n",
        "squared_2 = diff_2 ** 2\n",
        "print(f\"Step 2 - Square the differences:\")\n",
        "print(f\"  ({diff_1:.3f})² = {squared_1:.3f}\")\n",
        "print(f\"  ({diff_2:.3f})² = {squared_2:.3f}\")\n",
        "print()\n",
        "\n",
        "# Step 3: Sum the squared differences\n",
        "sum_squared = squared_1 + squared_2\n",
        "print(f\"Step 3 - Sum:\")\n",
        "print(f\"  {squared_1:.3f} + {squared_2:.3f} = {sum_squared:.3f}\")\n",
        "print()\n",
        "\n",
        "# Step 4: Take square root\n",
        "distance = np.sqrt(sum_squared)\n",
        "print(f\"Step 4 - Square root:\")\n",
        "print(f\"  √{sum_squared:.3f} = {distance:.3f}\")\n",
        "print()\n",
        "print(f\"Distance from test point to first training point: {distance:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 1: Using a Loop (Explicit Logic)\n",
        "\n",
        "Now let's calculate distances to **all** training points using a loop.\n",
        "\n",
        "This shows the logic clearly: we go through each training point one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate distances using a loop\n",
        "distances_loop = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    # Get the training point\n",
        "    train_point = X_train[i]\n",
        "\n",
        "    # Calculate difference for each feature\n",
        "    diff = test_point - train_point\n",
        "\n",
        "    # Square the differences\n",
        "    squared_diff = diff ** 2\n",
        "\n",
        "    # Sum and take square root\n",
        "    distance = np.sqrt(np.sum(squared_diff))\n",
        "\n",
        "    # Store the distance\n",
        "    distances_loop.append(distance)\n",
        "\n",
        "    print(f\"Distance to point {i}: {distance:.4f}\")\n",
        "\n",
        "# Convert to numpy array\n",
        "distances_loop = np.array(distances_loop)\n",
        "print(f\"\\nDistances shape: {distances_loop.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 2: Using Vectorization (Efficient)\n",
        "\n",
        "Instead of looping, we can use `pairwise_distances` from sklearn.\n",
        "\n",
        "This computes **all distances at once** using optimized NumPy operations - much faster!\n",
        "\n",
        "**Note:** `pairwise_distances` returns a 2D array (matrix of distances), so we use `.ravel()` to flatten it to 1D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate distances using pairwise_distances\n",
        "distances_2d = pairwise_distances(X_test, X_train)\n",
        "print(\"2D array shape:\", distances_2d.shape)  # (1, 10) = 1 test point, 10 training points\n",
        "print(\"2D array:\")\n",
        "print(distances_2d)\n",
        "print()\n",
        "\n",
        "# Flatten to 1D array using .ravel()\n",
        "distances_vectorized = distances_2d.ravel()\n",
        "print(\"1D array shape:\", distances_vectorized.shape)  # (10,)\n",
        "print(\"1D array:\")\n",
        "print(distances_vectorized)\n",
        "print()\n",
        "\n",
        "# Verify both approaches give same result\n",
        "print(\"Results match:\", np.allclose(distances_loop, distances_vectorized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Find K Nearest Neighbors\n",
        "\n",
        "Now we have distances to all training points. We need to find the **5 closest points** (K=5).\n",
        "\n",
        "**How do we find them?**\n",
        "We need to:\n",
        "1. Sort the distances from smallest to largest\n",
        "2. Get the **indices** (positions) of the 5 smallest distances\n",
        "\n",
        "### What is `argsort()`?\n",
        "\n",
        "`argsort()` returns the **indices** that would sort an array, not the sorted values themselves.\n",
        "\n",
        "**Example:**\n",
        "- Array: [4.5, 2.1, 7.3, 1.8, 3.2]\n",
        "- `argsort()` returns: [3, 1, 4, 0, 2]\n",
        "- This means: index 3 has the smallest value (1.8), then index 1 (2.1), then index 4 (3.2), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's see which indices argsort returns\n",
        "sorted_indices = np.argsort(distances_vectorized)\n",
        "print(\"All indices sorted by distance:\")\n",
        "print(sorted_indices)\n",
        "print()\n",
        "\n",
        "# Get the first 5 indices (K=5 nearest neighbors)\n",
        "K = 5\n",
        "nearest_indices = sorted_indices[:K]\n",
        "print(f\"Indices of {K} nearest neighbors:\")\n",
        "print(nearest_indices)\n",
        "print()\n",
        "\n",
        "# Show the actual distances\n",
        "print(f\"Distances to these {K} nearest neighbors:\")\n",
        "for i, idx in enumerate(nearest_indices):\n",
        "    print(f\"  Neighbor {i+1}: point {idx}, distance = {distances_vectorized[idx]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Get Target Values of Nearest Neighbors\n",
        "\n",
        "Now we know **which** training points are closest.\n",
        "\n",
        "Let's see what **target values** these neighbors have.\n",
        "\n",
        "Remember: In regression, each training point has a continuous target value (not a class label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the target values of the K nearest neighbors\n",
        "neighbor_values = y_train[nearest_indices]\n",
        "\n",
        "print(f\"Target values of {K} nearest neighbors:\")\n",
        "print(neighbor_values)\n",
        "print()\n",
        "\n",
        "# Show details\n",
        "print(\"Detailed view:\")\n",
        "for i, idx in enumerate(nearest_indices):\n",
        "    print(f\"  Neighbor {i+1}: point {idx}, target = {y_train[idx]:.3f}, distance = {distances_vectorized[idx]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Make Prediction via Averaging\n",
        "\n",
        "Now we have the target values of the K nearest neighbors.\n",
        "\n",
        "**For regression, we predict by taking the average (mean) of these values.**\n",
        "\n",
        "### Approach 1: Manual Averaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average manually\n",
        "sum_values = 0\n",
        "for value in neighbor_values:\n",
        "    sum_values += value\n",
        "\n",
        "average_manual = sum_values / len(neighbor_values)\n",
        "\n",
        "print(\"Target values:\", neighbor_values)\n",
        "print(f\"\\nSum of values: {sum_values:.3f}\")\n",
        "print(f\"Number of neighbors: {len(neighbor_values)}\")\n",
        "print(f\"Average: {sum_values:.3f} / {len(neighbor_values)} = {average_manual:.3f}\")\n",
        "print(f\"\\nPredicted value (manual): {average_manual:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Approach 2: Using NumPy's `mean()`\n",
        "\n",
        "`np.mean()` or `.mean()` calculates the average efficiently.\n",
        "\n",
        "This is more concise than manual summation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average using NumPy\n",
        "prediction_numpy = neighbor_values.mean()\n",
        "\n",
        "print(\"Target values:\", neighbor_values)\n",
        "print(f\"Mean: {prediction_numpy:.3f}\")\n",
        "print()\n",
        "\n",
        "# Verify both approaches match\n",
        "print(f\"Manual and NumPy predictions match: {np.isclose(average_manual, prediction_numpy)}\")\n",
        "print(f\"Difference: {abs(average_manual - prediction_numpy):.10f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Visualize the Result\n",
        "\n",
        "Let's visualize the test point, its K nearest neighbors, and their target values.\n",
        "\n",
        "We'll now color the training points by their target values to see the pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the regression result\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left plot: Show all points and K nearest neighbors\n",
        "ax1.scatter(X_train[:,0], X_train[:,1],\n",
        "           c='steelblue', s=100, alpha=0.3,\n",
        "           edgecolors='black', linewidths=1, label='Training points')\n",
        "\n",
        "# Highlight the K nearest neighbors\n",
        "nearest_neighbors_X = X_train[nearest_indices]\n",
        "ax1.scatter(nearest_neighbors_X[:,0], nearest_neighbors_X[:,1],\n",
        "           c='green', s=200, marker='s', alpha=0.7,\n",
        "           edgecolors='darkgreen', linewidths=2, label=f'{K} Nearest Neighbors')\n",
        "\n",
        "# Plot test point\n",
        "ax1.scatter(X_test[:,0], X_test[:,1],\n",
        "           c='red', s=400, marker='*',\n",
        "           edgecolors='black', linewidths=2,\n",
        "           label=f'Test point (predicted: {prediction_numpy:.3f})')\n",
        "\n",
        "ax1.set_xlabel('Feature 1 ($x_1$)', fontsize=12)\n",
        "ax1.set_ylabel('Feature 2 ($x_2$)', fontsize=12)\n",
        "ax1.set_title(f'KNN Regression: Finding Neighbors (K={K})', fontsize=14)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.axis([0, 5, 0, 5])\n",
        "\n",
        "# Right plot: Show points colored by target values\n",
        "scatter = ax2.scatter(X_train[:,0], X_train[:,1],\n",
        "                     c=y_train, cmap='viridis', s=100, alpha=0.6,\n",
        "                     edgecolors='black', linewidths=1.5)\n",
        "plt.colorbar(scatter, ax=ax2, label='Target Value')\n",
        "\n",
        "# Highlight nearest neighbors\n",
        "ax2.scatter(nearest_neighbors_X[:,0], nearest_neighbors_X[:,1],\n",
        "           c='red', s=200, marker='s', alpha=0.5,\n",
        "           edgecolors='darkred', linewidths=2, label=f'{K} Nearest Neighbors')\n",
        "\n",
        "# Plot test point\n",
        "ax2.scatter(X_test[:,0], X_test[:,1],\n",
        "           c='red', s=400, marker='*',\n",
        "           edgecolors='black', linewidths=2,\n",
        "           label=f'Test point')\n",
        "\n",
        "ax2.set_xlabel('Feature 1 ($x_1$)', fontsize=12)\n",
        "ax2.set_ylabel('Feature 2 ($x_2$)', fontsize=12)\n",
        "ax2.set_title('Target Values Distribution', fontsize=14)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.axis([0, 5, 0, 5])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTest point {X_test[0]} prediction: {prediction_numpy:.3f}\")\n",
        "print(f\"Based on averaging {K} nearest neighbors:\")\n",
        "for i, val in enumerate(neighbor_values):\n",
        "    print(f\"  Neighbor {i+1}: target = {val:.3f}\")\n",
        "print(f\"Average: {prediction_numpy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "We've walked through all the computational steps of KNN Regression:\n",
        "\n",
        "1. ✅ **Visualized data** - saw training points in 2D space\n",
        "2. ✅ **Calculated distances** - computed Euclidean distance from test point to each training point\n",
        "3. ✅ **Found K nearest neighbors** - used `argsort()` to find indices of 5 closest points\n",
        "4. ✅ **Made prediction** - used **averaging** of the K neighbors' target values\n",
        "\n",
        "### Key Difference: Classification vs Regression\n",
        "\n",
        "| Aspect | Classification | Regression |\n",
        "|--------|---------------|-----------|\n",
        "| **Target values** | Discrete classes (0, 1, 2, ...) | Continuous numbers (1.5, 2.3, ...) |\n",
        "| **Prediction method** | Majority voting | Averaging |\n",
        "| **Output** | Class label | Continuous value |\n",
        "\n",
        "### Key NumPy Operations Used:\n",
        "\n",
        "- **`pairwise_distances(X_test, X_train)`** - efficiently calculates all distances\n",
        "- **`.ravel()`** - flattens 2D array to 1D\n",
        "- **`np.argsort(distances)`** - returns indices that would sort the array\n",
        "- **`array[indices]`** - fancy indexing to select multiple elements\n",
        "- **`.mean()`** or `np.mean()` - calculates average\n",
        "\n",
        "### Why Both Approaches?\n",
        "\n",
        "- **Loop versions** help you understand the logic step-by-step\n",
        "- **Vectorized versions** are much faster for large datasets\n",
        "\n",
        "In practice, use vectorized operations, but understanding loops helps you know what's happening under the hood!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFSQie0+xeC4hIKO4jdigH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
