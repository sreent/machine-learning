{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/K-Nearest%20Neighbhours%20Classification/KNN%20Classification%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Nearest Neighbors (KNN) Classification"
   ],
   "metadata": {
    "id": "OpLpu61iiDz9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab, you will implement a K-Nearest Neighbors classifier from scratch, tune its parameters, and apply it to real data. Along the way, you\u2019ll answer conceptual questions and create visualizations to deepen your understanding. By the end, you will have a clear grasp of how KNN works, how to evaluate it using accuracy and confusion matrices, and why practices like feature scaling and proper data splitting are critical.\n"
   ],
   "metadata": {
    "id": "ZahTMlifiEBa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of KNN\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple, instance-based learning algorithm used for classification (and regression). For classification, KNN makes predictions by looking at the K training examples closest (in feature space) to a new data point, and assigning the majority class among those neighbors. It is considered a lazy learning method because it does not build an explicit model; instead, all training data is stored, and generalization is postponed until a query (prediction) is made.\n",
    "\n",
    "How KNN Classification Works:\n",
    "\n",
    "1.\tChoose K: Decide on the number of neighbors (K) to use for predictions.\n",
    "2.\tCompute Distances: To classify a new point, compute the distance between this point and all points in the training set (commonly using Euclidean distance).\n",
    "3.\tFind Nearest Neighbors: Identify the K training points with the smallest distances to the new point.\n",
    "4.\tMajority Vote: Among these K neighbors, count the occurrences of each class and take the majority vote. The new point is predicted to belong to the class with the most votes.\n",
    "5.\tReturn the Prediction: Assign the predicted class to the new point.\n"
   ],
   "metadata": {
    "id": "gX3UlspviNKs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image.png](data:image/png;base64,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)"
   ],
   "metadata": {
    "id": "gNMBXNcBQ2we"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For example, if K=3 and among the 3 nearest neighbors 2 are class Green and 1 is class Red, the new point will be classified as class Green.\n",
    "\n"
   ],
   "metadata": {
    "id": "IHskpfkYP0cg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visual K Progression\n",
    "\n",
    "To understand how the choice of K affects predictions, let's visualize how KNN makes decisions for different K values. We'll create a simple 2D dataset and observe how the prediction changes as we vary K from 1 to 5.\n",
    "\n",
    "For each value of K, we'll:\n",
    "- Circle the K nearest neighbors to a query point\n",
    "- Count votes from each class (e.g., \"# Green = 2, # Red = 1\")\n",
    "- Show the final prediction based on majority vote\n",
    "\n",
    "This visualization will demonstrate:\n",
    "- **Small K (K=1, K=2)**: More sensitive to individual points, can be noisy\n",
    "- **Medium K (K=3, K=4)**: More balanced predictions\n",
    "- **Larger K (K=5)**: Smoother decision boundaries, more stable predictions"
   ],
   "metadata": {
    "id": "dc_dTo-5VVLU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from collections import Counter\n",
    "\n",
    "# Create a simple 2D dataset\n",
    "np.random.seed(42)\n",
    "# Class 0 (Red): centered around (2, 2)\n",
    "class_0 = np.random.randn(15, 2) * 0.5 + np.array([2, 2])\n",
    "# Class 1 (Green): centered around (4, 4)\n",
    "class_1 = np.random.randn(15, 2) * 0.5 + np.array([4, 4])\n",
    "\n",
    "X_train = np.vstack([class_0, class_1])\n",
    "y_train = np.array([0]*15 + [1]*15)\n",
    "\n",
    "# Query point to classify\n",
    "query_point = np.array([3.0, 3.5])\n",
    "\n",
    "# Calculate distances from query point to all training points\n",
    "distances = np.sqrt(np.sum((X_train - query_point)**2, axis=1))\n",
    "\n",
    "# Create subplots for K=1 to K=5\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "k_values = [1, 2, 3, 4, 5]\n",
    "\n",
    "for idx, k in enumerate(k_values):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Find K nearest neighbors\n",
    "    nearest_indices = np.argsort(distances)[:k]\n",
    "    nearest_labels = y_train[nearest_indices]\n",
    "\n",
    "    # Count votes\n",
    "    vote_counts = Counter(nearest_labels)\n",
    "    prediction = max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "    # Plot all training points\n",
    "    ax.scatter(class_0[:, 0], class_0[:, 1], c='red', s=100, alpha=0.6, label='Class 0 (Red)', edgecolors='black')\n",
    "    ax.scatter(class_1[:, 0], class_1[:, 1], c='green', s=100, alpha=0.6, label='Class 1 (Green)', edgecolors='black')\n",
    "\n",
    "    # Highlight K nearest neighbors with circles\n",
    "    for i in nearest_indices:\n",
    "        circle = Circle(X_train[i], 0.2, color='blue', fill=False, linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    # Plot query point\n",
    "    pred_color = 'red' if prediction == 0 else 'green'\n",
    "    ax.scatter(query_point[0], query_point[1], c=pred_color, s=300, marker='*',\n",
    "               edgecolors='black', linewidth=2, label='Query Point', zorder=5)\n",
    "\n",
    "    # Add vote count and prediction text\n",
    "    red_votes = vote_counts.get(0, 0)\n",
    "    green_votes = vote_counts.get(1, 0)\n",
    "    pred_class = \"Red\" if prediction == 0 else \"Green\"\n",
    "\n",
    "    ax.text(0.5, 0.95, f'K = {k}', transform=ax.transAxes, fontsize=14,\n",
    "            fontweight='bold', ha='center', va='top')\n",
    "    ax.text(0.5, 0.88, f'# Red = {red_votes}, # Green = {green_votes}',\n",
    "            transform=ax.transAxes, fontsize=11, ha='center', va='top')\n",
    "    ax.text(0.5, 0.80, f'Prediction: {pred_class}', transform=ax.transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center', va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor=pred_color, alpha=0.3))\n",
    "\n",
    "    ax.set_xlim(0, 6)\n",
    "    ax.set_ylim(0, 6)\n",
    "    ax.set_xlabel('Feature 1', fontsize=10)\n",
    "    if idx == 0:\n",
    "        ax.set_ylabel('Feature 2', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('How K Affects KNN Predictions: Visualizing K Nearest Neighbors', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- As K increases, the prediction becomes more stable and less sensitive to individual points\")\n",
    "print(\"- Small K values can lead to overfitting (too sensitive to noise)\")\n",
    "print(\"- Large K values can lead to underfitting (too smooth, may ignore local patterns)\")"
   ],
   "metadata": {
    "id": "ovJ0rkjUVVLU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question**: In KNN classification, the parameter K refers to:\n",
    "\n",
    "> A. The number of nearest neighbors used to determine the class of a new data point.\n",
    ">\n",
    "> B. The number of features (dimensions) in the dataset.\n",
    ">\n",
    "> C. The number of classes in the classification problem.\n",
    ">\n",
    "> D. The exponent used in the distance calculation.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is TRUE**: K is the number of nearest neighbors whose votes determine the predicted class (e.g., K=5 means the 5 closest neighbors vote)\n",
    "- **B is FALSE**: The number of features is typically denoted by n, p, or d (dimensions), not K\n",
    "- **C is FALSE**: The number of classes is independent of K; you can use any K value regardless of how many classes exist\n",
    "- **D is FALSE**: The exponent in distance metrics (like Minkowski distance) is typically denoted by p, not K\n",
    "\n",
    "**Key Insight**: In KNN classification, the predicted class is determined by majority voting among the K nearest neighbors.\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "1H6lgCADiwfx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bias-Variance Trade-off in KNN\n",
    "\n",
    "The choice of K has a significant effect on the model\u2019s complexity and performance:\n",
    "\n",
    "- Small K (e.g., K=1) tends to lead to complex, highly flexible decision boundaries that closely follow the training data. This can result in overfitting (low bias, high variance) \u2013 high accuracy on training data but low accuracy on unseen data.\n",
    "- Large K (e.g., K large relative to number of samples) produces smoother, less complex decision boundaries because predictions are averaged over many neighbors. This can result in underfitting (high bias, low variance) \u2013 both training and validation accuracy might be low because the model is too simple to capture patterns.\n",
    "\n",
    "We will observe this behavior when we experiment with different values of K."
   ],
   "metadata": {
    "id": "-L4gKSiL-ERn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distance Metrics and Feature Scaling\n",
    "\n",
    "KNN relies on a distance measure to determine \u201cnearest\u201d neighbors. Common choices include:\n",
    "\n",
    "-\tEuclidean distance (L2 norm)\n",
    "-\tManhattan distance (L1 norm)\n",
    "-\tCosine distance, etc.\n",
    "\n",
    "Feature scaling is crucial for KNN because the distance computation is sensitive to the scale of features. If one feature has a much larger range than others, it can dominate the distance calculation and distort nearest neighbor relationships. We typically address this by scaling or standardizing features (e.g., using z-scores) so that all features contribute more equally to distance calculations. You will see the impact of scaling when we apply KNN to a real dataset."
   ],
   "metadata": {
    "id": "CV8NW9n4i9hz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question**: When using KNN on a dataset with features measured in very different units (e.g., one feature in the range 0-1000 and another in 0-1), what is the best practice?\n>\n> A. Normalize or standardize the features so they have similar scales before training KNN.\n>\n> B. Remove the feature with the larger range to avoid dominance in distance calculation.\n>\n> C. Use a different distance metric that ignores scale differences, so scaling is not needed.\n>\n> D. Increase K proportionally to the range differences to offset the scale issue.\n\n<details>\n\n<summary>Click to reveal answer</summary>\n\n**Correct Answer: A**\n\n**Explanation:**\n- **A is TRUE**: Normalization (e.g., min-max scaling to [0,1]) or standardization (e.g., z-score to mean=0, std=1) ensures all features contribute equally to distance calculations\n- **B is FALSE**: Removing features loses valuable information; scaling preserves all features while fixing the scale issue\n- **C is FALSE**: No standard distance metric can ignore scale differences; all distance-based methods are affected by feature scales\n- **D is FALSE**: Changing K doesn't address the fundamental problem that features with larger ranges will dominate the distance metric\n\n**Example**: If Feature1 ranges 0-1 and Feature2 ranges 0-1000, the distance will be almost entirely determined by Feature2, making Feature1 nearly irrelevant. Scaling fixes this.\n\n</details>\n\n**Key Insight**: KNN relies entirely on distance calculations between data points. When features have different scales (e.g., age in years vs. income in dollars), features with larger ranges will dominate the distance metric, making the algorithm biased toward those features. Feature scaling (like standardization or normalization) ensures all features contribute equally to the distance calculation, which is essential for KNN's performance."
   ],
   "metadata": {
    "id": "cB_Uc4bSjQl5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN Algorithm: Pseudocode\n",
    "\n",
    "Before implementing KNN from scratch, let's understand the algorithm's structure through formal pseudocode. KNN is a **lazy learning** algorithm, meaning it doesn't build an explicit model during training\u2014it simply stores the training data and performs all computation during prediction.\n",
    "\n",
    "### Formal Pseudocode\n",
    "\n",
    "```\n",
    "# ============================================\n",
    "# Inputs\n",
    "# ============================================\n",
    "# data \u2190 training set of N examples (x, y)\n",
    "# k \u2190 number of neighbours\n",
    "# metric \u2190 distance function (e.g., Euclidean, Manhattan)\n",
    "# X_query \u2190 set of examples to classify\n",
    "\n",
    "# ============================================\n",
    "# ----- \"fit\" (lazy) -----\n",
    "# ============================================\n",
    "X_train \u2190 data.x\n",
    "y_train \u2190 data.y\n",
    "\n",
    "# ============================================\n",
    "# ----- predict -----\n",
    "# ============================================\n",
    "\u0177 \u2190 list of length |X_query|\n",
    "FOR i = 1 TO |X_query| DO\n",
    "    x* \u2190 X_query[i]\n",
    "    d \u2190 distances from x* to all X_train using metric\n",
    "    J \u2190 indices of the k smallest values in d\n",
    "    \u0177[i] \u2190 majority_vote(y_train[J])\n",
    "END FOR\n",
    "RETURN \u0177\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **Lazy Learning**: The `fit` phase simply stores the training data\u2014no model parameters are learned.\n",
    "2. **Prediction Phase**: All the work happens during prediction:\n",
    "   - Calculate distances from the query point to all training points\n",
    "   - Find the K nearest neighbors\n",
    "   - Take a majority vote among their labels\n",
    "3. **Computational Cost**: For each prediction, we compute distances to all N training points, making KNN O(N) per prediction.\n",
    "\n",
    "Now let's implement this algorithm from scratch!"
   ],
   "metadata": {
    "id": "FQ5oC0KCVVLX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing a Custom KNN Classifier\n",
    "\n",
    "Instead of using sklearn.neighbors.KNeighborsClassifier, we will build our own MyKNNClassifier from scratch. This will solidify our understanding of how the algorithm works internally. We will incorporate some best practices into our implementation, such as input validation (shape checks, value checks) and ensuring reproducibility where relevant.\n",
    "\n",
    "Let\u2019s start by implementing the MyKNNClassifier class with the following specifications:\n",
    "- It should follow the basic structure of scikit-learn classifiers, with fit and predict methods.\n",
    "-\tIn fit(X, y), simply store the training data (X and y). We will use underscores (X_train_, y_train_) to indicate stored fitted data attributes.\n",
    "-\tIn predict(X), use the KNN algorithm: for each sample in X, compute distances to all points in X_train_, find the K nearest neighbors, and return the majority class among those neighbors.\n",
    "-\tInclude shape guards and input validation:\n",
    "  -\tCheck that X and y have appropriate shapes in fit (e.g., same number of samples).\n",
    "  -\tEnsure that k is a positive integer and not greater than the number of training samples.\n",
    "  -\tOptionally, ensure that the number of features in any data passed to predict matches the number in X_train_.\n",
    "-\tWe will use Euclidean distance by default (you can allow other metrics as an extension). To compute distances efficiently, we can use sklearn.metrics.pairwise_distances or NumPy operations.\n",
    "-\tUse the Python collections.Counter to perform the majority vote among neighbors\u2019 labels."
   ],
   "metadata": {
    "id": "yUBHykTrn7M9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a scaffold of the MyKNNClassifier class. Fill in the TODO sections to complete the implementation:"
   ],
   "metadata": {
    "id": "zvWu4Jlcn7W6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class MyKNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=3, metric='euclidean'):\n",
    "        \"\"\"KNN classifier: majority vote among k nearest neighbours.\"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"'Fit' (lazy): store training arrays to use during predict().\"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        # TODO: store training data (use attribute names referenced in predict)\n",
    "        self.X_train_ = _________\n",
    "        self.y_train_ = _________\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return one predicted label per row in X (same order as X).\"\"\"\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        # TODO: prepare output array with same dtype as training labels\n",
    "        y_pred = _________   # e.g., np.empty(X.shape[0], dtype=self.y_train_.dtype)\n",
    "\n",
    "        for i, x in enumerate(X):\n",
    "            # TODO: compute distances from x to all training points\n",
    "            d = _________     # use pairwise_distances(self.X_train_, x[None, :], metric=self.metric).ravel()\n",
    "\n",
    "            # TODO: get indices of the k smallest distances (nearest neighbours)\n",
    "            J = _________     # e.g., np.argsort(d)[:self.k]\n",
    "\n",
    "            # TODO: majority vote (deterministic tie-break via np.unique)\n",
    "            labels, counts = _________   # e.g., np.unique(self.y_train_[J], return_counts=True)\n",
    "            y_pred[i] = _________        # e.g., labels[np.argmax(counts)]\n",
    "\n",
    "        # TODO: return predictions as a 1D NumPy array\n",
    "        return _________"
   ],
   "metadata": {
    "id": "eTGQx81BiMbG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you have filled in the implementation, let\u2019s test our custom classifier on a simple dataset to ensure it works as expected."
   ],
   "metadata": {
    "id": "Quw6AEuaomvh"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6xHF9fvVVLX"
   },
   "source": [
    "> **Question:** Unlike algorithms such as logistic regression or decision trees, KNN has virtually no training time but can be slow at prediction time, especially with large datasets. What best explains this computational characteristic?\n>\n> A. KNN doesn't learn a model during training\u2014it simply stores the data. Each prediction requires computing distances to all training examples and finding the K nearest neighbors, which scales linearly with dataset size\n>\n> B. Training is fast because KNN only needs to compute class frequencies and decision boundaries once; predictions are slower because they require checking which region of the decision boundary the new point falls into\n>\n> C. KNN uses efficient hashing during training to organize points into buckets by their feature values, making training fast; predictions are slower because hash lookups and collision resolution add computational overhead\n>\n> D. The training phase builds an optimized lookup table mapping feature combinations to class labels, which is quick; predictions are slower because they must search this table and handle cases where exact matches aren't found\n\n<details>\n\n<summary>Click to reveal answer</summary>\n\n**Correct Answer: A**\n\n**Explanation:**\n\nKNN is an **instance-based** or **lazy learning** algorithm, which fundamentally differs from eager learners like logistic regression or neural networks.\n\n**A is TRUE**: This correctly describes KNN's behavior:\n- **\"Training\" phase**: Simply stores the (X, y) pairs in memory - no learning happens\n  - Complexity: O(1) for storage operations, or O(N) to load N points\n  - No optimization, no gradient descent, no parameter fitting\n- **Prediction phase**: For EACH new point:\n  1. Compute distance to ALL N training points: O(N \u00d7 d) where d = dimensions\n  2. Find K smallest distances: O(N) or O(N log K) depending on implementation\n  3. Majority vote among K neighbors' classes: O(K)\n- **Result**: Prediction time grows with training set size (problematic for large datasets)\n\n**B is FALSE**: This describes parametric models, not KNN:\n- KNN does NOT compute decision boundaries during training\n- It doesn't pre-calculate class frequencies or separating hyperplanes\n- Decision boundaries in KNN are implicit and only emerge when making predictions\n- Each prediction independently evaluates distances; there's no \"region checking\"\n\n**C is FALSE**: Standard KNN does NOT use hashing:\n- No hash tables or buckets are created during training\n- Feature-based hashing would only work for categorical features with exact matches\n- Continuous features (which KNN typically uses) can't be effectively hashed\n- Locality-sensitive hashing (LSH) exists for approximate KNN but isn't the default behavior\n\n**D is FALSE**: KNN does NOT build lookup tables:\n- A lookup table assumes discrete feature combinations, but KNN handles continuous features\n- The feature space is continuous and infinite, making exhaustive lookup tables impossible\n- KNN must handle arbitrary new points that don't match any training feature values\n- This describes more of a decision table or rule-based classifier, not KNN\n\n**Computational Comparison:**\n\n| Algorithm | Training Time | Prediction Time | Why? |\n|-----------|---------------|-----------------|------|\n| KNN | O(1) | O(N \u00d7 d) per prediction | No training; must scan all data |\n| Logistic Regression | O(iterations \u00d7 N \u00d7 d) | O(d) per prediction | Learn parameters; simple dot product |\n| Decision Tree | O(N \u00d7 d \u00d7 log N) | O(log N) per prediction | Build tree structure; traverse path |\n\n**Real-World Implications:**\n- **Small datasets** (N < 10,000): KNN is convenient - no training needed!\n- **Large datasets** (N > 100,000): KNN becomes impractical for real-time predictions\n- **Production systems**: KNN rarely used due to slow prediction scaling\n\n**Advanced Note**: Some libraries use approximate nearest neighbor algorithms (KD-trees, Ball-trees, LSH) to speed up predictions, but:\n- These DO require training time to build the index structure\n- They only help significantly in low dimensions (< 20 features)\n- The standard sklearn implementation uses brute force for small datasets\n\n</details>\n\n**Key Insight**: KNN is a lazy learning algorithm that defers all computation until prediction time. During \"training,\" it simply stores the data points. This makes training instantaneous but means every prediction requires computing distances to all training samples, making predictions slow on large datasets. This is fundamentally different from eager learners like logistic regression that invest time upfront to learn parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A Dataset for Visualization\n",
    "\n",
    "To visualize how KNN works, we\u2019ll use R ElemStatLearn's \"Simulated Mixture Gaussian\" dataset:\n",
    "-\tTotal points: 200 (100 per class).\n",
    "-\tClasses: 2\n",
    "-\tFeatures: $x_1$ and $x_2$ (2D), which we can plot on a plane.\n",
    "-\tThis dataset is partially overlapping and not linearly separable, which is perfect for exploring KNN decision boundaries and performance.\n",
    "\n",
    "Let\u2019s load the dataset:"
   ],
   "metadata": {
    "id": "OiMSd5giouAD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL for our dataset, mixture-example.csv\n",
    "URL = \"https://drive.google.com/file/d/1l0QDFXeyrelvjXlyhnj4ppP_SSTABIKp/view?usp=sharing\"\n",
    "FILE_PATH = \"https://drive.google.com/uc?export=download&id=\" + URL.split(\"/\")[-2]\n",
    "\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Filter data by labels\n",
    "X = data[['X', 'Y']].values\n",
    "y = data['Label'].values\n",
    "\n",
    "print(\"Dataset shape:\", X.shape, \"Labels shape:\", y.shape)\n"
   ],
   "metadata": {
    "id": "cya5lCOGolau"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the above code will load the dataset and print the shapes. You should see Dataset shape: (200, 2) Labels shape: (200,) confirming we have 200 samples with 2 features each. Next, let\u2019s visualize this dataset to understand its structure:"
   ],
   "metadata": {
    "id": "P6jzwp3Jolzg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], color='lightblue', label='0', marker='o')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], color='orange', label='1', marker='o')\n",
    "\n",
    "plt.xlabel('$x_1$', fontsize=20)\n",
    "plt.ylabel('$x_2$', fontsize=20)\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "XXDV0ifa3WHF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the scatter plot, points of different colors represent the two classes (for example, blue for class 0 and red for class 1). Notice that the classes are composed of multiple clusters spread around the space, with some overlap between the blue and red points. This will make the classification task non-trivial, which is great for exploring how KNN behaves."
   ],
   "metadata": {
    "id": "QHeeDVZt3m8g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting into Train, Validation, and Test Sets\n",
    "\n",
    "To evaluate our model properly and tune the hyperparameter K, we will split the data into three sets:\n",
    "\t\u2022\tTraining set (Train) \u2013 used to fit the KNN model.\n",
    "\t\u2022\tValidation set (Val) \u2013 used to select the best K (tuning the hyperparameter). We will test different K values on this set.\n",
    "\t\u2022\tTest set (Test) \u2013 used only for final evaluation of the model\u2019s performance after tuning, to simulate unseen data.\n",
    "\n",
    "We\u2019ll do a 60%/20%/20% split for train/val/test. We will stratify the split to maintain the class proportions in each subset (ensuring each subset has roughly equal class 0 vs class 1 distribution). We also set a random_state for reproducibility:"
   ],
   "metadata": {
    "id": "7WA3Ep2T3spD"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jj9Ro5tdVVLY"
   },
   "source": [
    "**Note on Feature Scaling:** You may notice we haven't discussed feature scaling yet for this Mixture Gaussian dataset. This is because both features (x\u2081 and x\u2082) are already on similar scales (roughly -4 to +4 range).\n",
    "\n",
    "However, in real-world datasets\u2014like the Wine dataset we'll work with later\u2014features often have vastly different scales (e.g., Proline: 280-1700 vs Malic acid: 0.7-6). In those cases, feature scaling becomes **critical** for KNN performance. We'll explore this in detail in the second part of this lab."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: First, split into Train (60%) and Temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "# TODO: Next, split the Temp 40% into equal halves for Validation (20%) and Test (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"Validation size:\", X_val.shape[0], \"Test size:\", X_test.shape[0])"
   ],
   "metadata": {
    "id": "zS5RBkbZ3ifX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this split, you should see roughly: Train size 120, Validation size 40, Test size 40 (since 60/20/20 of 200 is 120/40/40). It\u2019s important that we do not touch the test set until the very end when we\u2019re ready to evaluate our final model. Using the test set in tuning would be a form of data leakage and could make our evaluation overly optimistic."
   ],
   "metadata": {
    "id": "sr2X48fc4LOc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have our data split, let\u2019s use our MyKNNClassifier to fit on the training set and evaluate on the validation set. This will serve as a quick check that our implementation works and give us a baseline accuracy for an arbitrary choice of K (say, K=3):"
   ],
   "metadata": {
    "id": "0wFPuf7S4lx1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate our KNN classifier with K=3 (arbitrary choice to start)\n",
    "knn = MyKNNClassifier(k=_________, metric=_________)\n",
    "knn.fit(_________, _________)\n",
    "\n",
    "# TODO: Predict on the validation set\n",
    "y_pred_val = knn.predict(_________)\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, _________)\n",
    "print(f\"Validation accuracy with k=3: {val_accuracy:.2f}\")"
   ],
   "metadata": {
    "id": "hAtf9us64G24"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The printed accuracy is the proportion of validation points correctly classified with K=3. This gives a sense of how the model is doing with this choice. However, we shouldn\u2019t read too much into a single result \u2014 we need to see how K affects performance overall."
   ],
   "metadata": {
    "id": "K-RYU9Cl4s7W"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning the Hyperparameter K\n",
    "\n",
    "Let\u2019s systematically evaluate how the choice of K affects the model. We will try a range of K values and compute the accuracy on both the training set and validation set for each K. Tracking training accuracy along with validation accuracy is informative:\n",
    "\n",
    "- Training accuracy tells us how well the model fits the training data.\n",
    "- Validation accuracy tells us how well the model generalizes to unseen data (for different K).\n",
    "\n",
    "By comparing the two, we can diagnose overfitting or underfitting:\n",
    "\n",
    "- If training accuracy is much higher than validation accuracy for a certain K, the model might be overfitting (performing well on train, poorly on val).\n",
    "- If both training and validation accuracies are low, the model might be underfitting (not even fitting the train set well).\n",
    "\n",
    "We\u2019ll evaluate K from 1 up to, say, 15 and record the accuracies:"
   ],
   "metadata": {
    "id": "oxHuV0vY4xNS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "ks = range(1, 16)\n",
    "\n",
    "for k in ks:\n",
    "    # TODO: Set hyperparameters, i.e. k and metric for our KNN classifier\n",
    "    knn = MyKNNClassifier(k=_________, metric=_________)\n",
    "    # TODO: Train final model on training set\n",
    "    knn.fit(_________, _________)\n",
    "    # TODO: Predict on the training set\n",
    "    y_pred_train = _________\n",
    "    # TODO: Compute validation accuracy\n",
    "    train_acc = accuracy_score(_________, _________)\n",
    "    # TODO: Predict on the validation set\n",
    "    y_pred_val = knn.predict(_________)\n",
    "    # TODO: Accuracy on validation set\n",
    "    val_acc = accuracy_score(_________, _________)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "# Determine the best K based on highest validation accuracy\n",
    "best_k = np.argmax(val_accuracies) + 1  # +1 because index 0 corresponds to k=1\n",
    "best_val_acc = val_accuracies[best_k - 1]\n",
    "print(f\"Best K by validation accuracy = {best_k}, which gave val accuracy = {best_val_acc:.3f}\")"
   ],
   "metadata": {
    "id": "cjHkTZ4j5DAk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let\u2019s plot the accuracy vs. K to visualize the trend:"
   ],
   "metadata": {
    "id": "ipyKdwVg47b3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ks, train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(ks, val_accuracies, marker='s', label='Validation Accuracy')\n",
    "plt.xticks(ks)\n",
    "plt.xlabel('K (Number of Neighbours)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs K for KNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "4lY4Blxs4wVz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plot shows two curves: one for training accuracy and one for validation accuracy as K increases. Observe the behavior:\n",
    "\n",
    "- At K=1 (far left), training accuracy is likely 100% (each point is its own nearest neighbor, so it perfectly predicts training data) while validation accuracy might be significantly lower. This is a sign of overfitting (model too complex, essentially memorizing training data).\n",
    "- As K increases, training accuracy usually drops (the model is less flexible), while validation accuracy may initially increase as overfitting reduces, then eventually decrease once K becomes too large (model underfits by being too rigid).\n",
    "- There is often a sweet spot where validation accuracy is maximized \u2014 that is our chosen best K."
   ],
   "metadata": {
    "id": "MKgWuoVF5ONP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question:** You train a KNN model with K=1 and observe 100% training accuracy but only 70% validation accuracy. What is the most likely explanation?\n",
    ">\n",
    "> A) The model is overfitting - K=1 creates highly complex decision boundaries that memorize training noise but fail to generalize\n",
    ">\n",
    "> B) The model needs more features - K=1 doesn't have enough information to make good predictions\n",
    ">\n",
    "> C) The validation set is too small - increasing its size would likely improve the 70% validation accuracy to match training\n",
    ">\n",
    "> D) The distance metric is poorly chosen - switching from Euclidean to Manhattan distance would likely close the accuracy gap\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is TRUE**: K=1 creates the most complex possible decision boundary in KNN. Each training point becomes its own \"island\" in the decision space, leading to perfect training accuracy but poor generalization. This is a classic case of overfitting.\n",
    "- **B is FALSE**: The issue isn't lack of features - K=1 already uses all available features. Adding more features would likely make overfitting worse.\n",
    "- **C is FALSE**: While validation set size can affect estimates, a 30-point gap (100% vs 70%) indicates a fundamental problem with the model, not just estimation variance.\n",
    "- **D is FALSE**: The distance metric choice affects performance, but switching metrics won't fix the fundamental overfitting problem caused by K=1.\n",
    "\n",
    "**Key Insight**: Small K values (especially K=1) lead to overfitting because they memorize training noise. Larger K values smooth out predictions and generalize better.\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "waax90325WBD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should see from the plot that our training accuracy starts high and decreases as K grows, whereas validation accuracy rises then eventually falls. The best K is where the validation curve peaks. We printed best_k above; let\u2019s proceed with that value.\n",
    "\n",
    "For example, if the plot shows that validation accuracy peaks at K=3 (just an example), then K=3 is our optimal choice on this validation set. We will use this best K for our final model."
   ],
   "metadata": {
    "id": "0ymPTZov5eEm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distance Metric Comparison\n",
    "\n",
    "So far, we've been using the default Euclidean distance. But KNN can use different distance metrics! The choice of distance metric can significantly affect model performance. Let's compare:\n",
    "\n",
    "### Common Distance Metrics\n",
    "\n",
    "1. **Euclidean Distance** (L2 norm):\n",
    "   - Formula: $d = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n",
    "   - Measures \"straight-line\" distance\n",
    "   - Sensitive to magnitude differences\n",
    "\n",
    "2. **Manhattan Distance** (L1 norm):\n",
    "   - Formula: $d = \\sum_{i=1}^{n} |x_i - y_i|$\n",
    "   - Measures \"city block\" distance (like navigating a grid)\n",
    "   - More robust to outliers\n",
    "\n",
    "Let's perform a **grid search** over both K values AND distance metrics to find the best combination:"
   ],
   "metadata": {
    "id": "BTNaBnvTVVLZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Grid search over K and distance metrics\n",
    "k_values = range(1, 21)\n",
    "metrics = ['euclidean', 'manhattan']\n",
    "results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    metric_train_acc = []\n",
    "    metric_val_acc = []\n",
    "\n",
    "    for k in k_values:\n",
    "        # Use sklearn's KNN with custom metric\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        knn.fit(X_train_vis, y_train_vis)\n",
    "\n",
    "        train_acc = knn.score(X_train_vis, y_train_vis)\n",
    "        val_acc = knn.score(X_val_vis, y_val_vis)\n",
    "\n",
    "        metric_train_acc.append(train_acc)\n",
    "        metric_val_acc.append(val_acc)\n",
    "\n",
    "        results.append({\n",
    "            'K': k,\n",
    "            'Metric': metric,\n",
    "            'Train_Accuracy': train_acc,\n",
    "            'Val_Accuracy': val_acc\n",
    "        })\n",
    "\n",
    "    # Plot for this metric\n",
    "    plt.plot(k_values, metric_val_acc, marker='o', label=f'{metric.capitalize()} (Val)', linewidth=2)\n",
    "\n",
    "# Create results table\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find best configuration\n",
    "best_idx = results_df['Val_Accuracy'].idxmax()\n",
    "best_config = results_df.iloc[best_idx]\n",
    "\n",
    "print(\"GRID SEARCH RESULTS: K vs Distance Metric\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show sample of results\n",
    "pivot_table = results_df.pivot(index='K', columns='Metric', values='Val_Accuracy')\n",
    "print(\"\\nValidation Accuracy Table (sample K values):\")\n",
    "print(pivot_table.loc[[1, 3, 5, 7, 9, 11, 13, 15]].to_string())\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"BEST CONFIGURATION:\")\n",
    "print(f\"  K = {int(best_config['K'])}\")\n",
    "print(f\"  Metric = {best_config['Metric']}\")\n",
    "print(f\"  Validation Accuracy = {best_config['Val_Accuracy']:.4f}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# Plotting\n",
    "plt.xlabel('K (Number of Neighbors)', fontsize=12)\n",
    "plt.ylabel('Validation Accuracy', fontsize=12)\n",
    "plt.title('Distance Metric Comparison: Euclidean vs Manhattan', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Different distance metrics can lead to different optimal K values\")\n",
    "print(\"- The best metric depends on the data distribution and feature characteristics\")\n",
    "print(\"- Always experiment with multiple metrics during hyperparameter tuning!\")"
   ],
   "metadata": {
    "id": "seMn7gJqVVLZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing Decision Boundaries: Euclidean vs Manhattan\n",
    "\n",
    "Now let's visualize how the choice of distance metric affects the decision boundaries:"
   ],
   "metadata": {
    "id": "fDw0o4h2VVLZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Use the best K from our grid search\n",
    "best_k = int(best_config['K'])\n",
    "\n",
    "# Create a mesh for plotting decision boundaries\n",
    "x_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\n",
    "y_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "\n",
    "for idx, metric in enumerate(['euclidean', 'manhattan']):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Train KNN with this metric\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "    knn.fit(X_train_vis, y_train_vis)\n",
    "\n",
    "    # Predict on mesh\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot decision boundary\n",
    "    ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.4)\n",
    "    ax.contour(xx, yy, Z, colors='black', linewidths=0.5, alpha=0.3)\n",
    "\n",
    "    # Plot training points\n",
    "    ax.scatter(X_train_vis[:, 0], X_train_vis[:, 1], c=y_train_vis,\n",
    "               cmap=cmap_bold, edgecolor='black', s=50, alpha=0.8, label='Training data')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    val_acc = knn.score(X_val_vis, y_val_vis)\n",
    "\n",
    "    ax.set_title(f'{metric.capitalize()} Distance (K={best_k})\\nVal Accuracy: {val_acc:.4f}',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Feature 1', fontsize=11)\n",
    "    ax.set_ylabel('Feature 2', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Decision Boundary Comparison: Different Distance Metrics',\n",
    "             fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Euclidean distance creates smoother, more circular decision boundaries\")\n",
    "print(\"- Manhattan distance creates more angular, grid-like decision boundaries\")\n",
    "print(\"- The difference can lead to different classification results, especially near boundaries\")"
   ],
   "metadata": {
    "id": "tauxKkmxVVLf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Decision Boundaries\n",
    "\n",
    "To build intuition, let\u2019s visualize the decision boundary of our KNN classifier on this 2D dataset. We\u2019ll use the DecisionBoundaryDisplay.from_estimator utility from scikit-learn to create a contour plot showing which class the KNN would predict at each point in the feature space. We will also plot the training and validation points to see how they fall in relation to the boundaries.\n",
    "\n",
    "Note: This visualization is only possible in low dimensions (2D in our case). It can help us see how the choice of K affects the complexity of the boundary."
   ],
   "metadata": {
    "id": "ep19djdY5h6j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Use the best K found\n",
    "knn_best = MyKNNClassifier(k=best_k, metric='euclidean')\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the decision boundary for the trained classifier\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    knn_best,            # our classifier\n",
    "    X_train,             # the data to use for creating the boundary (training data range)\n",
    "    response_method=\"predict\",\n",
    "    cmap='coolwarm',     # color map for regions\n",
    "    alpha=0.5            # transparency of the boundary overlay\n",
    ")\n",
    "\n",
    "# Overlay the validation data with class labels\n",
    "class_names = ['0', '1']\n",
    "colors = ['lightblue', 'orange']\n",
    "for i, color in enumerate(colors):\n",
    "    idx = np.where(y_val == i)\n",
    "    ax.scatter(X_val[idx, 0], X_val[idx, 1], c=color, edgecolor='k', s=100, label=f'{class_names[i]}')\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.legend(loc='best')  # Position the legend to not overlap with data\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.title(f\"KNN Decision Boundary (K={best_k})\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "CihL7ifb5U-a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the visualization:\n",
    "\n",
    "-\tThe colored regions (background) indicate the predicted class by KNN across the feature space (red vs blue regions).\n",
    "-\tPoints are plotted on top: training points (small circles) and validation points (star markers) in their true class colors.\n",
    "-\tYou can visually inspect how well the boundary separates the classes and where errors occur (validation stars that lie in a region of the opposite color would be misclassified)."
   ],
   "metadata": {
    "id": "6d1Kmd0s5x0G"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try experimenting by changing best_k to a smaller value (like 1) or a larger value and re-running the boundary plot code. You\u2019ll see:\n",
    "\n",
    "- For small K (e.g., 1-3): the decision boundary will be very wiggly and complex, wrapping tightly around individual training points. This can slice the space into many small regions (possibly leading to misclassifications on validation points that fall in strange pockets).\n",
    "- For large K (e.g., 10+): the decision boundary will be much smoother, perhaps a simple shape dividing the two main clusters, but it might misclassify points that actually could be distinguished with a more nuanced boundary.\n",
    "\n",
    "This aligns with our earlier discussion on overfitting vs underfitting:\n",
    "\n",
    "- Small K => complex boundary (risk of overfitting).\n",
    "- Large K => simple boundary (risk of underfitting)."
   ],
   "metadata": {
    "id": "yBTrpflZ6B7k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating on the Test Set\n",
    "\n",
    "We used the validation set to choose the best K. Now it\u2019s time to get an unbiased evaluation of our model using the test set (which we haven\u2019t touched so far).\n",
    "\n",
    "Before evaluating, it\u2019s common practice (if data permits) to retrain the model on the combined training + validation data using the chosen hyperparameters. The idea is to utilize all available data (except test) for training now that we\u2019ve fixed K, to potentially improve the model\u2019s performance. In our case, we have a fairly small dataset, so this might help a bit.\n",
    "\n",
    "Let\u2019s combine the training and validation sets, retrain MyKNNClassifier with best_k on this larger set, and then evaluate on the test set:"
   ],
   "metadata": {
    "id": "GQ5cn6Qg6Lc-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine train+val for final training\n",
    "X_train_val = np.vstack([X_train, X_val])\n",
    "y_train_val = np.hstack([y_train, y_val])\n",
    "\n",
    "# TODO: Train final model on combined data\n",
    "final_knn = MyKNNClassifier(k=best_k, distance_metric='euclidean')\n",
    "_________\n",
    "\n",
    "# TODO: Predict on the test set\n",
    "y_pred_test = _________\n",
    "# TODO: Compute test accuracy\n",
    "test_accuracy = accuracy_score(_________, _________)\n",
    "print(f\"Test Accuracy with K={best_k}: {test_accuracy:.3f}\")"
   ],
   "metadata": {
    "id": "JifqvcS-57R1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will create a confusion matrix for the test predictions. A confusion matrix shows how the model\u2019s predictions compare to the true labels, broken down by class. It\u2019s a great way to see which classes the model is getting wrong, not just how many it got wrong.\n",
    "\n",
    "For our binary class problem (class 0 vs class 1):\n",
    "\n",
    "- The confusion matrix will be 2x2.\n",
    "- Rows typically represent the true class, and columns the predicted class.\n",
    "- The cell (i, j) will contain the number of instances of true class i that were predicted as class j.\n",
    "\n",
    "Let\u2019s compute and visualize the confusion matrix:"
   ],
   "metadata": {
    "id": "bt6irtJp6UAu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title(f\"Confusion Matrix (Test) - K={best_k}\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "3btLVtlu6ajy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine the confusion matrix:\n",
    "\n",
    "- The diagonal [top-left and bottom-right] are the counts of correct predictions for class 0 and class 1, respectively.\n",
    "- The off-diagonals [top-right, bottom-left] are the misclassifications:\n",
    "- Top-right: how many class 0 were wrongly predicted as class 1.\n",
    "- Bottom-left: how many class 1 were wrongly predicted as class 0.\n",
    "\n",
    "For example, a confusion matrix output:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "18 & 2 \\\\\n",
    "3  & 17\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "would mean:\n",
    "- 18 instances of class 0 correctly predicted as 0 (true negatives if class 1 is \u201cpositive\u201d).\n",
    "- 17 instances of class 1 correctly predicted as 1 (true positives).\n",
    "- 2 instances of class 0 misclassified as 1 (false positives).\n",
    "- 3 instances of class 1 misclassified as 0 (false negatives).\n",
    "\n",
    "Using the confusion matrix along with accuracy gives us a more complete picture. We can identify if the model is skewed towards one class or if certain classes are harder to predict."
   ],
   "metadata": {
    "id": "T6Jz79ai6dfQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question:** What additional information does a confusion matrix provide beyond overall accuracy?\n",
    ">\n",
    "> A) Per-class performance showing which classes are well-predicted and which are frequently confused with each other\n",
    ">\n",
    "> B) The optimal K value that would maximize accuracy for each individual class\n",
    ">\n",
    "> C) Feature importance scores indicating which input features contribute most to correct classifications\n",
    ">\n",
    "> D) Probability distributions showing the model's confidence level for each prediction\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is TRUE**: The confusion matrix shows how many samples from each true class were predicted as each class. This reveals which classes the model confuses with each other, providing much more insight than overall accuracy.\n",
    "- **B is FALSE**: The confusion matrix doesn't suggest optimal K values - it only shows prediction results for the current model.\n",
    "- **C is FALSE**: Feature importance is not shown in a confusion matrix. That would require techniques like permutation importance or SHAP values.\n",
    "- **D is FALSE**: Standard confusion matrices show counts (or proportions), not probability distributions or confidence levels. You'd need to look at predict_proba() outputs for confidence levels.\n",
    "\n",
    "**Key Insight**: Accuracy can hide important performance issues. A confusion matrix reveals which specific classes are being misclassified and how.\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "KqAIF5Oe7aaU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting Results:\n",
    "\n",
    "- Check the test accuracy you obtained. Is it close to the validation accuracy at best K? Ideally, it should be in a similar ballpark if our validation selection was effective and there was no overfitting to the validation set.\n",
    "- Look at the confusion matrix. Are the errors mostly in one of the off-diagonals? This might indicate if the model has a bias towards predicting one class more often (for instance, if one class has more examples).\n",
    "- If we saw a large difference between training and validation accuracy earlier (a sign of overfitting), did using the best K and more training data improve the situation?"
   ],
   "metadata": {
    "id": "Ll19DAZ97kMe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying KNN to the Wine Dataset\n",
    "\n",
    "Now that we\u2019ve implemented and tested KNN on a synthetic dataset, let\u2019s apply our MyKNNClassifier to a real-world dataset: the classic Wine recognition dataset. This dataset consists of chemical analysis results of wines derived from three different cultivars (classes). There are 13 numeric features (like alcohol content, malic acid, etc.) and 3 classes of wine.\n",
    "\n",
    "We will see how KNN performs on this multi-class dataset and demonstrate the critical importance of feature scaling.\n",
    "\n",
    "Loading and Exploring the Data\n",
    "\n",
    "First, load the dataset and inspect its basic properties:"
   ],
   "metadata": {
    "id": "vO-FicWi7vy6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "print(\"Wine data shape:\", X_wine.shape, \"Labels:\", set(y_wine))\n",
    "print(\"Feature names:\", wine.feature_names)\n",
    "print(\"Class names:\", wine.target_names)"
   ],
   "metadata": {
    "id": "Rf4KwfOc7W49"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will output:\n",
    "\n",
    "- Shape of the data (should be (178, 13) meaning 178 samples, 13 features).\n",
    "- The set of labels (0, 1, 2 corresponding to the three wine classes).\n",
    "- The feature names and class names (class names might be generic like class_0, class_1, etc., since this dataset doesn't give actual cultivar names)."
   ],
   "metadata": {
    "id": "9YG9_2Rs72XD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Split into Train (70%) and Test (30%)\\\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_wine, y_wine, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "print(\"Wine train size:\", X_train_w.shape[0], \"test size:\", X_test_w.shape[0])"
   ],
   "metadata": {
    "id": "9-Op4l7t79Lp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, important: The features in the wine dataset have very different scales (for example, \u201cAlcohol\u201d might be in the range 11-14, \u201cMalic acid\u201d in 0-5, \u201cProline\u201d in 200-1700, etc.). We must scale the features before using KNN. We will compare model performance with and without scaling to emphasize this.\n",
    "\n",
    "We\u2019ll use standardization (z-scores) via StandardScaler to scale features to mean 0 and variance 1. We fit the scaler on the training data only (to avoid leaking information from the test set), then transform both train and test sets:"
   ],
   "metadata": {
    "id": "hYDdarpw8CKT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Why Feature Scaling Matters: A Concrete Example\n",
    "\n",
    "Before we apply scaling, let's understand **why** it's critical for KNN. Consider measuring similarity between people using height (in cm) and weight (in kg):\n",
    "\n",
    "### Example: Distance Without Scaling\n",
    "\n",
    "**Person A**: Height = 170 cm, Weight = 60 kg  \n",
    "**Person B**: Height = 160 cm, Weight = 60 kg  \n",
    "**Distance (Manhattan)**: |170 - 160| + |60 - 60| = **10**\n",
    "\n",
    "**Person C**: Height = 170 cm, Weight = 60 kg  \n",
    "**Person D**: Height = 170 cm, Weight = 70 kg  \n",
    "**Distance (Manhattan)**: |170 - 170| + |60 - 70| = **10**\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Both pairs have the same distance (10), but:\n",
    "- **Pair A-B**: Differ by 10 cm in height (about 6% difference)\n",
    "- **Pair C-D**: Differ by 10 kg in weight (about 17% difference)\n",
    "\n",
    "**The 10 kg weight difference is much more significant than the 10 cm height difference**, yet they contribute equally to the distance calculation!\n",
    "\n",
    "### Why This Happens\n",
    "\n",
    "Features with **larger scales** (like height in cm: 150-190) dominate features with **smaller scales** (like weight in kg: 50-90). KNN treats all features equally in distance calculations, so large-scale features disproportionately influence neighbor selection.\n",
    "\n",
    "Let's see this numerically:"
   ],
   "metadata": {
    "id": "vgQogz90VVLg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the people (height in cm, weight in kg)\n",
    "person_A = np.array([170, 60])\n",
    "person_B = np.array([160, 60])\n",
    "person_C = np.array([170, 60])\n",
    "person_D = np.array([170, 70])\n",
    "\n",
    "# Calculate Manhattan distances\n",
    "def manhattan_distance(p1, p2):\n",
    "    return np.sum(np.abs(p1 - p2))\n",
    "\n",
    "dist_AB = manhattan_distance(person_A, person_B)\n",
    "dist_CD = manhattan_distance(person_C, person_D)\n",
    "\n",
    "print(\"WITHOUT SCALING:\")\n",
    "print(f\"Distance between A and B: {dist_AB}\")\n",
    "print(f\"  - Height difference: {abs(person_A[0] - person_B[0])} cm\")\n",
    "print(f\"  - Weight difference: {abs(person_A[1] - person_B[1])} kg\")\n",
    "print()\n",
    "print(f\"Distance between C and D: {dist_CD}\")\n",
    "print(f\"  - Height difference: {abs(person_C[0] - person_D[0])} cm\")\n",
    "print(f\"  - Weight difference: {abs(person_C[1] - person_D[1])} kg\")\n",
    "print()\n",
    "print(\"Problem: Both distances are equal (10), but they represent different similarities!\")\n",
    "print()\n",
    "\n",
    "# Now let's scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a small dataset to fit the scaler\n",
    "data = np.array([[170, 60], [160, 60], [170, 70], [165, 65]])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "# Scale all four people\n",
    "person_A_scaled = scaler.transform([person_A])[0]\n",
    "person_B_scaled = scaler.transform([person_B])[0]\n",
    "person_C_scaled = scaler.transform([person_C])[0]\n",
    "person_D_scaled = scaler.transform([person_D])[0]\n",
    "\n",
    "dist_AB_scaled = manhattan_distance(person_A_scaled, person_B_scaled)\n",
    "dist_CD_scaled = manhattan_distance(person_C_scaled, person_D_scaled)\n",
    "\n",
    "print(\"AFTER SCALING:\")\n",
    "print(f\"Distance between A and B: {dist_AB_scaled:.3f}\")\n",
    "print(f\"Distance between C and D: {dist_CD_scaled:.3f}\")\n",
    "print()\n",
    "print(\"\u2713 Now the distances reflect true similarity!\")\n",
    "print(\"\u2713 Features are on comparable scales, and KNN can make better decisions.\")"
   ],
   "metadata": {
    "id": "d4TcKguPVVLg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding Standardization: Z-Scores\n",
    "\n",
    "Now that we understand why scaling matters, let's learn **how** StandardScaler works. It uses **Z-score standardization** (also called **standardization**).\n",
    "\n",
    "### The Z-Score Formula\n",
    "\n",
    "For each feature, StandardScaler transforms values using:\n",
    "\n",
    "$$Z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- **x** = original feature value\n",
    "- **\u03bc (mu)** = mean of the feature across all training samples\n",
    "- **\u03c3 (sigma)** = standard deviation of the feature across all training samples\n",
    "- **Z** = standardized value (z-score)\n",
    "\n",
    "### What This Does\n",
    "\n",
    "1. **Centers the data**: Subtracting \u03bc shifts the mean to 0\n",
    "2. **Scales the data**: Dividing by \u03c3 makes the standard deviation = 1\n",
    "3. **Result**: All features have mean = 0 and std = 1 (comparable scales!)\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's say we have a feature with values: [10, 20, 30, 40, 50]\n",
    "- Mean (\u03bc) = 30\n",
    "- Standard deviation (\u03c3) \u2248 14.14\n",
    "\n",
    "For x = 50:\n",
    "$$Z = \\frac{50 - 30}{14.14} = \\frac{20}{14.14} \u2248 1.41$$\n",
    "\n",
    "This means 50 is **1.41 standard deviations above the mean**.\n",
    "\n",
    "Let's see this in action with code:"
   ],
   "metadata": {
    "id": "ieZxrlbDVVLg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create sample data with two features on different scales\n",
    "# Feature 1: Height in cm (150-190)\n",
    "# Feature 2: Weight in kg (50-90)\n",
    "np.random.seed(42)\n",
    "heights = np.random.uniform(150, 190, 100)\n",
    "weights = np.random.uniform(50, 90, 100)\n",
    "data = np.column_stack([heights, weights])\n",
    "\n",
    "print(\"BEFORE STANDARDIZATION:\")\n",
    "print(f\"Heights - Mean: {np.mean(heights):.2f}, Std: {np.std(heights):.2f}\")\n",
    "print(f\"Weights - Mean: {np.mean(weights):.2f}, Std: {np.std(weights):.2f}\")\n",
    "print()\n",
    "\n",
    "# Apply StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "print(\"AFTER STANDARDIZATION:\")\n",
    "print(f\"Heights - Mean: {np.mean(data_scaled[:, 0]):.6f}, Std: {np.std(data_scaled[:, 0]):.6f}\")\n",
    "print(f\"Weights - Mean: {np.mean(data_scaled[:, 1]):.6f}, Std: {np.std(data_scaled[:, 1]):.6f}\")\n",
    "print()\n",
    "\n",
    "# Manual calculation example\n",
    "print(\"MANUAL CALCULATION EXAMPLE:\")\n",
    "print(\"Take the first height value:\", heights[0])\n",
    "mu_height = np.mean(heights)\n",
    "sigma_height = np.std(heights)\n",
    "z_score_manual = (heights[0] - mu_height) / sigma_height\n",
    "print(f\"Z = (x - \u03bc) / \u03c3 = ({heights[0]:.2f} - {mu_height:.2f}) / {sigma_height:.2f} = {z_score_manual:.6f}\")\n",
    "print(f\"StandardScaler result: {data_scaled[0, 0]:.6f}\")\n",
    "print(\"\u2713 They match!\")\n",
    "print()\n",
    "\n",
    "# Visualize the distributions before and after\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Before scaling\n",
    "axes[0, 0].hist(heights, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(np.mean(heights), color='red', linestyle='--', linewidth=2, label=f'Mean = {np.mean(heights):.1f}')\n",
    "axes[0, 0].set_title('Height (Before Scaling)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Height (cm)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].hist(weights, bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(np.mean(weights), color='red', linestyle='--', linewidth=2, label=f'Mean = {np.mean(weights):.1f}')\n",
    "axes[0, 1].set_title('Weight (Before Scaling)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Weight (kg)')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# After scaling\n",
    "axes[1, 0].hist(data_scaled[:, 0], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2, label='Mean = 0')\n",
    "axes[1, 0].set_title('Height (After Scaling)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Standardized Height (Z-score)')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].hist(data_scaled[:, 1], bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Mean = 0')\n",
    "axes[1, 1].set_title('Weight (After Scaling)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Standardized Weight (Z-score)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Effect of Z-Score Standardization', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Takeaway: After standardization, both features have mean \u2248 0 and std \u2248 1\")\n",
    "print(\"This puts them on equal footing for distance calculations in KNN!\")"
   ],
   "metadata": {
    "id": "qN4mj1hRVVLg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "# TODO: Fit on training data and transform training data\n",
    "X_train_w_scaled = scaler.fit_transform(_________)\n",
    "# TODO: Transform test data using the fitted scaler\n",
    "X_test_w_scaled = scaler.transform(_________)"
   ],
   "metadata": {
    "id": "EzSHY0Bw8F4U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: We only call fit_transform on the training data. The test data is transformed with the same scaling parameters. This ensures that our model is truly tested on unseen data that hasn\u2019t influenced the scaling. Never fit the scaler (or any preprocessing) on the full dataset before splitting or on the test set \u2013 that would introduce data leakage and inflate performance."
   ],
   "metadata": {
    "id": "YPEKjIw38Iqh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question:** When using StandardScaler with train/validation/test splits, what is the correct order of operations to avoid data leakage?\n",
    ">\n",
    "> A) Fit the scaler on training data only, then transform train, validation, and test sets using those fitted parameters\n",
    ">\n",
    "> B) Fit separate scalers on each dataset (train, validation, test) and transform each with its own parameters\n",
    ">\n",
    "> C) Fit the scaler on the combined training and validation sets, then transform all three sets\n",
    ">\n",
    "> D) Fit the scaler on all data combined before splitting to ensure consistent scaling across datasets\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:****Data leakage** occurs when information from validation or test sets \"leaks\" into the training process, leading to overly optimistic performance estimates that don't reflect real-world generalization.\n",
    "- **A is TRUE**: The scaler must only learn statistics (mean \u03bc, std \u03c3) from the training data. Then apply those same parameters to transform validation and test sets. This simulates real-world deployment where you only have training data statistics.\n",
    "- **B is FALSE**: Fitting separate scalers on validation/test sets causes severe data leakage. Example:  - Training set: Feature ranges [0-100], \u03bc=50, \u03c3=20  - Test set: Feature ranges [60-80], \u03bc=70, \u03c3=5  - If you fit separate scalers, the test scaler \"knows\" test data statistics it shouldn't know, making evaluation unrealistic\n",
    "- **C is FALSE**: Fitting on train+validation leaks validation set statistics into the scaling parameters. When you tune hyperparameters on validation set, you're indirectly using information about validation feature distributions.\n",
    "- **D is FALSE**: This is the worst option - the scaler learns statistics from test data, completely invalidating test set evaluation. Your model has \"seen\" test data characteristics through the scaler.\n",
    "\n",
    "**Correct Workflow:**\n",
    "```python\n",
    "# 1. Fit scaler on training data ONLY\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # learns \u03bc, \u03c3 from train\n",
    "\n",
    "# 2. Transform validation/test using SAME parameters\n",
    "X_val_scaled = scaler.transform(X_val)   # uses train's \u03bc, \u03c3\n",
    "X_test_scaled = scaler.transform(X_test)  # uses train's \u03bc, \u03c3\n",
    "```\n",
    "\n",
    "**Real-World Analogy:**\n",
    "In production, you'll only have training data to compute scaling parameters. Validation/test sets must use those same parameters to simulate realistic deployment.\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "A0rlwaalLEdE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let\u2019s evaluate KNN on the wine dataset in two scenarios:\n",
    "\n",
    "1.\tWithout scaling \u2013 using the original features.\n",
    "2.\tWith scaling \u2013 using the standardized features.\n",
    "\n",
    "For simplicity, we\u2019ll use the same K for both scenarios (for instance, K = 3, which is a common choice and often near optimal as well). If you want, you could perform a quick tune on the training set or via cross-validation to find the best K for wine, but here our focus is on the effect of scaling."
   ],
   "metadata": {
    "id": "ANPQxcrLK_Oy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. KNN on Wine data (unscaled features)"
   ],
   "metadata": {
    "id": "PLqkSEbi8UrN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Train final model on unscaled features\n",
    "knn_wine = MyKNNClassifier(k=3, metric='euclidean')\n",
    "knn_wine.fit(_________, _________)\n",
    "# TODO: Predict on the test set\n",
    "y_pred_wine = _________\n",
    "# TODO: Find accuracy score\n",
    "acc_wine = accuracy_score(y_test_w, _________)\n",
    "print(f\"KNN accuracy on Wine test (unscaled features, k=3): {acc_wine:.3f}\")\n",
    "\n",
    "# TODO: Compare model\u2019s predictions with the true labels, broken down by class\n",
    "cm_wine = confusion_matrix(_________, _________)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_wine, annot=True, fmt='d', cmap=\"YlOrBr\",\n",
    "            xticklabels=[f\"Pred {c}\" for c in range(3)],\n",
    "            yticklabels=[f\"Actual {c}\" for c in range(3)])\n",
    "plt.title(\"Wine Data Confusion Matrix (Unscaled)\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "NhqQuHbz8Rtm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will output the accuracy and show the confusion matrix for the 3-class classification. You will likely observe a moderate accuracy (often around 0.65-0.75 range for KNN unscaled on wine) and the confusion matrix may show a lot of misclassifications (off-diagonal counts)."
   ],
   "metadata": {
    "id": "RyI0332q8bVx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. KNN on Wine data (scaled features)"
   ],
   "metadata": {
    "id": "iXPzf_ch8eJB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Train final model on unscaled features\n",
    "knn_wine_scaled = MyKNNClassifier(k=3, distance_metric='euclidean')\n",
    "knn_wine_scaled.fit(_________, _________)\n",
    "# TODO: Predict on the test set\n",
    "y_pred_wine_scaled = _________\n",
    "# TODO: Find accuracy score\n",
    "acc_wine_scaled = _________\n",
    "print(f\"KNN accuracy on Wine test (scaled features, k=3): {acc_wine_scaled:.3f}\")\n",
    "\n",
    "# TODO: See which classes the model is getting wrong\n",
    "cm_wine_scaled = confusion_matrix(_________, _________)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_wine_scaled, annot=True, fmt='d', cmap=\"YlGnBu\",\n",
    "            xticklabels=[f\"Pred {c}\" for c in range(3)],\n",
    "            yticklabels=[f\"Actual {c}\" for c in range(3)])\n",
    "plt.title(\"Wine Data Confusion Matrix (Scaled)\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Dz5sZjG98dd1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now check the printed accuracies and the confusion matrices side by side:\n",
    "\n",
    "- You should see that accuracy with scaled features is significantly higher than without scaling. It\u2019s not uncommon to see unscaled KNN around ~70% accuracy vs scaled KNN around ~95% accuracy on this wine dataset.\n",
    "- The unscaled confusion matrix likely showed many off-diagonal values (mix-ups among classes), whereas the scaled confusion matrix should have clearer dominance on the diagonal (more correct classifications per class).\n",
    "\n",
    "This dramatic difference occurs because, without scaling, some features (like \u201cProline\u201d which can have values in the hundreds) dominate the distance calculation, drowning out the influence of other features. After scaling, each feature contributes more equally, and KNN can make much better distinctions between the classes."
   ],
   "metadata": {
    "id": "uUeBhmh-8kyX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question:** Why did KNN perform significantly better after feature scaling on the Wine dataset?\n",
    ">\n",
    "> A) Scaling prevents features with larger ranges (like Proline 280-1700) from dominating distance calculations over smaller-range features\n",
    ">\n",
    "> B) Scaling improves the mathematical properties of the distance metric, making Euclidean distance more stable numerically\n",
    ">\n",
    "> C) Scaling increases the effective sample size by making data points more uniformly distributed in feature space\n",
    ">\n",
    "> D) Scaling reduces overfitting by constraining all features to similar ranges, which acts as a form of regularization\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is TRUE**: KNN uses distance metrics (like Euclidean distance) that are sensitive to feature scales. In the Wine dataset, Proline ranges from 278 to 1680 while other features like Alcohol range from 11 to 15. Without scaling, Proline differences dominate the distance calculations, effectively making it a single-feature model.\n",
    "- **B is FALSE**: Scaling doesn't change the mathematical properties or numerical stability of Euclidean distance - it just ensures features contribute proportionally to the distance calculation.\n",
    "- **C is FALSE**: Scaling doesn't change the sample size or distribution of points in absolute terms - it just normalizes the scales so distances are comparable across features.\n",
    "- **D is FALSE**: Scaling is not a form of regularization. It's a preprocessing step to ensure fair feature contribution. Regularization penalizes model complexity, which KNN doesn't have in the traditional sense.\n",
    "\n",
    "**Key Insight**: Distance-based algorithms like KNN require feature scaling because they treat all features equally in distance calculations. Without scaling, features with larger numeric ranges dominate.\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "dJBMx0z28uIF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Wine Data with t-SNE\n",
    "\n",
    "To further illustrate the effect of scaling on the data itself, we can use t-SNE (t-distributed Stochastic Neighbor Embedding) to visualize the wine data in two dimensions. t-SNE is a nonlinear dimensionality reduction technique that tries to preserve the local structure of the data (i.e., points that are close in original space stay close in the embedding). It\u2019s useful for visualizing high-dimensional data.\n",
    "\n",
    "We\u2019ll create two t-SNE plots: one on the original features, one on the scaled features, and compare them."
   ],
   "metadata": {
    "id": "Y8_0FKV-83Sb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE on original wine data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_wine_tsne_orig = tsne.fit_transform(X_wine)  # using all data for visualization\n",
    "\n",
    "# t-SNE on scaled wine data\n",
    "tsne2 = TSNE(n_components=2, random_state=42)\n",
    "X_wine_tsne_scaled = tsne2.fit_transform(StandardScaler().fit_transform(X_wine))"
   ],
   "metadata": {
    "id": "Vst89TWG8qeK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let\u2019s plot these side by side. We\u2019ll color points by their true class label (0, 1, 2) to see if classes form distinct clusters. We want to use the same color scheme for both plots for a fair comparison:"
   ],
   "metadata": {
    "id": "1Mhzh0yh9Ap-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a color mapping for the three classes\n",
    "cmap = plt.cm.viridis\n",
    "norm = plt.Normalize(vmin=y_wine.min(), vmax=y_wine.max())\n",
    "target_names = wine.target_names  # e.g., ['class_0', 'class_1', 'class_2']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Plot t-SNE for original data\n",
    "scatter0 = axes[0].scatter(X_wine_tsne_orig[:, 0], X_wine_tsne_orig[:, 1],\n",
    "                           c=y_wine, cmap=cmap, norm=norm, edgecolor='k', alpha=0.7)\n",
    "axes[0].set_title(\"t-SNE (Original Features)\")\n",
    "axes[0].set_xlabel(\"TSNE 1\")\n",
    "axes[0].set_ylabel(\"TSNE 2\")\n",
    "# Plot t-SNE for scaled data\n",
    "scatter1 = axes[1].scatter(X_wine_tsne_scaled[:, 0], X_wine_tsne_scaled[:, 1],\n",
    "                           c=y_wine, cmap=cmap, norm=norm, edgecolor='k', alpha=0.7)\n",
    "axes[1].set_title(\"t-SNE (Scaled Features)\")\n",
    "axes[1].set_xlabel(\"TSNE 1\")\n",
    "axes[1].set_ylabel(\"TSNE 2\")\n",
    "\n",
    "# Add a legend using class names for colors\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='none', label=name,\n",
    "                          markerfacecolor=cmap(norm(i)), markersize=8, edgecolor='k')\n",
    "                   for i, name in enumerate(target_names)]\n",
    "axes[1].legend(handles=legend_elements, title=\"Wine Class\", loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "WRyNrG8y9CzU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpret the t-SNE plots:\n",
    "\n",
    "- Original features t-SNE: You might see that the points are in a weird, perhaps elongated shape or not clearly separated by class. The classes could be mixed together because certain features dominated distances, causing t-SNE to bunch points oddly.\n",
    "- Scaled features t-SNE: Here, you should observe more distinct clustering of points by class. The three classes are likely more separable (perhaps forming three clusters or at least tighter groupings of same-colored points). This indicates that after scaling, the inherent structure of the data (different wine classes) is clearer in the feature space, which is why KNN could perform better."
   ],
   "metadata": {
    "id": "uF6B3cm79Ju2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding Model Predictions: Error Analysis\n",
    "\n",
    "So far we've looked at overall accuracy, but where exactly does our KNN model make mistakes? Understanding **where** and **why** errors occur helps us:\n",
    "\n",
    "1. **Identify problematic regions** in the feature space\n",
    "2. **Understand model limitations** (e.g., does it fail in overlapping regions?)\n",
    "3. **Guide improvements** (e.g., collect more data in ambiguous regions)\n",
    "\n",
    "Let's perform an error analysis on our Wine dataset predictions. We'll identify:\n",
    "- Which test samples were misclassified\n",
    "- Whether errors occur in regions where classes overlap (high ambiguity)\n",
    "- How the model's certainty relates to classification accuracy\n",
    "\n",
    "This analysis connects back to the t-SNE visualization\u2014errors should occur where classes overlap!"
   ],
   "metadata": {
    "id": "rRpxtnBTVVLh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Train KNN on scaled Wine data (using best K=5 or adjust as needed)\n",
    "best_k_wine = 5  # Adjust based on your tuning results\n",
    "knn_wine = KNeighborsClassifier(n_neighbors=best_k_wine)\n",
    "knn_wine.fit(X_train_wine_scaled, y_train_wine)\n",
    "\n",
    "# Get predictions and prediction probabilities\n",
    "y_pred_wine = knn_wine.predict(X_test_wine_scaled)\n",
    "y_pred_proba_wine = knn_wine.predict_proba(X_test_wine_scaled)\n",
    "\n",
    "# Calculate prediction certainty (max probability)\n",
    "prediction_certainty = np.max(y_pred_proba_wine, axis=1)\n",
    "\n",
    "# Identify correct and incorrect predictions\n",
    "correct_mask = (y_pred_wine == y_test_wine)\n",
    "incorrect_mask = ~correct_mask\n",
    "\n",
    "# Error Analysis Summary\n",
    "print(\"ERROR ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total test samples: {len(y_test_wine)}\")\n",
    "print(f\"Correct predictions: {np.sum(correct_mask)} ({100*np.mean(correct_mask):.2f}%)\")\n",
    "print(f\"Incorrect predictions: {np.sum(incorrect_mask)} ({100*np.mean(incorrect_mask):.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Analyze prediction certainty\n",
    "print(\"PREDICTION CERTAINTY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Average certainty (correct predictions): {np.mean(prediction_certainty[correct_mask]):.4f}\")\n",
    "print(f\"Average certainty (incorrect predictions): {np.mean(prediction_certainty[incorrect_mask]):.4f}\")\n",
    "print()\n",
    "print(\"Insight: Lower certainty often indicates ambiguous regions where classes overlap.\")\n",
    "print()\n",
    "\n",
    "# Show misclassified examples\n",
    "if np.sum(incorrect_mask) > 0:\n",
    "    print(\"MISCLASSIFIED EXAMPLES:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Index':<8} {'True Class':<12} {'Predicted':<12} {'Certainty':<12}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    misclassified_indices = np.where(incorrect_mask)[0]\n",
    "    for idx in misclassified_indices[:10]:  # Show first 10\n",
    "        print(f\"{idx:<8} {y_test_wine.iloc[idx]:<12} {y_pred_wine[idx]:<12} {prediction_certainty[idx]:<12.4f}\")\n",
    "\n",
    "    if len(misclassified_indices) > 10:\n",
    "        print(f\"... and {len(misclassified_indices) - 10} more\")\n",
    "    print()\n",
    "\n",
    "# Visualize errors in t-SNE space\n",
    "print(\"Visualizing errors in t-SNE reduced space...\")\n",
    "print()\n",
    "\n",
    "# Perform t-SNE on test data\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X_test_wine_scaled)-1))\n",
    "X_test_tsne = tsne.fit_transform(X_test_wine_scaled)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Color by true class\n",
    "ax1 = axes[0]\n",
    "colors = ['red', 'green', 'blue']\n",
    "class_names = ['Class 0', 'Class 1', 'Class 2']\n",
    "\n",
    "for class_idx in range(3):\n",
    "    mask = y_test_wine == class_idx\n",
    "    ax1.scatter(X_test_tsne[mask, 0], X_test_tsne[mask, 1],\n",
    "                c=colors[class_idx], label=class_names[class_idx],\n",
    "                s=100, alpha=0.6, edgecolors='black')\n",
    "\n",
    "ax1.set_title('Test Data: Colored by True Class', fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel('t-SNE Dimension 1', fontsize=11)\n",
    "ax1.set_ylabel('t-SNE Dimension 2', fontsize=11)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Highlight errors\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Plot correct predictions in light gray\n",
    "ax2.scatter(X_test_tsne[correct_mask, 0], X_test_tsne[correct_mask, 1],\n",
    "            c='lightgray', label='Correct', s=100, alpha=0.4, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "# Plot incorrect predictions with high visibility\n",
    "ax2.scatter(X_test_tsne[incorrect_mask, 0], X_test_tsne[incorrect_mask, 1],\n",
    "            c='red', label='Misclassified', s=200, alpha=0.8, edgecolors='black',\n",
    "            linewidths=2, marker='X')\n",
    "\n",
    "ax2.set_title('Test Data: Highlighting Misclassifications', fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel('t-SNE Dimension 1', fontsize=11)\n",
    "ax2.set_ylabel('t-SNE Dimension 2', fontsize=11)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Error Analysis: Where Does KNN Make Mistakes?', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"- Misclassified points (red X's) often appear in overlapping regions\")\n",
    "print(\"- These are ambiguous regions where classes are not well-separated\")\n",
    "print(\"- KNN struggles when nearest neighbors belong to different classes\")\n",
    "print(\"- This connects to the t-SNE visualization: errors occur where clusters overlap!\")"
   ],
   "metadata": {
    "id": "a2bzjodgVVLh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "- Implemented KNN from scratch as MyKNNClassifier and verified it works similarly to scikit-learn\u2019s KNN.\n",
    "- Used training, validation, test splits to tune the hyperparameter K without leaking test information. We observed how to pick the best K by validation accuracy.\n",
    "- Explored the bias-variance trade-off in KNN: small K vs large K and how they affect decision boundaries and accuracy.\n",
    "- Emphasized evaluation using accuracy and confusion matrices. Accuracy gives an overall performance, while confusion matrices provide insight into class-wise performance and misclassification patterns.\n",
    "- Highlighted feature scaling as a critical preprocessing step for KNN. The Wine dataset example showed that scaling features (using StandardScaler) dramatically improved KNN accuracy, and t-SNE visualizations helped explain why.\n",
    "- Incorporated various best practices:\n",
    "- Shape and input validation in our implementation (to catch mistakes early).\n",
    "- Warnings about data leakage (e.g., fitting scalers on full data or using test data in tuning).\n",
    "- Setting random_state for reproducibility of our data splits and t-SNE.\n",
    "- Creating scalable visualizations (like adjusting marker sizes and using transparency for large scatter plots, and programmatically generating legends) to handle different dataset sizes and clarity.\n",
    "\n",
    "KNN is a simple yet powerful algorithm for many scenarios. However, keep in mind:\n",
    "- It can be computationally expensive for large datasets (since distance to all training points must be computed for each prediction).\n",
    "- It doesn\u2019t produce an explicit model, so storage of training data and prediction speed can be issues.\n",
    "- It often serves as a good baseline but may be outperformed by more complex models with proper training. Still, the lessons about cross-validation, scaling, and evaluation we practiced here apply to many other machine learning algorithms.\n"
   ],
   "metadata": {
    "id": "bFLBvAVD9SWY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Wrap-Up Question**: Bias\u2013variance in KNN:\n",
    ">\n",
    "> A. small K \u2192 low bias / high variance ; large K \u2192 high bias / low variance\n",
    ">\n",
    "> B. small K \u2192 high bias / low variance ; large K \u2192 low bias / high variance\n",
    ">\n",
    "> C. both small & large K \u2192 high variance\n",
    ">\n",
    ">D. K doesn\u2019t affect either\n",
    "<details>\n",
    "\n",
    "<summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: A**\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "**Small K (like K=1):**\n",
    "- **Low bias**: Can fit very complex patterns, even noise\n",
    "- **High variance**: Predictions change dramatically with small changes in training data\n",
    "- **Result**: Overfitting\n",
    "\n",
    "**Large K (like K=50):**\n",
    "- **High bias**: Smooths out patterns, may miss important details\n",
    "- **Low variance**: Predictions are stable across different training sets\n",
    "- **Result**: Underfitting\n",
    "\n",
    "**Why other options are wrong:**\n",
    "- **B is FALSE**: This reverses the relationship\n",
    "- **C is FALSE**: Large K reduces variance by averaging over many neighbors\n",
    "- **D is FALSE**: K is the primary hyperparameter controlling the bias-variance tradeoff in KNN\n",
    "\n",
    "**Key Insight**: The bias-variance tradeoff is fundamental to KNN. Small K is flexible but unstable (high variance), large K is stable but inflexible (high bias).\n",
    "\n",
    "</details>"
   ],
   "metadata": {
    "id": "ZCZHchoILX-K"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "EAJ8rrwj9Qb7"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}