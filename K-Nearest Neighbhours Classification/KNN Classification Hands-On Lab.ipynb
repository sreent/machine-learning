{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNF//zFNpbjbxNkox0uH5bY",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/K-Nearest%20Neighbours%20(KNN)%20Classification/Hands-On%20Lab%3A%20K-Nearest%20Neighbours%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Nearest Neighbors (KNN) Classification"
   ],
   "metadata": {
    "id": "OpLpu61iiDz9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab, you will implement a K-Nearest Neighbors classifier from scratch, tune its parameters, and apply it to real data. Along the way, you’ll answer conceptual questions and create visualizations to deepen your understanding. By the end, you will have a clear grasp of how KNN works, how to evaluate it using accuracy and confusion matrices, and why practices like feature scaling and proper data splitting are critical.\n"
   ],
   "metadata": {
    "id": "ZahTMlifiEBa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of KNN\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple, instance-based learning algorithm used for classification (and regression). For classification, KNN makes predictions by looking at the K training examples closest (in feature space) to a new data point, and assigning the majority class among those neighbors. It is considered a lazy learning method because it does not build an explicit model; instead, all training data is stored, and generalization is postponed until a query (prediction) is made.\n",
    "\n",
    "How KNN Classification Works:\n",
    "\n",
    "1.\tChoose K: Decide on the number of neighbors (K) to use for predictions.\n",
    "2.\tCompute Distances: To classify a new point, compute the distance between this point and all points in the training set (commonly using Euclidean distance).\n",
    "3.\tFind Nearest Neighbors: Identify the K training points with the smallest distances to the new point.\n",
    "4.\tMajority Vote: Among these K neighbors, count the occurrences of each class and take the majority vote. The new point is predicted to belong to the class with the most votes.\n",
    "5.\tReturn the Prediction: Assign the predicted class to the new point.\n"
   ],
   "metadata": {
    "id": "gX3UlspviNKs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image.png](data:image/png;base64,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)"
   ],
   "metadata": {
    "id": "gNMBXNcBQ2we"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For example, if K=3 and among the 3 nearest neighbors 2 are class Green and 1 is class Red, the new point will be classified as class Green.\n",
    "\n"
   ],
   "metadata": {
    "id": "IHskpfkYP0cg"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Visual K Progression\n\nTo understand how the choice of K affects predictions, let's visualize how KNN makes decisions for different K values. We'll create a simple 2D dataset and observe how the prediction changes as we vary K from 1 to 5.\n\nFor each value of K, we'll:\n- Circle the K nearest neighbors to a query point\n- Count votes from each class (e.g., \"# Green = 2, # Red = 1\")\n- Show the final prediction based on majority vote\n\nThis visualization will demonstrate:\n- **Small K (K=1, K=2)**: More sensitive to individual points, can be noisy\n- **Medium K (K=3, K=4)**: More balanced predictions\n- **Larger K (K=5)**: Smoother decision boundaries, more stable predictions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nfrom collections import Counter\n\n# Create a simple 2D dataset\nnp.random.seed(42)\n# Class 0 (Red): centered around (2, 2)\nclass_0 = np.random.randn(15, 2) * 0.5 + np.array([2, 2])\n# Class 1 (Green): centered around (4, 4)\nclass_1 = np.random.randn(15, 2) * 0.5 + np.array([4, 4])\n\nX_train = np.vstack([class_0, class_1])\ny_train = np.array([0]*15 + [1]*15)\n\n# Query point to classify\nquery_point = np.array([3.0, 3.5])\n\n# Calculate distances from query point to all training points\ndistances = np.sqrt(np.sum((X_train - query_point)**2, axis=1))\n\n# Create subplots for K=1 to K=5\nfig, axes = plt.subplots(1, 5, figsize=(20, 4))\nk_values = [1, 2, 3, 4, 5]\n\nfor idx, k in enumerate(k_values):\n    ax = axes[idx]\n    \n    # Find K nearest neighbors\n    nearest_indices = np.argsort(distances)[:k]\n    nearest_labels = y_train[nearest_indices]\n    \n    # Count votes\n    vote_counts = Counter(nearest_labels)\n    prediction = max(vote_counts, key=vote_counts.get)\n    \n    # Plot all training points\n    ax.scatter(class_0[:, 0], class_0[:, 1], c='red', s=100, alpha=0.6, label='Class 0 (Red)', edgecolors='black')\n    ax.scatter(class_1[:, 0], class_1[:, 1], c='green', s=100, alpha=0.6, label='Class 1 (Green)', edgecolors='black')\n    \n    # Highlight K nearest neighbors with circles\n    for i in nearest_indices:\n        circle = Circle(X_train[i], 0.2, color='blue', fill=False, linewidth=2)\n        ax.add_patch(circle)\n    \n    # Plot query point\n    pred_color = 'red' if prediction == 0 else 'green'\n    ax.scatter(query_point[0], query_point[1], c=pred_color, s=300, marker='*', \n               edgecolors='black', linewidth=2, label='Query Point', zorder=5)\n    \n    # Add vote count and prediction text\n    red_votes = vote_counts.get(0, 0)\n    green_votes = vote_counts.get(1, 0)\n    pred_class = \"Red\" if prediction == 0 else \"Green\"\n    \n    ax.text(0.5, 0.95, f'K = {k}', transform=ax.transAxes, fontsize=14, \n            fontweight='bold', ha='center', va='top')\n    ax.text(0.5, 0.88, f'# Red = {red_votes}, # Green = {green_votes}', \n            transform=ax.transAxes, fontsize=11, ha='center', va='top')\n    ax.text(0.5, 0.80, f'Prediction: {pred_class}', transform=ax.transAxes, \n            fontsize=12, fontweight='bold', ha='center', va='top', \n            bbox=dict(boxstyle='round', facecolor=pred_color, alpha=0.3))\n    \n    ax.set_xlim(0, 6)\n    ax.set_ylim(0, 6)\n    ax.set_xlabel('Feature 1', fontsize=10)\n    if idx == 0:\n        ax.set_ylabel('Feature 2', fontsize=10)\n    ax.grid(True, alpha=0.3)\n\nplt.suptitle('How K Affects KNN Predictions: Visualizing K Nearest Neighbors', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nObservations:\")\nprint(\"- As K increases, the prediction becomes more stable and less sensitive to individual points\")\nprint(\"- Small K values can lead to overfitting (too sensitive to noise)\")\nprint(\"- Large K values can lead to underfitting (too smooth, may ignore local patterns)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question**: In KNN classification, the parameter K refers to:\n",
    ">\n",
    "> A. The number of nearest neighbors used to determine the class of a new data point.\n",
    ">\n",
    "> B. The number of features (dimensions) in the dataset.\n",
    ">\n",
    "> C. The number of classes in the classification problem.\n",
    ">\n",
    "> D. The exponent used in the distance calculation."
   ],
   "metadata": {
    "id": "1H6lgCADiwfx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bias-Variance Trade-off in KNN\n",
    "\n",
    "The choice of K has a significant effect on the model’s complexity and performance:\n",
    "\n",
    "- Small K (e.g., K=1) tends to lead to complex, highly flexible decision boundaries that closely follow the training data. This can result in overfitting (low bias, high variance) – high accuracy on training data but low accuracy on unseen data.\n",
    "- Large K (e.g., K large relative to number of samples) produces smoother, less complex decision boundaries because predictions are averaged over many neighbors. This can result in underfitting (high bias, low variance) – both training and validation accuracy might be low because the model is too simple to capture patterns.\n",
    "\n",
    "We will observe this behavior when we experiment with different values of K."
   ],
   "metadata": {
    "id": "-L4gKSiL-ERn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Distance Metrics and Feature Scaling\n",
    "\n",
    "KNN relies on a distance measure to determine “nearest” neighbors. Common choices include:\n",
    "\n",
    "-\tEuclidean distance (L2 norm)\n",
    "-\tManhattan distance (L1 norm)\n",
    "-\tCosine distance, etc.\n",
    "\n",
    "Feature scaling is crucial for KNN because the distance computation is sensitive to the scale of features. If one feature has a much larger range than others, it can dominate the distance calculation and distort nearest neighbor relationships. We typically address this by scaling or standardizing features (e.g., using z-scores) so that all features contribute more equally to distance calculations. You will see the impact of scaling when we apply KNN to a real dataset."
   ],
   "metadata": {
    "id": "CV8NW9n4i9hz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Question**: When using KNN on a dataset with features measured in very different units (e.g., one feature in the range 0-1000 and another in 0-1), what is the best practice?\n",
    ">\n",
    "> A. Normalize or standardize the features so they have similar scales before training KNN.\n",
    ">\n",
    "> B. Remove the feature with the larger range to avoid dominance in distance calculation.\n",
    ">\n",
    "> C. Use a different distance metric that ignores scale differences, so scaling is not needed.\n",
    ">\n",
    "> D. Increase K proportionally to the range differences to offset the scale issue."
   ],
   "metadata": {
    "id": "cB_Uc4bSjQl5"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## KNN Algorithm: Pseudocode\n\nBefore implementing KNN from scratch, let's understand the algorithm's structure through formal pseudocode. KNN is a **lazy learning** algorithm, meaning it doesn't build an explicit model during training—it simply stores the training data and performs all computation during prediction.\n\n### Formal Pseudocode\n\n```\n# ============================================\n# Inputs\n# ============================================\n# data ← training set of N examples (x, y)\n# k ← number of neighbours\n# metric ← distance function (e.g., Euclidean, Manhattan)\n# X_query ← set of examples to classify\n\n# ============================================\n# ----- \"fit\" (lazy) -----\n# ============================================\nX_train ← data.x\ny_train ← data.y\n\n# ============================================\n# ----- predict -----\n# ============================================\nŷ ← list of length |X_query|\nFOR i = 1 TO |X_query| DO\n    x* ← X_query[i]\n    d ← distances from x* to all X_train using metric\n    J ← indices of the k smallest values in d\n    ŷ[i] ← majority_vote(y_train[J])\nEND FOR\nRETURN ŷ\n```\n\n### Key Observations\n\n1. **Lazy Learning**: The `fit` phase simply stores the training data—no model parameters are learned.\n2. **Prediction Phase**: All the work happens during prediction:\n   - Calculate distances from the query point to all training points\n   - Find the K nearest neighbors\n   - Take a majority vote among their labels\n3. **Computational Cost**: For each prediction, we compute distances to all N training points, making KNN O(N) per prediction.\n\nNow let's implement this algorithm from scratch!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing a Custom KNN Classifier\n",
    "\n",
    "Instead of using sklearn.neighbors.KNeighborsClassifier, we will build our own MyKNNClassifier from scratch. This will solidify our understanding of how the algorithm works internally. We will incorporate some best practices into our implementation, such as input validation (shape checks, value checks) and ensuring reproducibility where relevant.\n",
    "\n",
    "Let’s start by implementing the MyKNNClassifier class with the following specifications:\n",
    "- It should follow the basic structure of scikit-learn classifiers, with fit and predict methods.\n",
    "-\tIn fit(X, y), simply store the training data (X and y). We will use underscores (X_train_, y_train_) to indicate stored fitted data attributes.\n",
    "-\tIn predict(X), use the KNN algorithm: for each sample in X, compute distances to all points in X_train_, find the K nearest neighbors, and return the majority class among those neighbors.\n",
    "-\tInclude shape guards and input validation:\n",
    "  -\tCheck that X and y have appropriate shapes in fit (e.g., same number of samples).\n",
    "  -\tEnsure that k is a positive integer and not greater than the number of training samples.\n",
    "  -\tOptionally, ensure that the number of features in any data passed to predict matches the number in X_train_.\n",
    "-\tWe will use Euclidean distance by default (you can allow other metrics as an extension). To compute distances efficiently, we can use sklearn.metrics.pairwise_distances or NumPy operations.\n",
    "-\tUse the Python collections.Counter to perform the majority vote among neighbors’ labels."
   ],
   "metadata": {
    "id": "yUBHykTrn7M9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a scaffold of the MyKNNClassifier class. Fill in the TODO sections to complete the implementation:"
   ],
   "metadata": {
    "id": "zvWu4Jlcn7W6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class MyKNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k=3, metric='euclidean'):\n",
    "        \"\"\"KNN classifier: majority vote among k nearest neighbours.\"\"\"\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"'Fit' (lazy): store training arrays to use during predict().\"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        # TODO: store training data (use attribute names referenced in predict)\n",
    "        self.X_train_ = _________\n",
    "        self.y_train_ = _________\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return one predicted label per row in X (same order as X).\"\"\"\n",
    "        X = np.asarray(X)\n",
    "\n",
    "        # TODO: prepare output array with same dtype as training labels\n",
    "        y_pred = _________   # e.g., np.empty(X.shape[0], dtype=self.y_train_.dtype)\n",
    "\n",
    "        for i, x in enumerate(X):\n",
    "            # TODO: compute distances from x to all training points\n",
    "            d = _________     # use pairwise_distances(self.X_train_, x[None, :], metric=self.metric).ravel()\n",
    "\n",
    "            # TODO: get indices of the k smallest distances (nearest neighbours)\n",
    "            J = _________     # e.g., np.argsort(d)[:self.k]\n",
    "\n",
    "            # TODO: majority vote (deterministic tie-break via np.unique)\n",
    "            labels, counts = _________   # e.g., np.unique(self.y_train_[J], return_counts=True)\n",
    "            y_pred[i] = _________        # e.g., labels[np.argmax(counts)]\n",
    "\n",
    "        # TODO: return predictions as a 1D NumPy array\n",
    "        return _________"
   ],
   "metadata": {
    "id": "eTGQx81BiMbG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you have filled in the implementation, let’s test our custom classifier on a simple dataset to ensure it works as expected."
   ],
   "metadata": {
    "id": "Quw6AEuaomvh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A Dataset for Visualization\n",
    "\n",
    "To visualize how KNN works, we’ll use R ElemStatLearn's \"Simulated Mixture Gaussian\" dataset:\n",
    "-\tTotal points: 200 (100 per class).\n",
    "-\tClasses: 2\n",
    "-\tFeatures: $x_1$ and $x_2$ (2D), which we can plot on a plane.\n",
    "-\tThis dataset is partially overlapping and not linearly separable, which is perfect for exploring KNN decision boundaries and performance.\n",
    "\n",
    "Let’s load the dataset:"
   ],
   "metadata": {
    "id": "OiMSd5giouAD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL for our dataset, mixture-example.csv\n",
    "URL = \"https://drive.google.com/file/d/1l0QDFXeyrelvjXlyhnj4ppP_SSTABIKp/view?usp=sharing\"\n",
    "FILE_PATH = \"https://drive.google.com/uc?export=download&id=\" + URL.split(\"/\")[-2]\n",
    "\n",
    "data = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Filter data by labels\n",
    "X = data[['X', 'Y']].values\n",
    "y = data['Label'].values\n",
    "\n",
    "print(\"Dataset shape:\", X.shape, \"Labels shape:\", y.shape)\n"
   ],
   "metadata": {
    "id": "cya5lCOGolau"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the above code will load the dataset and print the shapes. You should see Dataset shape: (200, 2) Labels shape: (200,) confirming we have 200 samples with 2 features each. Next, let’s visualize this dataset to understand its structure:"
   ],
   "metadata": {
    "id": "P6jzwp3Jolzg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], color='lightblue', label='0', marker='o')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], color='orange', label='1', marker='o')\n",
    "\n",
    "plt.xlabel('$x_1$', fontsize=20)\n",
    "plt.ylabel('$x_2$', fontsize=20)\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "XXDV0ifa3WHF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the scatter plot, points of different colors represent the two classes (for example, blue for class 0 and red for class 1). Notice that the classes are composed of multiple clusters spread around the space, with some overlap between the blue and red points. This will make the classification task non-trivial, which is great for exploring how KNN behaves."
   ],
   "metadata": {
    "id": "QHeeDVZt3m8g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting into Train, Validation, and Test Sets\n",
    "\n",
    "To evaluate our model properly and tune the hyperparameter K, we will split the data into three sets:\n",
    "\t•\tTraining set (Train) – used to fit the KNN model.\n",
    "\t•\tValidation set (Val) – used to select the best K (tuning the hyperparameter). We will test different K values on this set.\n",
    "\t•\tTest set (Test) – used only for final evaluation of the model’s performance after tuning, to simulate unseen data.\n",
    "\n",
    "We’ll do a 60%/20%/20% split for train/val/test. We will stratify the split to maintain the class proportions in each subset (ensuring each subset has roughly equal class 0 vs class 1 distribution). We also set a random_state for reproducibility:"
   ],
   "metadata": {
    "id": "7WA3Ep2T3spD"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on Feature Scaling:** You may notice we haven't discussed feature scaling yet for this Mixture Gaussian dataset. This is because both features (x₁ and x₂) are already on similar scales (roughly -4 to +4 range). \n\nHowever, in real-world datasets—like the Wine dataset we'll work with later—features often have vastly different scales (e.g., Proline: 280-1700 vs Malic acid: 0.7-6). In those cases, feature scaling becomes **critical** for KNN performance. We'll explore this in detail in the second part of this lab."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: First, split into Train (60%) and Temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "# TODO: Next, split the Temp 40% into equal halves for Validation (20%) and Test (20%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \"Validation size:\", X_val.shape[0], \"Test size:\", X_test.shape[0])"
   ],
   "metadata": {
    "id": "zS5RBkbZ3ifX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "After this split, you should see roughly: Train size 120, Validation size 40, Test size 40 (since 60/20/20 of 200 is 120/40/40). It’s important that we do not touch the test set until the very end when we’re ready to evaluate our final model. Using the test set in tuning would be a form of data leakage and could make our evaluation overly optimistic."
   ],
   "metadata": {
    "id": "sr2X48fc4LOc"
   }
  },
  {
   "cell_type": "markdown",
   "source": "> **Question:** Why do we use a separate validation set for hyperparameter tuning instead of using the test set?\n>\n> A) To get an unbiased estimate of model performance - the test set must remain untouched until final evaluation to avoid overfitting to it\n>\n> B) To reduce computational cost - evaluating on a smaller validation set is faster than using the full test set\n>\n> C) To ensure reproducibility - validation sets are easier to recreate with the same random_state parameter\n>\n> D) To enable cross-validation - we can create multiple validation folds from the validation set for robust tuning",
   "metadata": {
    "id": "51xMKuFI4Nky"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have our data split, let’s use our MyKNNClassifier to fit on the training set and evaluate on the validation set. This will serve as a quick check that our implementation works and give us a baseline accuracy for an arbitrary choice of K (say, K=3):"
   ],
   "metadata": {
    "id": "0wFPuf7S4lx1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate our KNN classifier with K=3 (arbitrary choice to start)\n",
    "knn = MyKNNClassifier(k=_________, metric=_________)\n",
    "knn.fit(_________, _________)\n",
    "\n",
    "# TODO: Predict on the validation set\n",
    "y_pred_val = knn.predict(_________)\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "from sklearn.metrics import accuracy_score\n",
    "val_accuracy = accuracy_score(y_val, _________)\n",
    "print(f\"Validation accuracy with k=3: {val_accuracy:.2f}\")"
   ],
   "metadata": {
    "id": "hAtf9us64G24"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The printed accuracy is the proportion of validation points correctly classified with K=3. This gives a sense of how the model is doing with this choice. However, we shouldn’t read too much into a single result — we need to see how K affects performance overall."
   ],
   "metadata": {
    "id": "K-RYU9Cl4s7W"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tuning the Hyperparameter K\n",
    "\n",
    "Let’s systematically evaluate how the choice of K affects the model. We will try a range of K values and compute the accuracy on both the training set and validation set for each K. Tracking training accuracy along with validation accuracy is informative:\n",
    "\n",
    "- Training accuracy tells us how well the model fits the training data.\n",
    "- Validation accuracy tells us how well the model generalizes to unseen data (for different K).\n",
    "\n",
    "By comparing the two, we can diagnose overfitting or underfitting:\n",
    "\n",
    "- If training accuracy is much higher than validation accuracy for a certain K, the model might be overfitting (performing well on train, poorly on val).\n",
    "- If both training and validation accuracies are low, the model might be underfitting (not even fitting the train set well).\n",
    "\n",
    "We’ll evaluate K from 1 up to, say, 15 and record the accuracies:"
   ],
   "metadata": {
    "id": "oxHuV0vY4xNS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "ks = range(1, 16)\n",
    "\n",
    "for k in ks:\n",
    "    # TODO: Set hyperparameters, i.e. k and metric for our KNN classifier\n",
    "    knn = MyKNNClassifier(k=_________, metric=_________)\n",
    "    # TODO: Train final model on training set\n",
    "    knn.fit(_________, _________)\n",
    "    # TODO: Predict on the training set\n",
    "    y_pred_train = _________\n",
    "    # TODO: Compute validation accuracy\n",
    "    train_acc = accuracy_score(_________, _________)\n",
    "    # TODO: Predict on the validation set\n",
    "    y_pred_val = knn.predict(_________)\n",
    "    # TODO: Accuracy on validation set\n",
    "    val_acc = accuracy_score(_________, _________)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "# Determine the best K based on highest validation accuracy\n",
    "best_k = np.argmax(val_accuracies) + 1  # +1 because index 0 corresponds to k=1\n",
    "best_val_acc = val_accuracies[best_k - 1]\n",
    "print(f\"Best K by validation accuracy = {best_k}, which gave val accuracy = {best_val_acc:.3f}\")"
   ],
   "metadata": {
    "id": "cjHkTZ4j5DAk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let’s plot the accuracy vs. K to visualize the trend:"
   ],
   "metadata": {
    "id": "ipyKdwVg47b3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ks, train_accuracies, marker='o', label='Train Accuracy')\n",
    "plt.plot(ks, val_accuracies, marker='s', label='Validation Accuracy')\n",
    "plt.xticks(ks)\n",
    "plt.xlabel('K (Number of Neighbours)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs K for KNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "4lY4Blxs4wVz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plot shows two curves: one for training accuracy and one for validation accuracy as K increases. Observe the behavior:\n",
    "\n",
    "- At K=1 (far left), training accuracy is likely 100% (each point is its own nearest neighbor, so it perfectly predicts training data) while validation accuracy might be significantly lower. This is a sign of overfitting (model too complex, essentially memorizing training data).\n",
    "- As K increases, training accuracy usually drops (the model is less flexible), while validation accuracy may initially increase as overfitting reduces, then eventually decrease once K becomes too large (model underfits by being too rigid).\n",
    "- There is often a sweet spot where validation accuracy is maximized — that is our chosen best K."
   ],
   "metadata": {
    "id": "MKgWuoVF5ONP"
   }
  },
  {
   "cell_type": "markdown",
   "source": "> **Question:** You train a KNN model with K=1 and observe 100% training accuracy but only 70% validation accuracy. What is the most likely explanation?\n>\n> A) The model is overfitting - K=1 creates highly complex decision boundaries that memorize training noise but fail to generalize\n>\n> B) The model needs more features - K=1 doesn't have enough information to make good predictions\n>\n> C) The validation set is too small - increasing its size would likely improve the 70% validation accuracy to match training\n>\n> D) The distance metric is poorly chosen - switching from Euclidean to Manhattan distance would likely close the accuracy gap",
   "metadata": {
    "id": "waax90325WBD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should see from the plot that our training accuracy starts high and decreases as K grows, whereas validation accuracy rises then eventually falls. The best K is where the validation curve peaks. We printed best_k above; let’s proceed with that value.\n",
    "\n",
    "For example, if the plot shows that validation accuracy peaks at K=3 (just an example), then K=3 is our optimal choice on this validation set. We will use this best K for our final model."
   ],
   "metadata": {
    "id": "0ymPTZov5eEm"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Distance Metric Comparison\n\nSo far, we've been using the default Euclidean distance. But KNN can use different distance metrics! The choice of distance metric can significantly affect model performance. Let's compare:\n\n### Common Distance Metrics\n\n1. **Euclidean Distance** (L2 norm):\n   - Formula: $d = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n   - Measures \"straight-line\" distance\n   - Sensitive to magnitude differences\n\n2. **Manhattan Distance** (L1 norm):\n   - Formula: $d = \\sum_{i=1}^{n} |x_i - y_i|$\n   - Measures \"city block\" distance (like navigating a grid)\n   - More robust to outliers\n\nLet's perform a **grid search** over both K values AND distance metrics to find the best combination:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Grid search over K and distance metrics\nk_values = range(1, 21)\nmetrics = ['euclidean', 'manhattan']\nresults = []\n\nfor metric in metrics:\n    metric_train_acc = []\n    metric_val_acc = []\n    \n    for k in k_values:\n        # Use sklearn's KNN with custom metric\n        knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n        knn.fit(X_train_vis, y_train_vis)\n        \n        train_acc = knn.score(X_train_vis, y_train_vis)\n        val_acc = knn.score(X_val_vis, y_val_vis)\n        \n        metric_train_acc.append(train_acc)\n        metric_val_acc.append(val_acc)\n        \n        results.append({\n            'K': k,\n            'Metric': metric,\n            'Train_Accuracy': train_acc,\n            'Val_Accuracy': val_acc\n        })\n    \n    # Plot for this metric\n    plt.plot(k_values, metric_val_acc, marker='o', label=f'{metric.capitalize()} (Val)', linewidth=2)\n\n# Create results table\nresults_df = pd.DataFrame(results)\n\n# Find best configuration\nbest_idx = results_df['Val_Accuracy'].idxmax()\nbest_config = results_df.iloc[best_idx]\n\nprint(\"GRID SEARCH RESULTS: K vs Distance Metric\")\nprint(\"=\" * 60)\n\n# Show sample of results\npivot_table = results_df.pivot(index='K', columns='Metric', values='Val_Accuracy')\nprint(\"\\nValidation Accuracy Table (sample K values):\")\nprint(pivot_table.loc[[1, 3, 5, 7, 9, 11, 13, 15]].to_string())\n\nprint(f\"\\n{'=' * 60}\")\nprint(f\"BEST CONFIGURATION:\")\nprint(f\"  K = {int(best_config['K'])}\")\nprint(f\"  Metric = {best_config['Metric']}\")\nprint(f\"  Validation Accuracy = {best_config['Val_Accuracy']:.4f}\")\nprint(f\"{'=' * 60}\")\n\n# Plotting\nplt.xlabel('K (Number of Neighbors)', fontsize=12)\nplt.ylabel('Validation Accuracy', fontsize=12)\nplt.title('Distance Metric Comparison: Euclidean vs Manhattan', fontsize=14, fontweight='bold')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nKey Observations:\")\nprint(\"- Different distance metrics can lead to different optimal K values\")\nprint(\"- The best metric depends on the data distribution and feature characteristics\")\nprint(\"- Always experiment with multiple metrics during hyperparameter tuning!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Visualizing Decision Boundaries: Euclidean vs Manhattan\n\nNow let's visualize how the choice of distance metric affects the decision boundaries:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom matplotlib.colors import ListedColormap\n\n# Use the best K from our grid search\nbest_k = int(best_config['K'])\n\n# Create a mesh for plotting decision boundaries\nx_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\ny_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\nxx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n                     np.linspace(y_min, y_max, 200))\n\n# Create subplots\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\ncmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\ncmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n\nfor idx, metric in enumerate(['euclidean', 'manhattan']):\n    ax = axes[idx]\n    \n    # Train KNN with this metric\n    knn = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n    knn.fit(X_train_vis, y_train_vis)\n    \n    # Predict on mesh\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    \n    # Plot decision boundary\n    ax.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.4)\n    ax.contour(xx, yy, Z, colors='black', linewidths=0.5, alpha=0.3)\n    \n    # Plot training points\n    ax.scatter(X_train_vis[:, 0], X_train_vis[:, 1], c=y_train_vis, \n               cmap=cmap_bold, edgecolor='black', s=50, alpha=0.8, label='Training data')\n    \n    # Calculate accuracy\n    val_acc = knn.score(X_val_vis, y_val_vis)\n    \n    ax.set_title(f'{metric.capitalize()} Distance (K={best_k})\\nVal Accuracy: {val_acc:.4f}', \n                 fontsize=13, fontweight='bold')\n    ax.set_xlabel('Feature 1', fontsize=11)\n    ax.set_ylabel('Feature 2', fontsize=11)\n    ax.grid(True, alpha=0.3)\n\nplt.suptitle('Decision Boundary Comparison: Different Distance Metrics', \n             fontsize=15, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nObservations:\")\nprint(\"- Euclidean distance creates smoother, more circular decision boundaries\")\nprint(\"- Manhattan distance creates more angular, grid-like decision boundaries\")\nprint(\"- The difference can lead to different classification results, especially near boundaries\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Decision Boundaries\n",
    "\n",
    "To build intuition, let’s visualize the decision boundary of our KNN classifier on this 2D dataset. We’ll use the DecisionBoundaryDisplay.from_estimator utility from scikit-learn to create a contour plot showing which class the KNN would predict at each point in the feature space. We will also plot the training and validation points to see how they fall in relation to the boundaries.\n",
    "\n",
    "Note: This visualization is only possible in low dimensions (2D in our case). It can help us see how the choice of K affects the complexity of the boundary."
   ],
   "metadata": {
    "id": "ep19djdY5h6j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Use the best K found\n",
    "knn_best = MyKNNClassifier(k=best_k, metric='euclidean')\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Plot the decision boundary for the trained classifier\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    knn_best,            # our classifier\n",
    "    X_train,             # the data to use for creating the boundary (training data range)\n",
    "    response_method=\"predict\",\n",
    "    cmap='coolwarm',     # color map for regions\n",
    "    alpha=0.5            # transparency of the boundary overlay\n",
    ")\n",
    "\n",
    "# Overlay the validation data with class labels\n",
    "class_names = ['0', '1']\n",
    "colors = ['lightblue', 'orange']\n",
    "for i, color in enumerate(colors):\n",
    "    idx = np.where(y_val == i)\n",
    "    ax.scatter(X_val[idx, 0], X_val[idx, 1], c=color, edgecolor='k', s=100, label=f'{class_names[i]}')\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.legend(loc='best')  # Position the legend to not overlap with data\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.title(f\"KNN Decision Boundary (K={best_k})\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "CihL7ifb5U-a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the visualization:\n",
    "\n",
    "-\tThe colored regions (background) indicate the predicted class by KNN across the feature space (red vs blue regions).\n",
    "-\tPoints are plotted on top: training points (small circles) and validation points (star markers) in their true class colors.\n",
    "-\tYou can visually inspect how well the boundary separates the classes and where errors occur (validation stars that lie in a region of the opposite color would be misclassified)."
   ],
   "metadata": {
    "id": "6d1Kmd0s5x0G"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try experimenting by changing best_k to a smaller value (like 1) or a larger value and re-running the boundary plot code. You’ll see:\n",
    "\n",
    "- For small K (e.g., 1-3): the decision boundary will be very wiggly and complex, wrapping tightly around individual training points. This can slice the space into many small regions (possibly leading to misclassifications on validation points that fall in strange pockets).\n",
    "- For large K (e.g., 10+): the decision boundary will be much smoother, perhaps a simple shape dividing the two main clusters, but it might misclassify points that actually could be distinguished with a more nuanced boundary.\n",
    "\n",
    "This aligns with our earlier discussion on overfitting vs underfitting:\n",
    "\n",
    "- Small K => complex boundary (risk of overfitting).\n",
    "- Large K => simple boundary (risk of underfitting)."
   ],
   "metadata": {
    "id": "yBTrpflZ6B7k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating on the Test Set\n",
    "\n",
    "We used the validation set to choose the best K. Now it’s time to get an unbiased evaluation of our model using the test set (which we haven’t touched so far).\n",
    "\n",
    "Before evaluating, it’s common practice (if data permits) to retrain the model on the combined training + validation data using the chosen hyperparameters. The idea is to utilize all available data (except test) for training now that we’ve fixed K, to potentially improve the model’s performance. In our case, we have a fairly small dataset, so this might help a bit.\n",
    "\n",
    "Let’s combine the training and validation sets, retrain MyKNNClassifier with best_k on this larger set, and then evaluate on the test set:"
   ],
   "metadata": {
    "id": "GQ5cn6Qg6Lc-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Combine train+val for final training\n",
    "X_train_val = np.vstack([X_train, X_val])\n",
    "y_train_val = np.hstack([y_train, y_val])\n",
    "\n",
    "# TODO: Train final model on combined data\n",
    "final_knn = MyKNNClassifier(k=best_k, distance_metric='euclidean')\n",
    "_________\n",
    "\n",
    "# TODO: Predict on the test set\n",
    "y_pred_test = _________\n",
    "# TODO: Compute test accuracy\n",
    "test_accuracy = accuracy_score(_________, _________)\n",
    "print(f\"Test Accuracy with K={best_k}: {test_accuracy:.3f}\")"
   ],
   "metadata": {
    "id": "JifqvcS-57R1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will create a confusion matrix for the test predictions. A confusion matrix shows how the model’s predictions compare to the true labels, broken down by class. It’s a great way to see which classes the model is getting wrong, not just how many it got wrong.\n",
    "\n",
    "For our binary class problem (class 0 vs class 1):\n",
    "\n",
    "- The confusion matrix will be 2x2.\n",
    "- Rows typically represent the true class, and columns the predicted class.\n",
    "- The cell (i, j) will contain the number of instances of true class i that were predicted as class j.\n",
    "\n",
    "Let’s compute and visualize the confusion matrix:"
   ],
   "metadata": {
    "id": "bt6irtJp6UAu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title(f\"Confusion Matrix (Test) - K={best_k}\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "3btLVtlu6ajy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine the confusion matrix:\n",
    "\n",
    "- The diagonal [top-left and bottom-right] are the counts of correct predictions for class 0 and class 1, respectively.\n",
    "- The off-diagonals [top-right, bottom-left] are the misclassifications:\n",
    "- Top-right: how many class 0 were wrongly predicted as class 1.\n",
    "- Bottom-left: how many class 1 were wrongly predicted as class 0.\n",
    "\n",
    "For example, a confusion matrix output:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "18 & 2 \\\\\n",
    "3  & 17\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "would mean:\n",
    "- 18 instances of class 0 correctly predicted as 0 (true negatives if class 1 is “positive”).\n",
    "- 17 instances of class 1 correctly predicted as 1 (true positives).\n",
    "- 2 instances of class 0 misclassified as 1 (false positives).\n",
    "- 3 instances of class 1 misclassified as 0 (false negatives).\n",
    "\n",
    "Using the confusion matrix along with accuracy gives us a more complete picture. We can identify if the model is skewed towards one class or if certain classes are harder to predict."
   ],
   "metadata": {
    "id": "T6Jz79ai6dfQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": "> **Question:** What additional information does a confusion matrix provide beyond overall accuracy?\n>\n> A) Per-class performance showing which classes are well-predicted and which are frequently confused with each other\n>\n> B) The optimal K value that would maximize accuracy for each individual class\n>\n> C) Feature importance scores indicating which input features contribute most to correct classifications\n>\n> D) Probability distributions showing the model's confidence level for each prediction",
   "metadata": {
    "id": "KqAIF5Oe7aaU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpreting Results:\n",
    "\n",
    "- Check the test accuracy you obtained. Is it close to the validation accuracy at best K? Ideally, it should be in a similar ballpark if our validation selection was effective and there was no overfitting to the validation set.\n",
    "- Look at the confusion matrix. Are the errors mostly in one of the off-diagonals? This might indicate if the model has a bias towards predicting one class more often (for instance, if one class has more examples).\n",
    "- If we saw a large difference between training and validation accuracy earlier (a sign of overfitting), did using the best K and more training data improve the situation?"
   ],
   "metadata": {
    "id": "Ll19DAZ97kMe"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying KNN to the Wine Dataset\n",
    "\n",
    "Now that we’ve implemented and tested KNN on a synthetic dataset, let’s apply our MyKNNClassifier to a real-world dataset: the classic Wine recognition dataset. This dataset consists of chemical analysis results of wines derived from three different cultivars (classes). There are 13 numeric features (like alcohol content, malic acid, etc.) and 3 classes of wine.\n",
    "\n",
    "We will see how KNN performs on this multi-class dataset and demonstrate the critical importance of feature scaling.\n",
    "\n",
    "Loading and Exploring the Data\n",
    "\n",
    "First, load the dataset and inspect its basic properties:"
   ],
   "metadata": {
    "id": "vO-FicWi7vy6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load the wine dataset\n",
    "wine = load_wine()\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "print(\"Wine data shape:\", X_wine.shape, \"Labels:\", set(y_wine))\n",
    "print(\"Feature names:\", wine.feature_names)\n",
    "print(\"Class names:\", wine.target_names)"
   ],
   "metadata": {
    "id": "Rf4KwfOc7W49"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will output:\n\n- Shape of the data (should be (178, 13) meaning 178 samples, 13 features).\n- The set of labels (0, 1, 2 corresponding to the three wine classes).\n- The feature names and class names (class names might be generic like class_0, class_1, etc., since this dataset doesn't give actual cultivar names)."
   ],
   "metadata": {
    "id": "9YG9_2Rs72XD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Split into Train (70%) and Test (30%)\\\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(\n",
    "    X_wine, y_wine, test_size=_________, random_state=42, stratify=_________\n",
    ")\n",
    "print(\"Wine train size:\", X_train_w.shape[0], \"test size:\", X_test_w.shape[0])"
   ],
   "metadata": {
    "id": "9-Op4l7t79Lp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, important: The features in the wine dataset have very different scales (for example, “Alcohol” might be in the range 11-14, “Malic acid” in 0-5, “Proline” in 200-1700, etc.). We must scale the features before using KNN. We will compare model performance with and without scaling to emphasize this.\n",
    "\n",
    "We’ll use standardization (z-scores) via StandardScaler to scale features to mean 0 and variance 1. We fit the scaler on the training data only (to avoid leaking information from the test set), then transform both train and test sets:"
   ],
   "metadata": {
    "id": "hYDdarpw8CKT"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Why Feature Scaling Matters: A Concrete Example\n\nBefore we apply scaling, let's understand **why** it's critical for KNN. Consider measuring similarity between people using height (in cm) and weight (in kg):\n\n### Example: Distance Without Scaling\n\n**Person A**: Height = 170 cm, Weight = 60 kg  \n**Person B**: Height = 160 cm, Weight = 60 kg  \n**Distance (Manhattan)**: |170 - 160| + |60 - 60| = **10**\n\n**Person C**: Height = 170 cm, Weight = 60 kg  \n**Person D**: Height = 170 cm, Weight = 70 kg  \n**Distance (Manhattan)**: |170 - 170| + |60 - 70| = **10**\n\n### The Problem\n\nBoth pairs have the same distance (10), but:\n- **Pair A-B**: Differ by 10 cm in height (about 6% difference)\n- **Pair C-D**: Differ by 10 kg in weight (about 17% difference)\n\n**The 10 kg weight difference is much more significant than the 10 cm height difference**, yet they contribute equally to the distance calculation!\n\n### Why This Happens\n\nFeatures with **larger scales** (like height in cm: 150-190) dominate features with **smaller scales** (like weight in kg: 50-90). KNN treats all features equally in distance calculations, so large-scale features disproportionately influence neighbor selection.\n\nLet's see this numerically:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\n\n# Define the people (height in cm, weight in kg)\nperson_A = np.array([170, 60])\nperson_B = np.array([160, 60])\nperson_C = np.array([170, 60])\nperson_D = np.array([170, 70])\n\n# Calculate Manhattan distances\ndef manhattan_distance(p1, p2):\n    return np.sum(np.abs(p1 - p2))\n\ndist_AB = manhattan_distance(person_A, person_B)\ndist_CD = manhattan_distance(person_C, person_D)\n\nprint(\"WITHOUT SCALING:\")\nprint(f\"Distance between A and B: {dist_AB}\")\nprint(f\"  - Height difference: {abs(person_A[0] - person_B[0])} cm\")\nprint(f\"  - Weight difference: {abs(person_A[1] - person_B[1])} kg\")\nprint()\nprint(f\"Distance between C and D: {dist_CD}\")\nprint(f\"  - Height difference: {abs(person_C[0] - person_D[0])} cm\")\nprint(f\"  - Weight difference: {abs(person_C[1] - person_D[1])} kg\")\nprint()\nprint(\"Problem: Both distances are equal (10), but they represent different similarities!\")\nprint()\n\n# Now let's scale the features\nfrom sklearn.preprocessing import StandardScaler\n\n# Create a small dataset to fit the scaler\ndata = np.array([[170, 60], [160, 60], [170, 70], [165, 65]])\nscaler = StandardScaler()\nscaler.fit(data)\n\n# Scale all four people\nperson_A_scaled = scaler.transform([person_A])[0]\nperson_B_scaled = scaler.transform([person_B])[0]\nperson_C_scaled = scaler.transform([person_C])[0]\nperson_D_scaled = scaler.transform([person_D])[0]\n\ndist_AB_scaled = manhattan_distance(person_A_scaled, person_B_scaled)\ndist_CD_scaled = manhattan_distance(person_C_scaled, person_D_scaled)\n\nprint(\"AFTER SCALING:\")\nprint(f\"Distance between A and B: {dist_AB_scaled:.3f}\")\nprint(f\"Distance between C and D: {dist_CD_scaled:.3f}\")\nprint()\nprint(\"✓ Now the distances reflect true similarity!\")\nprint(\"✓ Features are on comparable scales, and KNN can make better decisions.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Understanding Standardization: Z-Scores\n\nNow that we understand why scaling matters, let's learn **how** StandardScaler works. It uses **Z-score standardization** (also called **standardization**).\n\n### The Z-Score Formula\n\nFor each feature, StandardScaler transforms values using:\n\n$$Z = \\frac{x - \\mu}{\\sigma}$$\n\nWhere:\n- **x** = original feature value\n- **μ (mu)** = mean of the feature across all training samples\n- **σ (sigma)** = standard deviation of the feature across all training samples\n- **Z** = standardized value (z-score)\n\n### What This Does\n\n1. **Centers the data**: Subtracting μ shifts the mean to 0\n2. **Scales the data**: Dividing by σ makes the standard deviation = 1\n3. **Result**: All features have mean = 0 and std = 1 (comparable scales!)\n\n### Example\n\nLet's say we have a feature with values: [10, 20, 30, 40, 50]\n- Mean (μ) = 30\n- Standard deviation (σ) ≈ 14.14\n\nFor x = 50:\n$$Z = \\frac{50 - 30}{14.14} = \\frac{20}{14.14} ≈ 1.41$$\n\nThis means 50 is **1.41 standard deviations above the mean**.\n\nLet's see this in action with code:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Create sample data with two features on different scales\n# Feature 1: Height in cm (150-190)\n# Feature 2: Weight in kg (50-90)\nnp.random.seed(42)\nheights = np.random.uniform(150, 190, 100)\nweights = np.random.uniform(50, 90, 100)\ndata = np.column_stack([heights, weights])\n\nprint(\"BEFORE STANDARDIZATION:\")\nprint(f\"Heights - Mean: {np.mean(heights):.2f}, Std: {np.std(heights):.2f}\")\nprint(f\"Weights - Mean: {np.mean(weights):.2f}, Std: {np.std(weights):.2f}\")\nprint()\n\n# Apply StandardScaler\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data)\n\nprint(\"AFTER STANDARDIZATION:\")\nprint(f\"Heights - Mean: {np.mean(data_scaled[:, 0]):.6f}, Std: {np.std(data_scaled[:, 0]):.6f}\")\nprint(f\"Weights - Mean: {np.mean(data_scaled[:, 1]):.6f}, Std: {np.std(data_scaled[:, 1]):.6f}\")\nprint()\n\n# Manual calculation example\nprint(\"MANUAL CALCULATION EXAMPLE:\")\nprint(\"Take the first height value:\", heights[0])\nmu_height = np.mean(heights)\nsigma_height = np.std(heights)\nz_score_manual = (heights[0] - mu_height) / sigma_height\nprint(f\"Z = (x - μ) / σ = ({heights[0]:.2f} - {mu_height:.2f}) / {sigma_height:.2f} = {z_score_manual:.6f}\")\nprint(f\"StandardScaler result: {data_scaled[0, 0]:.6f}\")\nprint(\"✓ They match!\")\nprint()\n\n# Visualize the distributions before and after\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Before scaling\naxes[0, 0].hist(heights, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\naxes[0, 0].axvline(np.mean(heights), color='red', linestyle='--', linewidth=2, label=f'Mean = {np.mean(heights):.1f}')\naxes[0, 0].set_title('Height (Before Scaling)', fontsize=12, fontweight='bold')\naxes[0, 0].set_xlabel('Height (cm)')\naxes[0, 0].legend()\n\naxes[0, 1].hist(weights, bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\naxes[0, 1].axvline(np.mean(weights), color='red', linestyle='--', linewidth=2, label=f'Mean = {np.mean(weights):.1f}')\naxes[0, 1].set_title('Weight (Before Scaling)', fontsize=12, fontweight='bold')\naxes[0, 1].set_xlabel('Weight (kg)')\naxes[0, 1].legend()\n\n# After scaling\naxes[1, 0].hist(data_scaled[:, 0], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\naxes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2, label='Mean = 0')\naxes[1, 0].set_title('Height (After Scaling)', fontsize=12, fontweight='bold')\naxes[1, 0].set_xlabel('Standardized Height (Z-score)')\naxes[1, 0].legend()\n\naxes[1, 1].hist(data_scaled[:, 1], bins=20, color='lightgreen', edgecolor='black', alpha=0.7)\naxes[1, 1].axvline(0, color='red', linestyle='--', linewidth=2, label='Mean = 0')\naxes[1, 1].set_title('Weight (After Scaling)', fontsize=12, fontweight='bold')\naxes[1, 1].set_xlabel('Standardized Weight (Z-score)')\naxes[1, 1].legend()\n\nplt.suptitle('Effect of Z-Score Standardization', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"Key Takeaway: After standardization, both features have mean ≈ 0 and std ≈ 1\")\nprint(\"This puts them on equal footing for distance calculations in KNN!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "# TODO: Fit on training data and transform training data\n",
    "X_train_w_scaled = scaler.fit_transform(_________)\n",
    "# TODO: Transform test data using the fitted scaler\n",
    "X_test_w_scaled = scaler.transform(_________)"
   ],
   "metadata": {
    "id": "EzSHY0Bw8F4U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: We only call fit_transform on the training data. The test data is transformed with the same scaling parameters. This ensures that our model is truly tested on unseen data that hasn’t influenced the scaling. Never fit the scaler (or any preprocessing) on the full dataset before splitting or on the test set – that would introduce data leakage and inflate performance."
   ],
   "metadata": {
    "id": "YPEKjIw38Iqh"
   }
  },
  {
   "cell_type": "markdown",
   "source": "> **Question:** When using StandardScaler with train/validation/test splits, what is the correct order of operations to avoid data leakage?\n>\n> A) Fit the scaler on training data only, then transform train, validation, and test sets using those fitted parameters\n>\n> B) Fit separate scalers on each dataset (train, validation, test) and transform each with its own parameters\n>\n> C) Fit the scaler on the combined training and validation sets, then transform all three sets\n>\n> D) Fit the scaler on all data combined before splitting to ensure consistent scaling across datasets",
   "metadata": {
    "id": "A0rlwaalLEdE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let’s evaluate KNN on the wine dataset in two scenarios:\n",
    "\n",
    "1.\tWithout scaling – using the original features.\n",
    "2.\tWith scaling – using the standardized features.\n",
    "\n",
    "For simplicity, we’ll use the same K for both scenarios (for instance, K = 3, which is a common choice and often near optimal as well). If you want, you could perform a quick tune on the training set or via cross-validation to find the best K for wine, but here our focus is on the effect of scaling."
   ],
   "metadata": {
    "id": "ANPQxcrLK_Oy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. KNN on Wine data (unscaled features)"
   ],
   "metadata": {
    "id": "PLqkSEbi8UrN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Train final model on unscaled features\n",
    "knn_wine = MyKNNClassifier(k=3, metric='euclidean')\n",
    "knn_wine.fit(_________, _________)\n",
    "# TODO: Predict on the test set\n",
    "y_pred_wine = _________\n",
    "# TODO: Find accuracy score\n",
    "acc_wine = accuracy_score(y_test_w, _________)\n",
    "print(f\"KNN accuracy on Wine test (unscaled features, k=3): {acc_wine:.3f}\")\n",
    "\n",
    "# TODO: Compare model’s predictions with the true labels, broken down by class\n",
    "cm_wine = confusion_matrix(_________, _________)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_wine, annot=True, fmt='d', cmap=\"YlOrBr\",\n",
    "            xticklabels=[f\"Pred {c}\" for c in range(3)],\n",
    "            yticklabels=[f\"Actual {c}\" for c in range(3)])\n",
    "plt.title(\"Wine Data Confusion Matrix (Unscaled)\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "NhqQuHbz8Rtm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This will output the accuracy and show the confusion matrix for the 3-class classification. You will likely observe a moderate accuracy (often around 0.65-0.75 range for KNN unscaled on wine) and the confusion matrix may show a lot of misclassifications (off-diagonal counts)."
   ],
   "metadata": {
    "id": "RyI0332q8bVx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. KNN on Wine data (scaled features)"
   ],
   "metadata": {
    "id": "iXPzf_ch8eJB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Train final model on unscaled features\n",
    "knn_wine_scaled = MyKNNClassifier(k=3, distance_metric='euclidean')\n",
    "knn_wine_scaled.fit(_________, _________)\n",
    "# TODO: Predict on the test set\n",
    "y_pred_wine_scaled = _________\n",
    "# TODO: Find accuracy score\n",
    "acc_wine_scaled = _________\n",
    "print(f\"KNN accuracy on Wine test (scaled features, k=3): {acc_wine_scaled:.3f}\")\n",
    "\n",
    "# TODO: See which classes the model is getting wrong\n",
    "cm_wine_scaled = confusion_matrix(_________, _________)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_wine_scaled, annot=True, fmt='d', cmap=\"YlGnBu\",\n",
    "            xticklabels=[f\"Pred {c}\" for c in range(3)],\n",
    "            yticklabels=[f\"Actual {c}\" for c in range(3)])\n",
    "plt.title(\"Wine Data Confusion Matrix (Scaled)\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "Dz5sZjG98dd1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now check the printed accuracies and the confusion matrices side by side:\n",
    "\n",
    "- You should see that accuracy with scaled features is significantly higher than without scaling. It’s not uncommon to see unscaled KNN around ~70% accuracy vs scaled KNN around ~95% accuracy on this wine dataset.\n",
    "- The unscaled confusion matrix likely showed many off-diagonal values (mix-ups among classes), whereas the scaled confusion matrix should have clearer dominance on the diagonal (more correct classifications per class).\n",
    "\n",
    "This dramatic difference occurs because, without scaling, some features (like “Proline” which can have values in the hundreds) dominate the distance calculation, drowning out the influence of other features. After scaling, each feature contributes more equally, and KNN can make much better distinctions between the classes."
   ],
   "metadata": {
    "id": "uUeBhmh-8kyX"
   }
  },
  {
   "cell_type": "markdown",
   "source": "> **Question:** Why did KNN perform significantly better after feature scaling on the Wine dataset?\n>\n> A) Scaling prevents features with larger ranges (like Proline 280-1700) from dominating distance calculations over smaller-range features\n>\n> B) Scaling improves the mathematical properties of the distance metric, making Euclidean distance more stable numerically\n>\n> C) Scaling increases the effective sample size by making data points more uniformly distributed in feature space\n>\n> D) Scaling reduces overfitting by constraining all features to similar ranges, which acts as a form of regularization",
   "metadata": {
    "id": "dJBMx0z28uIF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Wine Data with t-SNE\n",
    "\n",
    "To further illustrate the effect of scaling on the data itself, we can use t-SNE (t-distributed Stochastic Neighbor Embedding) to visualize the wine data in two dimensions. t-SNE is a nonlinear dimensionality reduction technique that tries to preserve the local structure of the data (i.e., points that are close in original space stay close in the embedding). It’s useful for visualizing high-dimensional data.\n",
    "\n",
    "We’ll create two t-SNE plots: one on the original features, one on the scaled features, and compare them."
   ],
   "metadata": {
    "id": "Y8_0FKV-83Sb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE on original wine data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_wine_tsne_orig = tsne.fit_transform(X_wine)  # using all data for visualization\n",
    "\n",
    "# t-SNE on scaled wine data\n",
    "tsne2 = TSNE(n_components=2, random_state=42)\n",
    "X_wine_tsne_scaled = tsne2.fit_transform(StandardScaler().fit_transform(X_wine))"
   ],
   "metadata": {
    "id": "Vst89TWG8qeK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let’s plot these side by side. We’ll color points by their true class label (0, 1, 2) to see if classes form distinct clusters. We want to use the same color scheme for both plots for a fair comparison:"
   ],
   "metadata": {
    "id": "1Mhzh0yh9Ap-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a color mapping for the three classes\n",
    "cmap = plt.cm.viridis\n",
    "norm = plt.Normalize(vmin=y_wine.min(), vmax=y_wine.max())\n",
    "target_names = wine.target_names  # e.g., ['class_0', 'class_1', 'class_2']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Plot t-SNE for original data\n",
    "scatter0 = axes[0].scatter(X_wine_tsne_orig[:, 0], X_wine_tsne_orig[:, 1],\n",
    "                           c=y_wine, cmap=cmap, norm=norm, edgecolor='k', alpha=0.7)\n",
    "axes[0].set_title(\"t-SNE (Original Features)\")\n",
    "axes[0].set_xlabel(\"TSNE 1\")\n",
    "axes[0].set_ylabel(\"TSNE 2\")\n",
    "# Plot t-SNE for scaled data\n",
    "scatter1 = axes[1].scatter(X_wine_tsne_scaled[:, 0], X_wine_tsne_scaled[:, 1],\n",
    "                           c=y_wine, cmap=cmap, norm=norm, edgecolor='k', alpha=0.7)\n",
    "axes[1].set_title(\"t-SNE (Scaled Features)\")\n",
    "axes[1].set_xlabel(\"TSNE 1\")\n",
    "axes[1].set_ylabel(\"TSNE 2\")\n",
    "\n",
    "# Add a legend using class names for colors\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='none', label=name,\n",
    "                          markerfacecolor=cmap(norm(i)), markersize=8, edgecolor='k')\n",
    "                   for i, name in enumerate(target_names)]\n",
    "axes[1].legend(handles=legend_elements, title=\"Wine Class\", loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "WRyNrG8y9CzU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interpret the t-SNE plots:\n\n- Original features t-SNE: You might see that the points are in a weird, perhaps elongated shape or not clearly separated by class. The classes could be mixed together because certain features dominated distances, causing t-SNE to bunch points oddly.\n- Scaled features t-SNE: Here, you should observe more distinct clustering of points by class. The three classes are likely more separable (perhaps forming three clusters or at least tighter groupings of same-colored points). This indicates that after scaling, the inherent structure of the data (different wine classes) is clearer in the feature space, which is why KNN could perform better."
   ],
   "metadata": {
    "id": "uF6B3cm79Ju2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Understanding Model Predictions: Error Analysis\n\nSo far we've looked at overall accuracy, but where exactly does our KNN model make mistakes? Understanding **where** and **why** errors occur helps us:\n\n1. **Identify problematic regions** in the feature space\n2. **Understand model limitations** (e.g., does it fail in overlapping regions?)\n3. **Guide improvements** (e.g., collect more data in ambiguous regions)\n\nLet's perform an error analysis on our Wine dataset predictions. We'll identify:\n- Which test samples were misclassified\n- Whether errors occur in regions where classes overlap (high ambiguity)\n- How the model's certainty relates to classification accuracy\n\nThis analysis connects back to the t-SNE visualization—errors should occur where classes overlap!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.manifold import TSNE\n\n# Train KNN on scaled Wine data (using best K=5 or adjust as needed)\nbest_k_wine = 5  # Adjust based on your tuning results\nknn_wine = KNeighborsClassifier(n_neighbors=best_k_wine)\nknn_wine.fit(X_train_wine_scaled, y_train_wine)\n\n# Get predictions and prediction probabilities\ny_pred_wine = knn_wine.predict(X_test_wine_scaled)\ny_pred_proba_wine = knn_wine.predict_proba(X_test_wine_scaled)\n\n# Calculate prediction certainty (max probability)\nprediction_certainty = np.max(y_pred_proba_wine, axis=1)\n\n# Identify correct and incorrect predictions\ncorrect_mask = (y_pred_wine == y_test_wine)\nincorrect_mask = ~correct_mask\n\n# Error Analysis Summary\nprint(\"ERROR ANALYSIS SUMMARY\")\nprint(\"=\" * 70)\nprint(f\"Total test samples: {len(y_test_wine)}\")\nprint(f\"Correct predictions: {np.sum(correct_mask)} ({100*np.mean(correct_mask):.2f}%)\")\nprint(f\"Incorrect predictions: {np.sum(incorrect_mask)} ({100*np.mean(incorrect_mask):.2f}%)\")\nprint()\n\n# Analyze prediction certainty\nprint(\"PREDICTION CERTAINTY ANALYSIS\")\nprint(\"=\" * 70)\nprint(f\"Average certainty (correct predictions): {np.mean(prediction_certainty[correct_mask]):.4f}\")\nprint(f\"Average certainty (incorrect predictions): {np.mean(prediction_certainty[incorrect_mask]):.4f}\")\nprint()\nprint(\"Insight: Lower certainty often indicates ambiguous regions where classes overlap.\")\nprint()\n\n# Show misclassified examples\nif np.sum(incorrect_mask) > 0:\n    print(\"MISCLASSIFIED EXAMPLES:\")\n    print(\"=\" * 70)\n    print(f\"{'Index':<8} {'True Class':<12} {'Predicted':<12} {'Certainty':<12}\")\n    print(\"-\" * 70)\n    \n    misclassified_indices = np.where(incorrect_mask)[0]\n    for idx in misclassified_indices[:10]:  # Show first 10\n        print(f\"{idx:<8} {y_test_wine.iloc[idx]:<12} {y_pred_wine[idx]:<12} {prediction_certainty[idx]:<12.4f}\")\n    \n    if len(misclassified_indices) > 10:\n        print(f\"... and {len(misclassified_indices) - 10} more\")\n    print()\n\n# Visualize errors in t-SNE space\nprint(\"Visualizing errors in t-SNE reduced space...\")\nprint()\n\n# Perform t-SNE on test data\ntsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X_test_wine_scaled)-1))\nX_test_tsne = tsne.fit_transform(X_test_wine_scaled)\n\n# Create visualization\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Plot 1: Color by true class\nax1 = axes[0]\ncolors = ['red', 'green', 'blue']\nclass_names = ['Class 0', 'Class 1', 'Class 2']\n\nfor class_idx in range(3):\n    mask = y_test_wine == class_idx\n    ax1.scatter(X_test_tsne[mask, 0], X_test_tsne[mask, 1], \n                c=colors[class_idx], label=class_names[class_idx], \n                s=100, alpha=0.6, edgecolors='black')\n\nax1.set_title('Test Data: Colored by True Class', fontsize=13, fontweight='bold')\nax1.set_xlabel('t-SNE Dimension 1', fontsize=11)\nax1.set_ylabel('t-SNE Dimension 2', fontsize=11)\nax1.legend(fontsize=10)\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Highlight errors\nax2 = axes[1]\n\n# Plot correct predictions in light gray\nax2.scatter(X_test_tsne[correct_mask, 0], X_test_tsne[correct_mask, 1], \n            c='lightgray', label='Correct', s=100, alpha=0.4, edgecolors='black', linewidths=0.5)\n\n# Plot incorrect predictions with high visibility\nax2.scatter(X_test_tsne[incorrect_mask, 0], X_test_tsne[incorrect_mask, 1], \n            c='red', label='Misclassified', s=200, alpha=0.8, edgecolors='black', \n            linewidths=2, marker='X')\n\nax2.set_title('Test Data: Highlighting Misclassifications', fontsize=13, fontweight='bold')\nax2.set_xlabel('t-SNE Dimension 1', fontsize=11)\nax2.set_ylabel('t-SNE Dimension 2', fontsize=11)\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\n\nplt.suptitle('Error Analysis: Where Does KNN Make Mistakes?', fontsize=15, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"KEY INSIGHTS:\")\nprint(\"- Misclassified points (red X's) often appear in overlapping regions\")\nprint(\"- These are ambiguous regions where classes are not well-separated\")\nprint(\"- KNN struggles when nearest neighbors belong to different classes\")\nprint(\"- This connects to the t-SNE visualization: errors occur where clusters overlap!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "- Implemented KNN from scratch as MyKNNClassifier and verified it works similarly to scikit-learn’s KNN.\n",
    "- Used training, validation, test splits to tune the hyperparameter K without leaking test information. We observed how to pick the best K by validation accuracy.\n",
    "- Explored the bias-variance trade-off in KNN: small K vs large K and how they affect decision boundaries and accuracy.\n",
    "- Emphasized evaluation using accuracy and confusion matrices. Accuracy gives an overall performance, while confusion matrices provide insight into class-wise performance and misclassification patterns.\n",
    "- Highlighted feature scaling as a critical preprocessing step for KNN. The Wine dataset example showed that scaling features (using StandardScaler) dramatically improved KNN accuracy, and t-SNE visualizations helped explain why.\n",
    "- Incorporated various best practices:\n",
    "- Shape and input validation in our implementation (to catch mistakes early).\n",
    "- Warnings about data leakage (e.g., fitting scalers on full data or using test data in tuning).\n",
    "- Setting random_state for reproducibility of our data splits and t-SNE.\n",
    "- Creating scalable visualizations (like adjusting marker sizes and using transparency for large scatter plots, and programmatically generating legends) to handle different dataset sizes and clarity.\n",
    "\n",
    "KNN is a simple yet powerful algorithm for many scenarios. However, keep in mind:\n",
    "- It can be computationally expensive for large datasets (since distance to all training points must be computed for each prediction).\n",
    "- It doesn’t produce an explicit model, so storage of training data and prediction speed can be issues.\n",
    "- It often serves as a good baseline but may be outperformed by more complex models with proper training. Still, the lessons about cross-validation, scaling, and evaluation we practiced here apply to many other machine learning algorithms.\n"
   ],
   "metadata": {
    "id": "bFLBvAVD9SWY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Wrap-Up Question**: Bias–variance in KNN:\n",
    ">\n",
    "> A. small K → low bias / high variance ; large K → high bias / low variance\n",
    ">\n",
    "> B. small K → high bias / low variance ; large K → low bias / high variance\n",
    ">\n",
    "> C. both small & large K → high variance\n",
    ">\n",
    ">D. K doesn’t affect either"
   ],
   "metadata": {
    "id": "ZCZHchoILX-K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Great job completing the lab! Feel free to experiment further:\n",
    ">\n",
    "> - Try other distance metrics (Manhattan, cosine) by setting distance_metric in MyKNNClassifier and see how the decision boundaries or accuracy change.\n",
    "> - Use cross-validation to confirm the best K.\n",
    "> - Explore how KNN deals with higher-dimensional data or imbalanced classes, etc."
   ],
   "metadata": {
    "id": "OI5VYiYL9qcx"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "EAJ8rrwj9Qb7"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}