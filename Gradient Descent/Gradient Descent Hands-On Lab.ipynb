{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Gradient%20Descent/Gradient%20Descent%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Hands-On Lab\n",
    "\n",
    "In this lab, you will implement Gradient Descent optimization from scratch, understand the mathematics behind it, and apply it to real data. Along the way, you'll answer conceptual questions and create visualizations to deepen your understanding.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the mathematics of Gradient Descent optimization\n",
    "- Implement a custom Gradient Descent class from scratch\n",
    "- Visualize convergence and loss curves\n",
    "- Understand the impact of learning rate on convergence\n",
    "- Apply feature scaling and understand why it's critical for gradient descent\n",
    "- Compare gradient descent with closed-form solutions\n",
    "- Understand batch, stochastic, and mini-batch variants\n",
    "- Analyze model performance and convergence behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Overview of Gradient Descent\n\nGradient Descent is an **iterative optimization algorithm** used to find the minimum of a function. In machine learning, we use it to **minimize the loss function** and find optimal model parameters.\n\n**Key Idea:**\n- Start with **random weights**\n- Iteratively **update weights** in the direction that reduces loss\n- Take steps proportional to the **negative gradient** of the loss function\n- Continue until **convergence** (loss stops decreasing)\n\n**The Update Rule:**\n$$w_{\\text{new}} = w_{\\text{old}} - \\alpha \\nabla_w L$$\n\nWhere:\n- **w** are the model weights (parameters)\n- **\u03b1** is the learning rate (step size)\n- **\u2207w L** is the gradient of the loss with respect to weights\n- **L** is the loss function (e.g., Sum of Squared Errors)\n\n**For Linear Regression with SSE Loss:**\n- Loss: $L(w) = \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n- Gradient: $\\nabla_w L = -2 \\Phi^T (y - \\Phi w)$\n- Update: $w = w - \\alpha \\nabla_w L$\n- Expanded form: $w = w - \\alpha(-2\\Phi^T(y - \\Phi w)) = w + 2\\alpha \\Phi^T (y - \\Phi w)$\n\n**Advantages:**\n- Works when no closed-form solution exists (e.g., neural networks)\n- Scales well to large datasets\n- Can be adapted to stochastic/mini-batch variants for efficiency\n- Foundation for deep learning optimization\n\n**Disadvantages:**\n- Requires tuning hyperparameters (learning rate, iterations)\n- Can be slow to converge\n- May get stuck in local minima (for non-convex functions)\n- Sensitive to feature scaling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: Gradient Descent finds optimal weights by:\n",
    ">\n",
    "> A. Computing the exact optimal solution directly using matrix inversion and least squares\n",
    ">\n",
    "> B. Iteratively updating weights in the direction that minimizes the loss function gradient\n",
    ">\n",
    "> C. Evaluating multiple weight configurations and selecting the combination with lowest validation error\n",
    ">\n",
    "> D. Approximating the closed-form solution through successive linearizations of the loss surface\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: This describes the normal equation for Linear Regression: w = (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y. The normal equation computes the exact optimal solution in one step through direct matrix operations, without any iteration. Gradient descent, in contrast, is an iterative method that gradually approaches the optimal solution.\n",
    "- **B is TRUE**: Gradient descent computes the gradient \u2207w L (the direction of steepest ascent) and updates weights in the opposite direction (steepest descent): w_new = w_old - \u03b1\u2207w L. By repeatedly taking steps in the direction that reduces loss most quickly, it converges to a minimum.\n",
    "- **C is FALSE**: While this describes a valid optimization approach (grid search or random search), it's not gradient descent. Gradient descent uses calculus-based gradients to determine the exact direction to move, not trial-and-error evaluation of different configurations. Grid search would be extremely inefficient for high-dimensional problems.\n",
    "- **D is FALSE**: This might describe methods like Newton's method or successive quadratic approximations, which use second-order information (Hessian matrix). Gradient descent uses only first-order gradients and doesn't approximate closed-form solutions - it directly minimizes the loss iteratively.\n",
    "\n",
    "**Key Insight**: Gradient descent is a **first-order, gradient-based, iterative optimization** method. It uses calculus to find the steepest descent direction, then takes small steps in that direction.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent vs Normal Equation (Closed-Form Solution)\n",
    "\n",
    "For Linear Regression, we have **two ways** to find optimal weights:\n",
    "\n",
    "### 1. Normal Equation (Closed-Form)\n",
    "$$w = (\\Phi^T \\Phi)^{-1} \\Phi^T y$$\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Exact optimal solution in one calculation\n",
    "- \u2705 No hyperparameters to tune\n",
    "- \u2705 No iterations needed\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Requires matrix inversion: O(d\u00b3) complexity (slow for many features)\n",
    "- \u274c Doesn't scale to very large datasets (memory intensive)\n",
    "- \u274c Only works for problems with closed-form solutions\n",
    "\n",
    "### 2. Gradient Descent (Iterative)\n",
    "$$w = w - \\alpha \\nabla_w L$$\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Scales well to large datasets (especially mini-batch/stochastic variants)\n",
    "- \u2705 Works for any differentiable loss function\n",
    "- \u2705 Foundation for neural networks and deep learning\n",
    "- \u2705 Can stop early if convergence is good enough\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Requires tuning learning rate and iterations\n",
    "- \u274c Slower convergence (multiple iterations)\n",
    "- \u274c Very sensitive to feature scaling\n",
    "\n",
    "### When to Use Each:\n",
    "\n",
    "| Scenario | Best Choice |\n",
    "|----------|-------------|\n",
    "| Small dataset (N < 10,000), few features (d < 1,000) | Normal Equation |\n",
    "| Large dataset (N > 100,000) | Gradient Descent (Mini-batch) |\n",
    "| Many features (d > 10,000) | Gradient Descent |\n",
    "| Neural networks, non-linear models | Gradient Descent (only option) |\n",
    "| Need exact optimal solution | Normal Equation |\n",
    "| Online learning (streaming data) | Stochastic Gradient Descent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Learning Rate: Critical Hyperparameter\n",
    "\n",
    "The **learning rate (\u03b1)** controls how big of a step we take in each iteration.\n",
    "\n",
    "### Impact of Different Learning Rates:\n",
    "\n",
    "**\u03b1 too small (e.g., 0.0001):**\n",
    "- \u2705 Stable convergence (doesn't overshoot)\n",
    "- \u274c Very slow (needs many iterations)\n",
    "- \u274c May get stuck in plateaus\n",
    "\n",
    "**\u03b1 optimal (e.g., 0.01-0.1):**\n",
    "- \u2705 Fast convergence\n",
    "- \u2705 Reaches minimum efficiently\n",
    "- \u2705 Smooth loss curve\n",
    "\n",
    "**\u03b1 too large (e.g., 1.0+):**\n",
    "- \u274c Overshoots minimum\n",
    "- \u274c Loss oscillates or increases\n",
    "- \u274c May diverge (loss \u2192 \u221e)\n",
    "\n",
    "We'll visualize these effects later in the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You're training a model with gradient descent and observe that the loss is increasing rather than decreasing over iterations. What is the MOST likely cause?\n",
    ">\n",
    "> A. The model architecture is too simple to capture the underlying data patterns effectively\n",
    ">\n",
    "> B. The learning rate is too large, causing the optimizer to overshoot the minimum\n",
    ">\n",
    "> C. The features need standardization because different scales are destabilizing gradient magnitudes\n",
    ">\n",
    "> D. The convergence tolerance is set too loose, allowing premature stopping at suboptimal solutions\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Model underfitting means the model can't fit the training data well, resulting in HIGH but STABLE loss that plateaus at a suboptimal value. The loss would remain consistently high across iterations, not increase over time. If loss is increasing, the optimization process itself is failing, not the model's representational capacity.\n",
    "- **B is TRUE**: When the learning rate \u03b1 is too large, the weight update w_new = w_old - \u03b1\u2207w overshoots the minimum. Instead of moving toward the optimal point, it jumps past it to a worse position with higher loss. In extreme cases, this causes divergence where loss \u2192 \u221e. The classic symptom of excessive learning rate is monotonically increasing loss or wild oscillations.\n",
    "- **C is FALSE**: While feature scaling IS very important for gradient descent stability, unscaled features typically cause SLOW and erratic convergence with oscillating loss, not monotonically increasing loss. Unscaled features create elongated loss surfaces that require careful learning rate tuning, but the loss would still trend downward overall, just very slowly and unstably.\n",
    "- **D is FALSE**: Convergence tolerance controls when training stops (when loss change falls below threshold). If tolerance is too loose, training might stop early, but this would result in HIGH loss at stopping time, not INCREASING loss. Increasing loss indicates the optimizer is actively making things worse, not stopping too early.\n",
    "\n",
    "**Key Insight**: Increasing loss during training almost always indicates \u03b1 is too large. Solution: reduce learning rate by 10\u00d7 (e.g., 0.1 \u2192 0.01).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: Critical for Gradient Descent!\n",
    "\n",
    "While feature scaling is recommended for Linear Regression's normal equation, it's **ESSENTIAL** for gradient descent.\n",
    "\n",
    "**Why is scaling so important for gradient descent?**\n",
    "\n",
    "1. **Convergence Speed:** Unscaled features create elongated loss surfaces\n",
    "   - Gradient descent zigzags instead of going straight to minimum\n",
    "   - Can be 100\u00d7 slower or more!\n",
    "   \n",
    "2. **Learning Rate Sensitivity:** Different features need different learning rates\n",
    "   - Small-scale features (0-1) might need \u03b1 = 0.1\n",
    "   - Large-scale features (0-10000) might need \u03b1 = 0.00001\n",
    "   - With one global \u03b1, impossible to optimize all features well\n",
    "   \n",
    "3. **Numerical Stability:** Large feature values can cause gradient explosion\n",
    "   - Gradients become huge \u2192 weights explode \u2192 overflow errors\n",
    "\n",
    "**Solution: Z-Score Standardization**\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "This transforms all features to:\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "- Similar scales \u2192 uniform convergence\n",
    "\n",
    "**Critical Rule:** Fit scaler on training data ONLY!\n",
    "```python\n",
    "scaler.fit(X_train)  # Learn \u03bc and \u03c3 from training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)    # Use same \u03bc and \u03c3\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same \u03bc and \u03c3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for Gradient Descent\n",
    "\n",
    "### Formal Pseudocode\n",
    "\n",
    "```\n",
    "============================================\n",
    "Inputs\n",
    "============================================\n",
    "X       \u2190 training features (N \u00d7 d matrix)\n",
    "y       \u2190 training targets (N \u00d7 1 vector)\n",
    "\u03b1       \u2190 learning rate (e.g., 0.01)\n",
    "max_iter \u2190 maximum iterations (e.g., 1000)\n",
    "tol     \u2190 convergence tolerance (e.g., 1e-6)\n",
    "\n",
    "============================================\n",
    "----- fit -----\n",
    "============================================\n",
    "1. Add bias column: \u03a6 \u2190 [1, X]  # (N \u00d7 (d+1))\n",
    "2. Initialize weights randomly: w \u2190 random small values\n",
    "3. For iteration = 1 to max_iter:\n",
    "     a. Compute predictions: \u0177 \u2190 \u03a6w\n",
    "     b. Compute errors: e \u2190 y - \u0177\n",
    "     c. Compute loss: L \u2190 (1/N) \u03a3 e\u00b2\n",
    "     d. Compute gradients: \u2207w \u2190 -(2/N) \u03a6\u1d40e\n",
    "     e. Update weights: w \u2190 w - \u03b1\u2207w\n",
    "     f. If |L_new - L_old| < tol: STOP (converged)\n",
    "4. Store final weights w\n",
    "\n",
    "============================================\n",
    "----- predict -----\n",
    "============================================\n",
    "For each query point in X_query:\n",
    "1. Add bias: \u03a6_query \u2190 [1, X_query]\n",
    "2. Compute prediction: \u0177 \u2190 \u03a6_query \u00b7 w\n",
    "3. Return \u0177\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "- **Iterative process:** Weights improve gradually over multiple iterations\n",
    "- **Convergence check:** Stop when loss stops decreasing significantly\n",
    "- **Prediction:** Same as Linear Regression (just matrix multiplication)\n",
    "- **Memory efficient:** Only stores weights (not all training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom Gradient Descent Class\n",
    "\n",
    "Below is a scaffold of the `MyGradientDescentRegressor` class. Fill in the TODO sections to complete the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class MyGradientDescentRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom Gradient Descent implementation for Linear Regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate : float, default=0.01\n",
    "        Learning rate (\u03b1) for gradient descent updates\n",
    "    max_iter : int, default=1000\n",
    "        Maximum number of iterations\n",
    "    tol : float, default=1e-6\n",
    "        Tolerance for convergence (stop if loss change < tol)\n",
    "    random_state : int, default=42\n",
    "        Random seed for weight initialization\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    weights_ : array of shape (n_features + 1,)\n",
    "        Learned weights including bias term\n",
    "    loss_history_ : list\n",
    "        Loss value at each iteration\n",
    "    n_iter_ : int\n",
    "        Actual number of iterations performed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000, tol=1e-6, random_state=42):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model using gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        # TODO: Create design matrix Phi by adding column of ones for bias term\n",
    "        Phi = None\n",
    "        \n",
    "        # TODO: Initialize weights randomly with small values (use self.random_state)\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights_ = None\n",
    "        \n",
    "        # Initialize loss history\n",
    "        self.loss_history_ = []\n",
    "        N = len(y)\n",
    "        \n",
    "        # Gradient Descent Loop\n",
    "        for iteration in range(self.max_iter):\n",
    "            # TODO: Compute predictions using current weights\n",
    "            predictions = None\n",
    "            \n",
    "            # TODO: Compute errors (residuals)\n",
    "            errors = None\n",
    "            \n",
    "            # TODO: Compute loss (Mean Squared Error)\n",
    "            loss = None\n",
    "            \n",
    "            # Store loss\n",
    "            self.loss_history_.append(loss)\n",
    "            \n",
    "            # Check convergence\n",
    "            if iteration > 0 and abs(self.loss_history_[-2] - self.loss_history_[-1]) < self.tol:\n",
    "                self.n_iter_ = iteration + 1\n",
    "                break\n",
    "            \n",
    "            # TODO: Compute gradients using the formula: -(2/N) * \u03a6\u1d40(y - \u0177)\n",
    "            gradients = None\n",
    "            \n",
    "            # TODO: Update weights using gradient descent update rule\n",
    "            pass\n",
    "        else:\n",
    "            self.n_iter_ = self.max_iter\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the learned model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : array of shape (n_samples,)\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        # TODO: Create design matrix (same as in fit)\n",
    "        Phi = None\n",
    "        \n",
    "        # TODO: Compute predictions\n",
    "        y_pred = None\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Once you have filled in the implementation, let's test our custom gradient descent regressor on a simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple test data\n",
    "np.random.seed(42)\n",
    "X_simple = np.array([[1], [2], [3], [4], [5]])\n",
    "y_simple = np.array([2, 4, 6, 8, 10])  # Perfect linear relationship: y = 2x\n",
    "\n",
    "# Fit model\n",
    "model = MyGradientDescentRegressor(learning_rate=0.01, max_iter=1000)\n",
    "model.fit(X_simple, y_simple)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_simple)\n",
    "\n",
    "print(\"Learned weights (w0=intercept, w1=slope):\", model.weights_)\n",
    "print(\"Expected: [0, 2] or very close to it\")\n",
    "print(\"\\nPredictions:\", predictions)\n",
    "print(\"Actual:     \", y_simple)\n",
    "print(\"\\nFinal MSE:\", model.loss_history_[-1])\n",
    "print(\"Expected: very close to 0\")\n",
    "print(f\"\\nConverged in {model.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence\n",
    "\n",
    "Let's plot the loss over iterations to see how the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Gradient Descent Convergence', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial loss: {model.loss_history_[0]:.6f}\")\n",
    "print(f\"Final loss:   {model.loss_history_[-1]:.6f}\")\n",
    "print(f\"Improvement:  {(1 - model.loss_history_[-1]/model.loss_history_[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: In a well-tuned gradient descent setup, what should the loss curve look like?\n",
    ">\n",
    "> A. Monotonically decreasing at a constant rate until reaching exactly zero at convergence\n",
    ">\n",
    "> B. Decreasing rapidly at first, then gradually slowing and flattening near the minimum\n",
    ">\n",
    "> C. Fluctuating randomly around a central value with gradually decreasing variance over iterations\n",
    ">\n",
    "> D. Decreasing in distinct steps with plateaus between iterations where no progress occurs\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Loss rarely decreases at a constant rate or reaches exactly zero. The rate of decrease depends on the gradient magnitude, which changes as you approach the minimum (gradients get smaller \u2192 slower progress). For noisy data, loss plateaus at a positive value (residual error), not zero. A constant-rate decrease would indicate the learning rate isn't being adjusted for the changing gradient landscape.\n",
    "- **B is TRUE**: A healthy loss curve shows: (1) Rapid decrease initially when gradients are large and weights are far from optimal, (2) Gradual slowdown as gradients become smaller near the minimum, (3) Flattening/plateau at convergence when gradient \u2248 0. This \"fast then slow\" pattern is the signature of successful first-order optimization approaching a local minimum.\n",
    "- **C is FALSE**: Random fluctuation is characteristic of stochastic gradient descent (SGD) using single samples or small mini-batches, not well-tuned batch gradient descent. For batch GD using all training data, the gradient is deterministic and loss should decrease monotonically. While SGD's fluctuation can help escape shallow local minima, it's not the expected behavior for standard batch GD.\n",
    "- **D is FALSE**: Distinct steps with plateaus suggest the learning rate is poorly tuned or there are numerical precision issues. Smooth gradient descent should show continuous progress, not discrete jumps. Step-like behavior might indicate: batch updates (normal for mini-batch GD), learning rate schedules with sudden drops, or gradient clipping thresholds being hit.\n",
    "\n",
    "**Key Insight**: Loss should decrease monotonically (batch GD) or with downward trend (SGD/mini-batch) and flatten at convergence. The rate of decrease naturally slows as you approach the minimum.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Dataset for Visualization\n",
    "\n",
    "Let's work with the same synthetic dataset from the Linear Regression lab to directly compare approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the same data as in Linear Regression Code Walk Through\n",
    "np.random.seed(42)\n",
    "X_train = np.arange(-9.5, 8.5, 0.1).reshape(-1, 1)\n",
    "y_train = X_train.ravel() + 1 + np.random.normal(0, 2, len(X_train))\n",
    "\n",
    "print(f\"Training data: {len(X_train)} points\")\n",
    "print(f\"X range: [{X_train.min():.1f}, {X_train.max():.1f}]\")\n",
    "print(f\"y range: [{y_train.min():.1f}, {y_train.max():.1f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Training Data: Linear Relationship with Noise', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your MyGradientDescentRegressor on the training data\n",
    "model = None\n",
    "\n",
    "print(f\"Learned weights: {model.weights_}\")\n",
    "print(f\"Model equation: y = {model.weights_[1]:.3f}x + {model.weights_[0]:.3f}\")\n",
    "print(f\"Converged in {model.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit\n",
    "x_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(x_line)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'GD fit: y={model.weights_[1]:.2f}x+{model.weights_[0]:.2f}')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Gradient Descent: Best Fit Line', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Training Loss Over Iterations', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial loss: {model.loss_history_[0]:.6f}\")\n",
    "print(f\"Final loss:   {model.loss_history_[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Learning Rate\n",
    "\n",
    "Let's experiment with different learning rates to see how they affect convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    model_lr = MyGradientDescentRegressor(learning_rate=lr, max_iter=100)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    \n",
    "    plt.plot(range(1, len(model_lr.loss_history_) + 1), model_lr.loss_history_,\n",
    "            linewidth=2, color=color, label=f'\u03b1 = {lr} ({model_lr.n_iter_} iter)')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Impact of Learning Rate on Convergence', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log scale to see all curves\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- \u03b1 = 0.001: Very slow convergence (needs more iterations)\")\n",
    "print(\"- \u03b1 = 0.01:  Good convergence speed\")\n",
    "print(\"- \u03b1 = 0.1:   Fast convergence\")\n",
    "print(\"- \u03b1 = 0.5:   May oscillate or diverge (too large)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You train gradient descent with \u03b1=0.001 for 100 iterations and the loss is still decreasing steadily. What should you do?\n",
    ">\n",
    "> A. Reduce the learning rate to \u03b1=0.0001 to ensure more stable and reliable convergence\n",
    ">\n",
    "> B. Increase max_iter to allow more iterations, or increase \u03b1 to converge faster\n",
    ">\n",
    "> C. Stop training now since 100 iterations provides sufficient convergence for most models\n",
    ">\n",
    "> D. Switch to the normal equation approach which guarantees finding the optimal solution faster\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The learning rate \u03b1=0.001 is already quite small. Decreasing it further to 0.0001 would make convergence even SLOWER, requiring even MORE iterations to reach the minimum. Since loss is steadily decreasing (not oscillating or diverging), there's no stability problem - the optimization is working correctly, just slowly.\n",
    "- **B is TRUE**: Steadily decreasing loss means gradient descent is working correctly but needs more time to converge. Two solutions: (1) Increase max_iter (e.g., to 1000 or 10000) to allow more iterations with the current learning rate, or (2) Increase \u03b1 (e.g., to 0.01 or 0.1) to take bigger steps and converge faster. The second option is usually more efficient for computational cost.\n",
    "- **C is FALSE**: There's no universal \"sufficient\" number of iterations. Required iterations depend on: learning rate, data size, feature scales, initialization, and convergence tolerance. If loss is still decreasing steadily after 100 iterations, the model hasn't converged yet. Stopping now would leave you with a suboptimal solution unnecessarily.\n",
    "- **D is FALSE**: \"Loss still decreasing steadily\" means gradient descent IS working properly - it just hasn't finished yet. This is not a failure case requiring a different algorithm. The normal equation would give the same final solution but doesn't provide insight into convergence behavior. For small problems, either approach works; switching algorithms mid-optimization is unnecessary.\n",
    "\n",
    "**Key Insight**: Steadily decreasing loss = working correctly but not converged yet. Solution: increase iterations or increase learning rate (carefully monitor for divergence). Oscillating/increasing loss = problem with learning rate.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Different Gradient Descent Variants\n",
    "\n",
    "There are three main variants of gradient descent:\n",
    "\n",
    "### 1. Batch Gradient Descent (What We Implemented)\n",
    "- Uses **ALL training data** in each iteration\n",
    "- Computes gradient using entire dataset: \u2207w = -(2/N) \u03a6\u1d40(y - \u03a6w)\n",
    "- **Pros:** Stable, smooth convergence, exact gradient\n",
    "- **Cons:** Slow for large datasets (must process all N samples per iteration)\n",
    "\n",
    "### 2. Stochastic Gradient Descent (SGD)\n",
    "- Uses **ONE random sample** in each iteration\n",
    "- Computes gradient using single example: \u2207w \u2248 -2(y\u1d62 - \u0177\u1d62)\u03c6\u1d62\n",
    "- **Pros:** Very fast iterations, can escape local minima, online learning\n",
    "- **Cons:** Noisy updates, erratic convergence, requires learning rate decay\n",
    "\n",
    "### 3. Mini-Batch Gradient Descent (Most Popular!)\n",
    "- Uses **SMALL BATCH** (e.g., 32, 64, 128 samples) in each iteration\n",
    "- Computes gradient using batch: \u2207w \u2248 -(2/B) \u03a3\u1d62(y\u1d62 - \u0177\u1d62)\u03c6\u1d62\n",
    "- **Pros:** Balance of speed and stability, GPU-friendly, works with large data\n",
    "- **Cons:** Adds batch size as hyperparameter\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "| Aspect | Batch GD | Stochastic GD | Mini-Batch GD |\n",
    "|--------|----------|---------------|---------------|\n",
    "| **Samples per iter** | All N | 1 | B (e.g., 32) |\n",
    "| **Gradient accuracy** | Exact | Noisy | Approximate |\n",
    "| **Convergence** | Smooth | Erratic | Smooth-ish |\n",
    "| **Speed per iter** | Slow | Very fast | Fast |\n",
    "| **Memory usage** | High | Low | Medium |\n",
    "| **Use case** | Small data | Online learning | Large data, deep learning |\n",
    "\n",
    "**Note:** Scikit-learn's `SGDRegressor` uses Stochastic GD, which is why our results differ slightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You have a dataset with 10 million training examples and want to train a linear regression model. Which optimization approach is MOST practical?\n",
    ">\n",
    "> A. Normal equation using closed-form solution for guaranteed optimal weights in one computation\n",
    ">\n",
    "> B. Batch gradient descent processing all 10 million samples in each iteration for exact gradients\n",
    ">\n",
    "> C. Mini-batch gradient descent with batches of 128-256 samples for efficiency and stability\n",
    ">\n",
    "> D. Stochastic gradient descent using exactly one random sample per iteration for maximum speed\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The normal equation requires computing (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y, where \u03a6 is 10M \u00d7 d. This involves: (1) Matrix multiplication O(Nd\u00b2) \u2248 billions of operations, (2) Matrix inversion O(d\u00b3), (3) Storing a 10M \u00d7 d matrix in memory (potentially gigabytes). For N=10M, this is extremely slow and memory-intensive. The normal equation doesn't scale to large datasets.\n",
    "- **B is FALSE**: Batch GD must process all 10 million samples in EACH iteration to compute one gradient. Even if each iteration takes 10 seconds and you need 100 iterations, that's 1000 seconds (16 minutes) of computation. Additionally, loading all 10M samples into memory simultaneously is impractical. Full batch GD doesn't scale to large datasets.\n",
    "- **C is TRUE**: Mini-batch GD with batch size B=128 means: (1) Only 128 samples in memory at once (feasible), (2) Fast iterations (~milliseconds each), (3) Can stream data from disk in chunks, (4) Parallelizes well on GPUs, (5) Good gradient estimates with much less computation. With B=128 and N=10M, each epoch is ~78,000 mini-batches, but each is very fast. This is standard for large-scale ML.\n",
    "- **D is FALSE**: While SGD (B=1) has very fast iterations, it's TOO noisy for stable convergence on 10M samples. The gradient from a single sample is a poor estimate of the true gradient direction, requiring many epochs and careful learning rate decay. Mini-batch (B=128-256) provides better balance: more stable than pure SGD, much faster than batch GD.\n",
    "\n",
    "**Key Insight**: For large datasets (N > 100,000), mini-batch gradient descent is the practical choice. It balances computational efficiency, memory usage, and convergence stability. This is why deep learning uses mini-batch GD almost exclusively.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Gradient Descent is an iterative optimization algorithm**\n",
    "   - Updates weights in direction that reduces loss: w = w - \u03b1\u2207w L\n",
    "   - Converges to optimal solution through many small steps\n",
    "   - Foundation for training neural networks and deep learning\n",
    "\n",
    "2. **Learning rate (\u03b1) is critical**\n",
    "   - Too small \u2192 slow convergence (many iterations needed)\n",
    "   - Too large \u2192 divergence (loss increases or oscillates)\n",
    "   - Typical range: 0.001 to 0.1\n",
    "   - Monitor loss curve to diagnose issues\n",
    "\n",
    "3. **Feature scaling is ESSENTIAL for gradient descent**\n",
    "   - Unscaled features cause slow/unstable convergence\n",
    "   - Different features need different step sizes \u2192 impossible with one \u03b1\n",
    "   - Always use StandardScaler or MinMaxScaler\n",
    "   - Fit scaler on training data ONLY!\n",
    "\n",
    "4. **Convergence monitoring**\n",
    "   - Plot loss over iterations\n",
    "   - Healthy curve: decreasing and flattening\n",
    "   - Stop when loss change < tolerance\n",
    "   - Early stopping prevents wasted computation\n",
    "\n",
    "5. **Gradient descent vs Normal equation**\n",
    "   - Normal equation: Fast for small data, exact solution, no tuning\n",
    "   - Gradient descent: Scales to large data, works for any model, needs tuning\n",
    "   - Both converge to same solution for linear regression\n",
    "\n",
    "### When to Use Gradient Descent\n",
    "\n",
    "\u2705 **Use Gradient Descent when:**\n",
    "- Training neural networks (only option available)\n",
    "- Dataset is very large (N > 100,000)\n",
    "- Online learning (data arrives in streams)\n",
    "- Need mini-batch or stochastic variants\n",
    "- Working with distributed systems (can parallelize mini-batches)\n",
    "\n",
    "\u274c **Use Normal Equation when:**\n",
    "- Small-medium dataset (N < 10,000)\n",
    "- Few features (d < 1,000)\n",
    "- Want exact solution without tuning\n",
    "- Simple linear regression\n",
    "\n",
    "### Gradient Descent Variants Summary\n",
    "\n",
    "| Variant | Samples/Iter | Best For |\n",
    "|---------|--------------|----------|\n",
    "| **Batch GD** | All N | Small datasets, smooth convergence |\n",
    "| **Stochastic GD** | 1 | Online learning, escaping local minima |\n",
    "| **Mini-Batch GD** | 32-256 | Large datasets, deep learning (MOST COMMON) |\n",
    "\n",
    "### Best Practices Checklist\n",
    "\n",
    "- \u2705 Always standardize features using StandardScaler\n",
    "- \u2705 Fit scaler on training data only (avoid data leakage)\n",
    "- \u2705 Start with learning rate \u03b1 = 0.01, adjust based on loss curve\n",
    "- \u2705 Monitor loss over iterations to diagnose convergence\n",
    "- \u2705 Use early stopping to prevent wasted computation\n",
    "- \u2705 Initialize weights with small random values\n",
    "- \u2705 For large data, use mini-batch variant (B=32-256)\n",
    "- \u2705 Compare with closed-form solution when possible (validation)\n",
    "- \u2705 Use learning rate decay for better convergence (advanced)\n",
    "- \u2705 Visualize loss curves to understand convergence behavior\n",
    "\n",
    "### Debugging Gradient Descent\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|--------------|----------|\n",
    "| Loss increasing | \u03b1 too large | Decrease learning rate by 10\u00d7 |\n",
    "| Loss oscillating | \u03b1 too large | Decrease learning rate |\n",
    "| Very slow convergence | \u03b1 too small OR unscaled features | Increase \u03b1 or standardize features |\n",
    "| Loss stuck at high value | Poor initialization OR bad \u03b1 | Try different random seed or \u03b1 |\n",
    "| NaN/Inf values | Gradient explosion | Standardize features, decrease \u03b1 |\n",
    "| Doesn't converge after 10k iter | Unscaled features | Standardize features! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Final Question**: You're training a neural network and observe that the training loss decreases smoothly for 50 epochs, then suddenly starts increasing. What is the MOST likely explanation?\n",
    ">\n",
    "> A. The model has successfully converged to the optimal region and is now oscillating around it\n",
    ">\n",
    "> B. The learning rate should be increased to accelerate convergence and escape local plateaus\n",
    ">\n",
    "> C. The learning rate is too high for later epochs and needs decay or reduction\n",
    ">\n",
    "> D. Feature standardization was skipped, causing numerical instability in later training stages only\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: If the model had converged optimally, the loss would plateau (stay relatively constant with small fluctuations), not suddenly increase. Increasing loss means the model is moving AWAY from the optimal solution, which is the opposite of convergence. Oscillation around a minimum would show small fluctuations, not systematic increase.\n",
    "- **B is FALSE**: If loss is already increasing after epoch 50, making the learning rate LARGER will make the problem dramatically worse! The model is already overshooting the minimum, so bigger steps would cause even more overshooting and potentially divergence to infinity. This would accelerate the problem, not solve it.\n",
    "- **C is TRUE**: This is a classic pattern: initially, when weights are far from optimal, a larger learning rate (e.g., \u03b1=0.1) works well for rapid progress. But as the model approaches the minimum (after ~50 epochs), those same large steps start overshooting. The loss surface becomes very narrow near the minimum, so the learning rate that worked early now causes instability. Solution: learning rate decay/scheduling (reduce \u03b1 over time).\n",
    "- **D is FALSE**: If features weren't standardized, you'd see problems from the VERY FIRST epoch - extremely slow convergence, erratic oscillations, or immediate divergence. The fact that loss decreased smoothly for 50 epochs proves features were properly scaled. This issue starting at epoch 50 indicates a learning rate problem specific to later training stages, not a data preprocessing issue.\n",
    "\n",
    "**Key Insight**: Loss decreasing then increasing suggests the learning rate is too large for the current optimization stage. Use learning rate schedules/decay: start high for fast initial progress, reduce over time for stable convergence near the minimum. This is standard practice in deep learning (e.g., cosine annealing, step decay).\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}