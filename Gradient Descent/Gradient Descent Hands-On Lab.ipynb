{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Gradient%20Descent/Gradient%20Descent%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Hands-On Lab\n",
    "\n",
    "In this lab, you will implement Gradient Descent optimization from scratch, understand the mathematics behind it, and apply it to real data. Along the way, you'll answer conceptual questions and create visualizations to deepen your understanding.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the mathematics of Gradient Descent optimization\n",
    "- Implement a custom Gradient Descent class from scratch\n",
    "- Visualize convergence and loss curves\n",
    "- Understand the impact of learning rate on convergence\n",
    "- Apply feature scaling and understand why it's critical for gradient descent\n",
    "- Compare gradient descent with closed-form solutions\n",
    "- Understand batch, stochastic, and mini-batch variants\n",
    "- Analyze model performance and convergence behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Overview of Gradient Descent\n\nGradient Descent is an **iterative optimization algorithm** used to find the minimum of a function. In machine learning, we use it to **minimize the loss function** and find optimal model parameters.\n\n**Key Idea:**\n- Start with **random weights**\n- Iteratively **update weights** in the direction that reduces loss\n- Take steps proportional to the **negative gradient** of the loss function\n- Continue until **convergence** (loss stops decreasing)\n\n**The Update Rule:**\n$$w_{\\text{new}} = w_{\\text{old}} - \\alpha \\nabla_w L$$\n\nWhere:\n- **w** are the model weights (parameters)\n- **\u03b1** is the learning rate (step size)\n- **\u2207w L** is the gradient of the loss with respect to weights\n- **L** is the loss function (e.g., Sum of Squared Errors)\n\n**For Linear Regression with SSE Loss:**\n- Loss: $L(w) = \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n- Gradient: $\\nabla_w L = -2 \\Phi^T (y - \\Phi w)$\n- Update: $w = w - \\alpha \\nabla_w L$\n- Expanded form: $w = w - \\alpha(-2\\Phi^T(y - \\Phi w)) = w + 2\\alpha \\Phi^T (y - \\Phi w)$\n\n**Advantages:**\n- Works when no closed-form solution exists (e.g., neural networks)\n- Scales well to large datasets\n- Can be adapted to stochastic/mini-batch variants for efficiency\n- Foundation for deep learning optimization\n\n**Disadvantages:**\n- Requires tuning hyperparameters (learning rate, iterations)\n- Can be slow to converge\n- May get stuck in local minima (for non-convex functions)\n- Sensitive to feature scaling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> **Question**: Gradient Descent finds optimal weights by:\n>\n> A. Computing the exact optimal solution directly using matrix inversion like the normal equation\n>\n> B. Iteratively updating weights in the direction that reduces the loss function using gradients\n>\n> C. Randomly trying different weight combinations until finding the best performing set\n>\n> D. Using K-nearest neighbors to estimate optimal weight values from training data\n\n<details><summary>Click to reveal answer</summary>\n\n**Correct Answer: B**\n\n**Explanation:**\n- **A is FALSE**: This describes the normal equation for Linear Regression: w = (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y. The normal equation computes the exact optimal solution in one step, without any iteration. Gradient descent, in contrast, is an iterative method that gradually approaches the optimal solution.\n- **B is TRUE**: Gradient descent computes the gradient \u2207w L (the direction of steepest ascent of the loss function) and updates weights in the opposite direction (steepest descent): w_new = w_old - \u03b1\u2207w L. By repeatedly taking small steps downhill, it converges to a local minimum (global for convex functions like SSE).\n- **C is FALSE**: Gradient descent is not random! It uses calculus (derivatives/gradients) to determine the exact direction to move weights. Random search would be extremely inefficient and wouldn't scale to high-dimensional problems.\n- **D is FALSE**: KNN is an instance-based learning algorithm for prediction, not an optimization method for finding weights. Gradient descent doesn't use neighbors or training data directly during the update step - it only uses gradients computed from the loss function.\n\n**Key Insight**: Gradient descent is a **deterministic, iterative, gradient-based optimization** method. It uses calculus to find the direction that most quickly reduces loss, then takes small steps in that direction.\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent vs Normal Equation (Closed-Form Solution)\n",
    "\n",
    "For Linear Regression, we have **two ways** to find optimal weights:\n",
    "\n",
    "### 1. Normal Equation (Closed-Form)\n",
    "$$w = (\\Phi^T \\Phi)^{-1} \\Phi^T y$$\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Exact optimal solution in one calculation\n",
    "- \u2705 No hyperparameters to tune\n",
    "- \u2705 No iterations needed\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Requires matrix inversion: O(d\u00b3) complexity (slow for many features)\n",
    "- \u274c Doesn't scale to very large datasets (memory intensive)\n",
    "- \u274c Only works for problems with closed-form solutions\n",
    "\n",
    "### 2. Gradient Descent (Iterative)\n",
    "$$w = w - \\alpha \\nabla_w L$$\n",
    "\n",
    "**Pros:**\n",
    "- \u2705 Scales well to large datasets (especially mini-batch/stochastic variants)\n",
    "- \u2705 Works for any differentiable loss function\n",
    "- \u2705 Foundation for neural networks and deep learning\n",
    "- \u2705 Can stop early if convergence is good enough\n",
    "\n",
    "**Cons:**\n",
    "- \u274c Requires tuning learning rate and iterations\n",
    "- \u274c Slower convergence (multiple iterations)\n",
    "- \u274c Very sensitive to feature scaling\n",
    "\n",
    "### When to Use Each:\n",
    "\n",
    "| Scenario | Best Choice |\n",
    "|----------|-------------|\n",
    "| Small dataset (N < 10,000), few features (d < 1,000) | Normal Equation |\n",
    "| Large dataset (N > 100,000) | Gradient Descent (Mini-batch) |\n",
    "| Many features (d > 10,000) | Gradient Descent |\n",
    "| Neural networks, non-linear models | Gradient Descent (only option) |\n",
    "| Need exact optimal solution | Normal Equation |\n",
    "| Online learning (streaming data) | Stochastic Gradient Descent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Learning Rate: Critical Hyperparameter\n",
    "\n",
    "The **learning rate (\u03b1)** controls how big of a step we take in each iteration.\n",
    "\n",
    "### Impact of Different Learning Rates:\n",
    "\n",
    "**\u03b1 too small (e.g., 0.0001):**\n",
    "- \u2705 Stable convergence (doesn't overshoot)\n",
    "- \u274c Very slow (needs many iterations)\n",
    "- \u274c May get stuck in plateaus\n",
    "\n",
    "**\u03b1 optimal (e.g., 0.01-0.1):**\n",
    "- \u2705 Fast convergence\n",
    "- \u2705 Reaches minimum efficiently\n",
    "- \u2705 Smooth loss curve\n",
    "\n",
    "**\u03b1 too large (e.g., 1.0+):**\n",
    "- \u274c Overshoots minimum\n",
    "- \u274c Loss oscillates or increases\n",
    "- \u274c May diverge (loss \u2192 \u221e)\n",
    "\n",
    "We'll visualize these effects later in the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You're training a model with gradient descent and observe that the loss is increasing rather than decreasing over iterations. What is the MOST likely cause?\n",
    ">\n",
    "> A. The model is underfitting because it's too simple to capture the data patterns\n",
    ">\n",
    "> B. The learning rate is too large, causing the optimizer to overshoot the minimum\n",
    ">\n",
    "> C. The features need to be standardized using z-score normalization\n",
    ">\n",
    "> D. The number of iterations is too small and convergence hasn't been reached yet\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Underfitting means the model can't fit the training data well, which would result in HIGH but STABLE loss. The loss would remain consistently high across iterations, not increase. If loss is increasing, the optimization process itself is failing, not the model capacity.\n",
    "- **B is TRUE**: When the learning rate \u03b1 is too large, the weight update w_new = w_old - \u03b1\u2207w can overshoot the minimum. Instead of moving toward the optimal point, it jumps past it to a worse position with higher loss. In extreme cases, this causes divergence where loss \u2192 \u221e. The classic symptom of too-large learning rate is loss increasing or wildly oscillating.\n",
    "- **C is FALSE**: While feature scaling IS very important for gradient descent (unstandardized features cause slow/unstable convergence), it typically causes SLOW convergence or oscillation, not monotonically increasing loss. Unscaled features make the loss surface elongated, requiring careful learning rate tuning, but don't inherently cause divergence.\n",
    "- **D is FALSE**: Too few iterations would mean you haven't reached the minimum yet, so loss would still be HIGH but DECREASING. If loss is increasing, stopping earlier wouldn't help - the problem is the update direction or step size is wrong.\n",
    "\n",
    "**Key Insight**: Increasing loss during training almost always indicates \u03b1 is too large. Solution: reduce learning rate by 10\u00d7 (e.g., 0.1 \u2192 0.01).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: Critical for Gradient Descent!\n",
    "\n",
    "While feature scaling is recommended for Linear Regression's normal equation, it's **ESSENTIAL** for gradient descent.\n",
    "\n",
    "**Why is scaling so important for gradient descent?**\n",
    "\n",
    "1. **Convergence Speed:** Unscaled features create elongated loss surfaces\n",
    "   - Gradient descent zigzags instead of going straight to minimum\n",
    "   - Can be 100\u00d7 slower or more!\n",
    "   \n",
    "2. **Learning Rate Sensitivity:** Different features need different learning rates\n",
    "   - Small-scale features (0-1) might need \u03b1 = 0.1\n",
    "   - Large-scale features (0-10000) might need \u03b1 = 0.00001\n",
    "   - With one global \u03b1, impossible to optimize all features well\n",
    "   \n",
    "3. **Numerical Stability:** Large feature values can cause gradient explosion\n",
    "   - Gradients become huge \u2192 weights explode \u2192 overflow errors\n",
    "\n",
    "**Solution: Z-Score Standardization**\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "This transforms all features to:\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "- Similar scales \u2192 uniform convergence\n",
    "\n",
    "**Critical Rule:** Fit scaler on training data ONLY!\n",
    "```python\n",
    "scaler.fit(X_train)  # Learn \u03bc and \u03c3 from training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)    # Use same \u03bc and \u03c3\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same \u03bc and \u03c3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for Gradient Descent\n",
    "\n",
    "### Formal Pseudocode\n",
    "\n",
    "```\n",
    "============================================\n",
    "Inputs\n",
    "============================================\n",
    "X       \u2190 training features (N \u00d7 d matrix)\n",
    "y       \u2190 training targets (N \u00d7 1 vector)\n",
    "\u03b1       \u2190 learning rate (e.g., 0.01)\n",
    "max_iter \u2190 maximum iterations (e.g., 1000)\n",
    "tol     \u2190 convergence tolerance (e.g., 1e-6)\n",
    "\n",
    "============================================\n",
    "----- fit -----\n",
    "============================================\n",
    "1. Add bias column: \u03a6 \u2190 [1, X]  # (N \u00d7 (d+1))\n",
    "2. Initialize weights randomly: w \u2190 random small values\n",
    "3. For iteration = 1 to max_iter:\n",
    "     a. Compute predictions: \u0177 \u2190 \u03a6w\n",
    "     b. Compute errors: e \u2190 y - \u0177\n",
    "     c. Compute loss: L \u2190 (1/N) \u03a3 e\u00b2\n",
    "     d. Compute gradients: \u2207w \u2190 -(2/N) \u03a6\u1d40e\n",
    "     e. Update weights: w \u2190 w - \u03b1\u2207w\n",
    "     f. If |L_new - L_old| < tol: STOP (converged)\n",
    "4. Store final weights w\n",
    "\n",
    "============================================\n",
    "----- predict -----\n",
    "============================================\n",
    "For each query point in X_query:\n",
    "1. Add bias: \u03a6_query \u2190 [1, X_query]\n",
    "2. Compute prediction: \u0177 \u2190 \u03a6_query \u00b7 w\n",
    "3. Return \u0177\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "- **Iterative process:** Weights improve gradually over multiple iterations\n",
    "- **Convergence check:** Stop when loss stops decreasing significantly\n",
    "- **Prediction:** Same as Linear Regression (just matrix multiplication)\n",
    "- **Memory efficient:** Only stores weights (not all training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom Gradient Descent Class\n",
    "\n",
    "Below is a scaffold of the `MyGradientDescentRegressor` class. Fill in the TODO sections to complete the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class MyGradientDescentRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom Gradient Descent implementation for Linear Regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    learning_rate : float, default=0.01\n",
    "        Learning rate (\u03b1) for gradient descent updates\n",
    "    max_iter : int, default=1000\n",
    "        Maximum number of iterations\n",
    "    tol : float, default=1e-6\n",
    "        Tolerance for convergence (stop if loss change < tol)\n",
    "    random_state : int, default=42\n",
    "        Random seed for weight initialization\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    weights_ : array of shape (n_features + 1,)\n",
    "        Learned weights including bias term\n",
    "    loss_history_ : list\n",
    "        Loss value at each iteration\n",
    "    n_iter_ : int\n",
    "        Actual number of iterations performed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000, tol=1e-6, random_state=42):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model using gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        # TODO: Add column of ones for bias term\n",
    "        # Hint: Use np.c_[np.ones(len(X)), X] to create design matrix Phi\n",
    "        Phi = None  # Replace with your code\n",
    "        \n",
    "        # TODO: Initialize weights randomly with small values\n",
    "        # Hint: np.random.seed(self.random_state)\n",
    "        #       self.weights_ = np.random.randn(Phi.shape[1]) * 0.01\n",
    "        np.random.seed(self.random_state)\n",
    "        self.weights_ = None  # Replace with your code\n",
    "        \n",
    "        # Initialize loss history\n",
    "        self.loss_history_ = []\n",
    "        N = len(y)\n",
    "        \n",
    "        # Gradient Descent Loop\n",
    "        for iteration in range(self.max_iter):\n",
    "            # TODO: Compute predictions\n",
    "            # Hint: predictions = Phi @ self.weights_\n",
    "            predictions = None  # Replace with your code\n",
    "            \n",
    "            # TODO: Compute errors (residuals)\n",
    "            # Hint: errors = y - predictions\n",
    "            errors = None  # Replace with your code\n",
    "            \n",
    "            # TODO: Compute loss (MSE)\n",
    "            # Hint: loss = (1/N) * np.sum(errors**2)\n",
    "            loss = None  # Replace with your code\n",
    "            \n",
    "            # Store loss\n",
    "            self.loss_history_.append(loss)\n",
    "            \n",
    "            # Check convergence\n",
    "            if iteration > 0 and abs(self.loss_history_[-2] - self.loss_history_[-1]) < self.tol:\n",
    "                self.n_iter_ = iteration + 1\n",
    "                break\n",
    "            \n",
    "            # TODO: Compute gradients\n",
    "            # Hint: gradients = -(2/N) * (Phi.T @ errors)\n",
    "            gradients = None  # Replace with your code\n",
    "            \n",
    "            # TODO: Update weights\n",
    "            # Hint: self.weights_ = self.weights_ - self.learning_rate * gradients\n",
    "            # Replace this line with your code\n",
    "            pass\n",
    "        else:\n",
    "            self.n_iter_ = self.max_iter\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the learned model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : array of shape (n_samples,)\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        # TODO: Add column of ones for bias term\n",
    "        Phi = None  # Replace with your code\n",
    "        \n",
    "        # TODO: Compute predictions\n",
    "        y_pred = None  # Replace with your code\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Once you have filled in the implementation, let's test our custom gradient descent regressor on a simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple test data\n",
    "np.random.seed(42)\n",
    "X_simple = np.array([[1], [2], [3], [4], [5]])\n",
    "y_simple = np.array([2, 4, 6, 8, 10])  # Perfect linear relationship: y = 2x\n",
    "\n",
    "# Fit model\n",
    "model = MyGradientDescentRegressor(learning_rate=0.01, max_iter=1000)\n",
    "model.fit(X_simple, y_simple)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_simple)\n",
    "\n",
    "print(\"Learned weights (w0=intercept, w1=slope):\", model.weights_)\n",
    "print(\"Expected: [0, 2] or very close to it\")\n",
    "print(\"\\nPredictions:\", predictions)\n",
    "print(\"Actual:     \", y_simple)\n",
    "print(\"\\nFinal MSE:\", model.loss_history_[-1])\n",
    "print(\"Expected: very close to 0\")\n",
    "print(f\"\\nConverged in {model.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence\n",
    "\n",
    "Let's plot the loss over iterations to see how the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Gradient Descent Convergence', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial loss: {model.loss_history_[0]:.6f}\")\n",
    "print(f\"Final loss:   {model.loss_history_[-1]:.6f}\")\n",
    "print(f\"Improvement:  {(1 - model.loss_history_[-1]/model.loss_history_[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: In a well-tuned gradient descent setup, what should the loss curve look like?\n",
    ">\n",
    "> A. Steadily increasing as the model learns more complex patterns\n",
    ">\n",
    "> B. Randomly fluctuating up and down throughout training\n",
    ">\n",
    "> C. Steadily decreasing and eventually flattening as it approaches the minimum\n",
    ">\n",
    "> D. Oscillating with larger and larger amplitude as training progresses\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Loss should DECREASE during training, not increase. Increasing loss means the model is getting worse at fitting the data, which indicates a problem (e.g., learning rate too high, gradient explosion, or wrong gradient calculation). The goal of optimization is to minimize loss.\n",
    "- **B is FALSE**: Random fluctuation suggests instability in the optimization process. For batch gradient descent (using all training data), loss should decrease monotonically. Some fluctuation is normal for stochastic/mini-batch gradient descent (using subsets of data), but the overall trend should still be downward.\n",
    "- **C is TRUE**: A healthy loss curve shows: (1) Rapid decrease initially (gradient is large far from minimum), (2) Gradual slowdown (gradient becomes smaller near minimum), (3) Flattening/plateau (convergence - gradient \u2248 0 at minimum). This is the signature of successful optimization.\n",
    "- **D is FALSE**: Increasing oscillation amplitude indicates divergence, typically caused by a learning rate that's too large. The optimizer overshoots the minimum by increasing amounts, causing loss to bounce around wildly and potentially explode to infinity.\n",
    "\n",
    "**Key Insight**: Loss should decrease monotonically (batch GD) or with downward trend (mini-batch/SGD) and flatten at convergence. Any other pattern indicates a problem with hyperparameters or implementation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Dataset for Visualization\n",
    "\n",
    "Let's work with the same synthetic dataset from the Linear Regression lab to directly compare approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the same data as in Linear Regression Code Walk Through\n",
    "np.random.seed(42)\n",
    "X_train = np.arange(-9.5, 8.5, 0.1).reshape(-1, 1)\n",
    "y_train = X_train.ravel() + 1 + np.random.normal(0, 2, len(X_train))\n",
    "\n",
    "print(f\"Training data: {len(X_train)} points\")\n",
    "print(f\"X range: [{X_train.min():.1f}, {X_train.max():.1f}]\")\n",
    "print(f\"y range: [{y_train.min():.1f}, {y_train.max():.1f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Training Data: Linear Relationship with Noise', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your MyGradientDescentRegressor on the training data\n",
    "# Hint: model = MyGradientDescentRegressor(learning_rate=0.01, max_iter=100)\n",
    "#       model.fit(X_train, y_train)\n",
    "\n",
    "model = None  # Replace with your code\n",
    "\n",
    "print(f\"Learned weights: {model.weights_}\")\n",
    "print(f\"Model equation: y = {model.weights_[1]:.3f}x + {model.weights_[0]:.3f}\")\n",
    "print(f\"Converged in {model.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit\n",
    "x_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(x_line)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'GD fit: y={model.weights_[1]:.2f}x+{model.weights_[0]:.2f}')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Gradient Descent: Best Fit Line', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Training Loss Over Iterations', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial loss: {model.loss_history_[0]:.6f}\")\n",
    "print(f\"Final loss:   {model.loss_history_[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Learning Rate\n",
    "\n",
    "Let's experiment with different learning rates to see how they affect convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    model_lr = MyGradientDescentRegressor(learning_rate=lr, max_iter=100)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    \n",
    "    plt.plot(range(1, len(model_lr.loss_history_) + 1), model_lr.loss_history_,\n",
    "            linewidth=2, color=color, label=f'\u03b1 = {lr} ({model_lr.n_iter_} iter)')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=14)\n",
    "plt.ylabel('Loss (MSE)', fontsize=14)\n",
    "plt.title('Impact of Learning Rate on Convergence', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')  # Log scale to see all curves\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- \u03b1 = 0.001: Very slow convergence (needs more iterations)\")\n",
    "print(\"- \u03b1 = 0.01:  Good convergence speed\")\n",
    "print(\"- \u03b1 = 0.1:   Fast convergence\")\n",
    "print(\"- \u03b1 = 0.5:   May oscillate or diverge (too large)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You train gradient descent with \u03b1=0.001 for 100 iterations and the loss is still decreasing steadily. What should you do?\n",
    ">\n",
    "> A. Decrease the learning rate to \u03b1=0.0001 for more stable convergence\n",
    ">\n",
    "> B. Stop training immediately since 100 iterations should be sufficient for any model\n",
    ">\n",
    "> C. Increase max_iter to allow more iterations, or increase \u03b1 for faster convergence\n",
    ">\n",
    "> D. Switch to the normal equation since gradient descent isn't working properly\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The learning rate \u03b1=0.001 is already quite small. Decreasing it further to 0.0001 would make convergence even SLOWER, requiring even MORE iterations. Since loss is steadily decreasing (not oscillating), there's no stability problem - the issue is just slow convergence.\n",
    "- **B is FALSE**: There's no universal \"sufficient\" number of iterations. The required iterations depend on: learning rate, data size, feature scales, initialization, and convergence tolerance. If loss is still decreasing steadily after 100 iterations, the model hasn't converged yet and needs more training.\n",
    "- **C is TRUE**: Steadily decreasing loss means gradient descent is working correctly but needs more time. Two solutions: (1) Increase max_iter (e.g., 1000 or 10000) to allow more iterations with the current learning rate, or (2) Increase \u03b1 (e.g., to 0.01 or 0.1) to take bigger steps and converge faster. The second option is usually more efficient.\n",
    "- **D is FALSE**: \"Loss still decreasing steadily\" means gradient descent IS working properly - it just hasn't finished yet. This is not a failure case. The normal equation would give the same final result but doesn't provide insight into convergence behavior. For this small problem, either approach works.\n",
    "\n",
    "**Key Insight**: Steadily decreasing loss = working correctly but not converged. Solution: increase iterations or increase learning rate (carefully). Oscillating/increasing loss = problem with learning rate.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Different Gradient Descent Variants\n",
    "\n",
    "There are three main variants of gradient descent:\n",
    "\n",
    "### 1. Batch Gradient Descent (What We Implemented)\n",
    "- Uses **ALL training data** in each iteration\n",
    "- Computes gradient using entire dataset: \u2207w = -(2/N) \u03a6\u1d40(y - \u03a6w)\n",
    "- **Pros:** Stable, smooth convergence, exact gradient\n",
    "- **Cons:** Slow for large datasets (must process all N samples per iteration)\n",
    "\n",
    "### 2. Stochastic Gradient Descent (SGD)\n",
    "- Uses **ONE random sample** in each iteration\n",
    "- Computes gradient using single example: \u2207w \u2248 -2(y\u1d62 - \u0177\u1d62)\u03c6\u1d62\n",
    "- **Pros:** Very fast iterations, can escape local minima, online learning\n",
    "- **Cons:** Noisy updates, erratic convergence, requires learning rate decay\n",
    "\n",
    "### 3. Mini-Batch Gradient Descent (Most Popular!)\n",
    "- Uses **SMALL BATCH** (e.g., 32, 64, 128 samples) in each iteration\n",
    "- Computes gradient using batch: \u2207w \u2248 -(2/B) \u03a3\u1d62(y\u1d62 - \u0177\u1d62)\u03c6\u1d62\n",
    "- **Pros:** Balance of speed and stability, GPU-friendly, works with large data\n",
    "- **Cons:** Adds batch size as hyperparameter\n",
    "\n",
    "### Comparison:\n",
    "\n",
    "| Aspect | Batch GD | Stochastic GD | Mini-Batch GD |\n",
    "|--------|----------|---------------|---------------|\n",
    "| **Samples per iter** | All N | 1 | B (e.g., 32) |\n",
    "| **Gradient accuracy** | Exact | Noisy | Approximate |\n",
    "| **Convergence** | Smooth | Erratic | Smooth-ish |\n",
    "| **Speed per iter** | Slow | Very fast | Fast |\n",
    "| **Memory usage** | High | Low | Medium |\n",
    "| **Use case** | Small data | Online learning | Large data, deep learning |\n",
    "\n",
    "**Note:** Scikit-learn's `SGDRegressor` uses Stochastic GD, which is why our results differ slightly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You have a dataset with 10 million training examples and want to train a linear regression model. Which optimization approach is MOST practical?\n",
    ">\n",
    "> A. Normal equation (closed-form solution) for instant exact results\n",
    ">\n",
    "> B. Batch gradient descent using all 10 million samples per iteration\n",
    ">\n",
    "> C. Mini-batch gradient descent with batches of 128-256 samples\n",
    ">\n",
    "> D. Stochastic gradient descent using exactly 1 random sample per iteration\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The normal equation requires computing (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y, where \u03a6 is 10M \u00d7 d. This involves: (1) Matrix multiplication: O(Nd\u00b2) \u2248 billions of operations, (2) Matrix inversion: O(d\u00b3), (3) Storing 10M \u00d7 d matrix in memory (could be gigabytes). For N=10M, this is extremely slow and memory-intensive. Normal equation doesn't scale to large datasets.\n",
    "- **B is FALSE**: Batch GD must process all 10 million samples in EACH iteration. Even if each iteration takes 10 seconds, and you need 100 iterations, that's 1000 seconds (16 minutes) just for computation - extremely slow. Also requires loading all 10M samples into memory simultaneously.\n",
    "- **C is TRUE**: Mini-batch GD with batch size B=128 means: (1) Only 128 samples in memory at once (feasible), (2) Fast iterations (~milliseconds each), (3) Can process data in chunks from disk, (4) Parallelizes well on GPUs, (5) Gets good gradient estimates with much less computation than full batch. With B=128 and N=10M, each epoch is ~78,000 mini-batches, but each is very fast. This is the standard approach for large-scale ML.\n",
    "- **D is FALSE**: While SGD (B=1) has very fast iterations, it's TOO noisy for stable convergence. With 10M samples, you'd need many epochs for a stable gradient estimate. Mini-batch (B=128-256) provides a much better balance: more stable than SGD, much faster than batch GD.\n",
    "\n",
    "**Key Insight**: For large datasets (N > 100,000), mini-batch gradient descent is the practical choice. It balances computational efficiency, memory usage, and convergence stability. This is why deep learning uses mini-batch GD almost exclusively.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Gradient Descent is an iterative optimization algorithm**\n",
    "   - Updates weights in direction that reduces loss: w = w - \u03b1\u2207w L\n",
    "   - Converges to optimal solution through many small steps\n",
    "   - Foundation for training neural networks and deep learning\n",
    "\n",
    "2. **Learning rate (\u03b1) is critical**\n",
    "   - Too small \u2192 slow convergence (many iterations needed)\n",
    "   - Too large \u2192 divergence (loss increases or oscillates)\n",
    "   - Typical range: 0.001 to 0.1\n",
    "   - Monitor loss curve to diagnose issues\n",
    "\n",
    "3. **Feature scaling is ESSENTIAL for gradient descent**\n",
    "   - Unscaled features cause slow/unstable convergence\n",
    "   - Different features need different step sizes \u2192 impossible with one \u03b1\n",
    "   - Always use StandardScaler or MinMaxScaler\n",
    "   - Fit scaler on training data ONLY!\n",
    "\n",
    "4. **Convergence monitoring**\n",
    "   - Plot loss over iterations\n",
    "   - Healthy curve: decreasing and flattening\n",
    "   - Stop when loss change < tolerance\n",
    "   - Early stopping prevents wasted computation\n",
    "\n",
    "5. **Gradient descent vs Normal equation**\n",
    "   - Normal equation: Fast for small data, exact solution, no tuning\n",
    "   - Gradient descent: Scales to large data, works for any model, needs tuning\n",
    "   - Both converge to same solution for linear regression\n",
    "\n",
    "### When to Use Gradient Descent\n",
    "\n",
    "\u2705 **Use Gradient Descent when:**\n",
    "- Training neural networks (only option available)\n",
    "- Dataset is very large (N > 100,000)\n",
    "- Online learning (data arrives in streams)\n",
    "- Need mini-batch or stochastic variants\n",
    "- Working with distributed systems (can parallelize mini-batches)\n",
    "\n",
    "\u274c **Use Normal Equation when:**\n",
    "- Small-medium dataset (N < 10,000)\n",
    "- Few features (d < 1,000)\n",
    "- Want exact solution without tuning\n",
    "- Simple linear regression\n",
    "\n",
    "### Gradient Descent Variants Summary\n",
    "\n",
    "| Variant | Samples/Iter | Best For |\n",
    "|---------|--------------|----------|\n",
    "| **Batch GD** | All N | Small datasets, smooth convergence |\n",
    "| **Stochastic GD** | 1 | Online learning, escaping local minima |\n",
    "| **Mini-Batch GD** | 32-256 | Large datasets, deep learning (MOST COMMON) |\n",
    "\n",
    "### Best Practices Checklist\n",
    "\n",
    "- \u2705 Always standardize features using StandardScaler\n",
    "- \u2705 Fit scaler on training data only (avoid data leakage)\n",
    "- \u2705 Start with learning rate \u03b1 = 0.01, adjust based on loss curve\n",
    "- \u2705 Monitor loss over iterations to diagnose convergence\n",
    "- \u2705 Use early stopping to prevent wasted computation\n",
    "- \u2705 Initialize weights with small random values\n",
    "- \u2705 For large data, use mini-batch variant (B=32-256)\n",
    "- \u2705 Compare with closed-form solution when possible (validation)\n",
    "- \u2705 Use learning rate decay for better convergence (advanced)\n",
    "- \u2705 Visualize loss curves to understand convergence behavior\n",
    "\n",
    "### Debugging Gradient Descent\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|--------------|----------|\n",
    "| Loss increasing | \u03b1 too large | Decrease learning rate by 10\u00d7 |\n",
    "| Loss oscillating | \u03b1 too large | Decrease learning rate |\n",
    "| Very slow convergence | \u03b1 too small OR unscaled features | Increase \u03b1 or standardize features |\n",
    "| Loss stuck at high value | Poor initialization OR bad \u03b1 | Try different random seed or \u03b1 |\n",
    "| NaN/Inf values | Gradient explosion | Standardize features, decrease \u03b1 |\n",
    "| Doesn't converge after 10k iter | Unscaled features | Standardize features! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Final Question**: You're training a neural network and observe that the training loss decreases smoothly for 50 epochs, then suddenly starts increasing. What is the MOST likely explanation?\n",
    ">\n",
    "> A. The model has successfully converged and entered the optimal region\n",
    ">\n",
    "> B. The learning rate should be increased to speed up convergence\n",
    ">\n",
    "> C. The learning rate might be too high for later epochs and needs decay/reduction\n",
    ">\n",
    "> D. The features weren't properly standardized before training started\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: If the model had converged optimally, the loss would plateau (stay constant), not increase. Increasing loss means the model is moving AWAY from the optimal solution, which is the opposite of convergence. This indicates a problem with the optimization, not success.\n",
    "- **B is FALSE**: If loss is already increasing, making the learning rate LARGER will make the problem worse! The model is overshooting, so bigger steps would cause even more overshooting and potentially divergence to infinity.\n",
    "- **C is TRUE**: This is a classic pattern: initially, when weights are far from optimal, a larger learning rate (e.g., \u03b1=0.1) works well for fast progress. But as the model gets close to the minimum (after ~50 epochs), those large steps start overshooting. The loss surface becomes very narrow near the minimum, so the same learning rate that worked early now causes instability. Solution: learning rate decay/scheduling (reduce \u03b1 over time, e.g., \u03b1 = 0.1 \u2192 0.01 \u2192 0.001).\n",
    "- **D is FALSE**: If features weren't standardized, you'd see problems from the VERY FIRST epoch - extremely slow convergence, erratic behavior, or immediate divergence. The fact that loss decreased smoothly for 50 epochs proves features were scaled properly. This issue started LATER, indicating a learning rate problem specific to later training stages.\n",
    "\n",
    "**Key Insight**: Loss decreasing then increasing suggests the learning rate is too large for the current optimization stage. Use learning rate schedules/decay: start high for fast progress, reduce over time for stable convergence. This is standard practice in deep learning.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}