{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Gradient%20Descent/Gradient%20Descent%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Hands-On Lab\n",
    "\n",
    "In this lab, you will implement Gradient Descent optimization from scratch, understand the mathematics behind it, and apply it to real data. Along the way, you'll answer conceptual questions and create visualizations to deepen your understanding.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the mathematics of Gradient Descent optimization\n",
    "- Implement a custom Gradient Descent class from scratch\n",
    "- Visualize convergence and loss curves\n",
    "- Understand the impact of learning rate on convergence\n",
    "- Apply feature scaling and understand why it's critical for gradient descent\n",
    "- Compare gradient descent with closed-form solutions\n",
    "- Understand batch, stochastic, and mini-batch variants\n",
    "- Analyze model performance and convergence behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Overview of Gradient Descent\n\nGradient Descent is an **iterative optimization algorithm** used to find the minimum of a function. In machine learning, we use it to **minimize the loss function** and find optimal model parameters.\n\n**Key Idea:**\n- Start with **random weights**\n- Iteratively **update weights** in the direction that reduces loss\n- Take steps proportional to the **negative gradient** of the loss function\n- Continue until **convergence** (loss stops decreasing)\n\n**The Update Rule:**\n$$w_{\\text{new}} = w_{\\text{old}} - \\alpha \\nabla_w L$$\n\nWhere:\n- **w** are the model weights (parameters)\n- **α** is the learning rate (step size)\n- **∇w L** is the gradient of the loss with respect to weights\n- **L** is the loss function (e.g., Sum of Squared Errors)\n\n**For Linear Regression with SSE Loss:**\n- Loss: $L(w) = \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n- Gradient: $\\nabla_w L = -2 \\Phi^T (y - \\Phi w)$\n- Update: $w = w + 2\\alpha \\Phi^T (y - \\Phi w)$\n\n**Advantages:**\n- Works when no closed-form solution exists (e.g., neural networks)\n- Scales well to large datasets\n- Can be adapted to stochastic/mini-batch variants for efficiency\n- Foundation for deep learning optimization\n\n**Disadvantages:**\n- Requires tuning hyperparameters (learning rate, iterations)\n- Can be slow to converge\n- May get stuck in local minima (for non-convex functions)\n- Sensitive to feature scaling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: Gradient Descent finds optimal weights by:\n",
    ">\n",
    "> A. Computing the exact optimal solution directly using matrix inversion like the normal equation\n",
    ">\n",
    "> B. Iteratively updating weights in the direction that reduces the loss function using gradients\n",
    ">\n",
    "> C. Randomly trying different weight combinations until finding the best performing set\n",
    ">\n",
    "> D. Using K-nearest neighbors to estimate optimal weight values from training data\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: This describes the normal equation for Linear Regression: w = (ΦᵀΦ)⁻¹Φᵀy. The normal equation computes the exact optimal solution in one step, without any iteration. Gradient descent, in contrast, is an iterative method that gradually approaches the optimal solution.\n",
    "- **B is TRUE**: Gradient descent computes the gradient ∇w L (the direction of steepest ascent of the loss function) and updates weights in the opposite direction (steepest descent): w_new = w_old - α∇w L. By repeatedly taking small steps downhill, it converges to a local minimum (global for convex functions like MSE).\n",
    "- **C is FALSE**: Gradient descent is not random! It uses calculus (derivatives/gradients) to determine the exact direction to move weights. Random search would be extremely inefficient and wouldn't scale to high-dimensional problems.\n",
    "- **D is FALSE**: KNN is an instance-based learning algorithm for prediction, not an optimization method for finding weights. Gradient descent doesn't use neighbors or training data directly during the update step - it only uses gradients computed from the loss function.\n",
    "\n",
    "**Key Insight**: Gradient descent is a **deterministic, iterative, gradient-based optimization** method. It uses calculus to find the direction that most quickly reduces loss, then takes small steps in that direction.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent vs Normal Equation (Closed-Form Solution)\n",
    "\n",
    "For Linear Regression, we have **two ways** to find optimal weights:\n",
    "\n",
    "### 1. Normal Equation (Closed-Form)\n",
    "$$w = (\\Phi^T \\Phi)^{-1} \\Phi^T y$$\n",
    "\n",
    "**Pros:**\n",
    "- ✅ Exact optimal solution in one calculation\n",
    "- ✅ No hyperparameters to tune\n",
    "- ✅ No iterations needed\n",
    "\n",
    "**Cons:**\n",
    "- ❌ Requires matrix inversion: O(d³) complexity (slow for many features)\n",
    "- ❌ Doesn't scale to very large datasets (memory intensive)\n",
    "- ❌ Only works for problems with closed-form solutions\n",
    "\n",
    "### 2. Gradient Descent (Iterative)\n",
    "$$w = w - \\alpha \\nabla_w L$$\n",
    "\n",
    "**Pros:**\n",
    "- ✅ Scales well to large datasets (especially mini-batch/stochastic variants)\n",
    "- ✅ Works for any differentiable loss function\n",
    "- ✅ Foundation for neural networks and deep learning\n",
    "- ✅ Can stop early if convergence is good enough\n",
    "\n",
    "**Cons:**\n",
    "- ❌ Requires tuning learning rate and iterations\n",
    "- ❌ Slower convergence (multiple iterations)\n",
    "- ❌ Very sensitive to feature scaling\n",
    "\n",
    "### When to Use Each:\n",
    "\n",
    "| Scenario | Best Choice |\n",
    "|----------|-------------|\n",
    "| Small dataset (N < 10,000), few features (d < 1,000) | Normal Equation |\n",
    "| Large dataset (N > 100,000) | Gradient Descent (Mini-batch) |\n",
    "| Many features (d > 10,000) | Gradient Descent |\n",
    "| Neural networks, non-linear models | Gradient Descent (only option) |\n",
    "| Need exact optimal solution | Normal Equation |\n",
    "| Online learning (streaming data) | Stochastic Gradient Descent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Learning Rate: Critical Hyperparameter\n",
    "\n",
    "The **learning rate (α)** controls how big of a step we take in each iteration.\n",
    "\n",
    "### Impact of Different Learning Rates:\n",
    "\n",
    "**α too small (e.g., 0.0001):**\n",
    "- ✅ Stable convergence (doesn't overshoot)\n",
    "- ❌ Very slow (needs many iterations)\n",
    "- ❌ May get stuck in plateaus\n",
    "\n",
    "**α optimal (e.g., 0.01-0.1):**\n",
    "- ✅ Fast convergence\n",
    "- ✅ Reaches minimum efficiently\n",
    "- ✅ Smooth loss curve\n",
    "\n",
    "**α too large (e.g., 1.0+):**\n",
    "- ❌ Overshoots minimum\n",
    "- ❌ Loss oscillates or increases\n",
    "- ❌ May diverge (loss → ∞)\n",
    "\n",
    "We'll visualize these effects later in the lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You're training a model with gradient descent and observe that the loss is increasing rather than decreasing over iterations. What is the MOST likely cause?\n",
    ">\n",
    "> A. The model is underfitting because it's too simple to capture the data patterns\n",
    ">\n",
    "> B. The learning rate is too large, causing the optimizer to overshoot the minimum\n",
    ">\n",
    "> C. The features need to be standardized using z-score normalization\n",
    ">\n",
    "> D. The number of iterations is too small and convergence hasn't been reached yet\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: B**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Underfitting means the model can't fit the training data well, which would result in HIGH but STABLE loss. The loss would remain consistently high across iterations, not increase. If loss is increasing, the optimization process itself is failing, not the model capacity.\n",
    "- **B is TRUE**: When the learning rate α is too large, the weight update w_new = w_old - α∇w can overshoot the minimum. Instead of moving toward the optimal point, it jumps past it to a worse position with higher loss. In extreme cases, this causes divergence where loss → ∞. The classic symptom of too-large learning rate is loss increasing or wildly oscillating.\n",
    "- **C is FALSE**: While feature scaling IS very important for gradient descent (unstandardized features cause slow/unstable convergence), it typically causes SLOW convergence or oscillation, not monotonically increasing loss. Unscaled features make the loss surface elongated, requiring careful learning rate tuning, but don't inherently cause divergence.\n",
    "- **D is FALSE**: Too few iterations would mean you haven't reached the minimum yet, so loss would still be HIGH but DECREASING. If loss is increasing, stopping earlier wouldn't help - the problem is the update direction or step size is wrong.\n",
    "\n",
    "**Key Insight**: Increasing loss during training almost always indicates α is too large. Solution: reduce learning rate by 10× (e.g., 0.1 → 0.01).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: Critical for Gradient Descent!\n",
    "\n",
    "While feature scaling is recommended for Linear Regression's normal equation, it's **ESSENTIAL** for gradient descent.\n",
    "\n",
    "**Why is scaling so important for gradient descent?**\n",
    "\n",
    "1. **Convergence Speed:** Unscaled features create elongated loss surfaces\n",
    "   - Gradient descent zigzags instead of going straight to minimum\n",
    "   - Can be 100× slower or more!\n",
    "   \n",
    "2. **Learning Rate Sensitivity:** Different features need different learning rates\n",
    "   - Small-scale features (0-1) might need α = 0.1\n",
    "   - Large-scale features (0-10000) might need α = 0.00001\n",
    "   - With one global α, impossible to optimize all features well\n",
    "   \n",
    "3. **Numerical Stability:** Large feature values can cause gradient explosion\n",
    "   - Gradients become huge → weights explode → overflow errors\n",
    "\n",
    "**Solution: Z-Score Standardization**\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "This transforms all features to:\n",
    "- Mean = 0\n",
    "- Standard deviation = 1\n",
    "- Similar scales → uniform convergence\n",
    "\n",
    "**Critical Rule:** Fit scaler on training data ONLY!\n",
    "```python\n",
    "scaler.fit(X_train)  # Learn μ and σ from training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)    # Use same μ and σ\n",
    "X_test_scaled = scaler.transform(X_test)  # Use same μ and σ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pseudocode for Gradient Descent\n\n### Formal Pseudocode\n\n```\n============================================\nInputs\n============================================\nX       ← training features (N × d matrix)\ny       ← training targets (N × 1 vector)\nα       ← learning rate (e.g., 0.01)\nmax_iter ← maximum iterations (e.g., 1000)\ntol     ← convergence tolerance (e.g., 1e-6)\n\n============================================\n----- fit -----\n============================================\n1. Add bias column: Φ ← [1, X]  # (N × (d+1))\n2. Initialize weights randomly: w ← random small values\n3. For iteration = 1 to max_iter:\n     a. Compute predictions: ŷ ← Φw\n     b. Compute errors: e ← y - ŷ\n     c. Compute loss: L ← Σ e²\n     d. Compute gradients: ∇w ← -2Φᵀe\n     e. Update weights: w ← w - α∇w\n     f. If |L_new - L_old| < tol: STOP (converged)\n4. Store final weights w\n\n============================================\n----- predict -----\n============================================\nFor each query point in X_query:\n1. Add bias: Φ_query ← [1, X_query]\n2. Compute prediction: ŷ ← Φ_query · w\n3. Return ŷ\n```\n\n### Key Observations\n- **Iterative process:** Weights improve gradually over multiple iterations\n- **Convergence check:** Stop when loss stops decreasing significantly\n- **Prediction:** Same as Linear Regression (just matrix multiplication)\n- **Memory efficient:** Only stores weights (not all training data)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom Gradient Descent Class\n",
    "\n",
    "Below is a scaffold of the `MyGradientDescentRegressor` class. Fill in the TODO sections to complete the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nfrom sklearn.base import BaseEstimator, RegressorMixin\n\nclass MyGradientDescentRegressor(BaseEstimator, RegressorMixin):\n    \"\"\"\n    Custom Gradient Descent implementation for Linear Regression.\n    \n    Parameters:\n    -----------\n    learning_rate : float, default=0.01\n        Learning rate (α) for gradient descent updates\n    max_iter : int, default=1000\n        Maximum number of iterations\n    tol : float, default=1e-6\n        Tolerance for convergence (stop if loss change < tol)\n    random_state : int, default=42\n        Random seed for weight initialization\n    \n    Attributes:\n    -----------\n    weights_ : array of shape (n_features + 1,)\n        Learned weights including bias term\n    loss_history_ : list\n        Loss value at each iteration\n    n_iter_ : int\n        Actual number of iterations performed\n    \"\"\"\n    \n    def __init__(self, learning_rate=0.01, max_iter=1000, tol=1e-6, random_state=42):\n        self.learning_rate = learning_rate\n        self.max_iter = max_iter\n        self.tol = tol\n        self.random_state = random_state\n    \n    def fit(self, X, y):\n        \"\"\"\n        Fit the model using gradient descent.\n        \n        Parameters:\n        -----------\n        X : array-like of shape (n_samples, n_features)\n            Training data\n        y : array-like of shape (n_samples,)\n            Target values\n        \n        Returns:\n        --------\n        self\n        \"\"\"\n        # TODO: Add column of ones for bias term\n        # Hint: Use np.c_[np.ones(len(X)), X] to create design matrix Phi\n        Phi = None  # Replace with your code\n        \n        # TODO: Initialize weights randomly with small values\n        # Hint: np.random.seed(self.random_state)\n        #       self.weights_ = np.random.randn(Phi.shape[1]) * 0.01\n        np.random.seed(self.random_state)\n        self.weights_ = None  # Replace with your code\n        \n        # Initialize loss history\n        self.loss_history_ = []\n        \n        # Gradient Descent Loop\n        for iteration in range(self.max_iter):\n            # TODO: Compute predictions\n            # Hint: predictions = Phi @ self.weights_\n            predictions = None  # Replace with your code\n            \n            # TODO: Compute errors (residuals)\n            # Hint: errors = y - predictions\n            errors = None  # Replace with your code\n            \n            # TODO: Compute loss (SSE)\n            # Hint: loss = np.sum(errors**2)\n            loss = None  # Replace with your code\n            \n            # Store loss\n            self.loss_history_.append(loss)\n            \n            # Check convergence\n            if iteration > 0 and abs(self.loss_history_[-2] - self.loss_history_[-1]) < self.tol:\n                self.n_iter_ = iteration + 1\n                break\n            \n            # TODO: Compute gradients\n            # Hint: gradients = -2 * (Phi.T @ errors)\n            gradients = None  # Replace with your code\n            \n            # TODO: Update weights\n            # Hint: self.weights_ = self.weights_ - self.learning_rate * gradients\n            # Replace this line with your code\n            pass\n        else:\n            self.n_iter_ = self.max_iter\n        \n        return self\n    \n    def predict(self, X):\n        \"\"\"\n        Predict using the learned model.\n        \n        Parameters:\n        -----------\n        X : array-like of shape (n_samples, n_features)\n            Samples to predict\n        \n        Returns:\n        --------\n        y_pred : array of shape (n_samples,)\n            Predicted values\n        \"\"\"\n        # TODO: Add column of ones for bias term\n        Phi = None  # Replace with your code\n        \n        # TODO: Compute predictions\n        y_pred = None  # Replace with your code\n        \n        return y_pred"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Once you have filled in the implementation, let's test our custom gradient descent regressor on a simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create simple test data\nnp.random.seed(42)\nX_simple = np.array([[1], [2], [3], [4], [5]])\ny_simple = np.array([2, 4, 6, 8, 10])  # Perfect linear relationship: y = 2x\n\n# Fit model\nmodel = MyGradientDescentRegressor(learning_rate=0.01, max_iter=1000)\nmodel.fit(X_simple, y_simple)\n\n# Make predictions\npredictions = model.predict(X_simple)\n\nprint(\"Learned weights (w0=intercept, w1=slope):\", model.weights_)\nprint(\"Expected: [0, 2] or very close to it\")\nprint(\"\\nPredictions:\", predictions)\nprint(\"Actual:     \", y_simple)\nprint(\"\\nFinal SSE:\", model.loss_history_[-1])\nprint(\"Expected: very close to 0\")\nprint(f\"\\nConverged in {model.n_iter_} iterations\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence\n",
    "\n",
    "Let's plot the loss over iterations to see how the model learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\nplt.xlabel('Iteration', fontsize=14)\nplt.ylabel('Loss (SSE)', fontsize=14)\nplt.title('Gradient Descent Convergence', fontsize=16)\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"Initial loss: {model.loss_history_[0]:.6f}\")\nprint(f\"Final loss:   {model.loss_history_[-1]:.6f}\")\nprint(f\"Improvement:  {(1 - model.loss_history_[-1]/model.loss_history_[0])*100:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: In a well-tuned gradient descent setup, what should the loss curve look like?\n",
    ">\n",
    "> A. Steadily increasing as the model learns more complex patterns\n",
    ">\n",
    "> B. Randomly fluctuating up and down throughout training\n",
    ">\n",
    "> C. Steadily decreasing and eventually flattening as it approaches the minimum\n",
    ">\n",
    "> D. Oscillating with larger and larger amplitude as training progresses\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: Loss should DECREASE during training, not increase. Increasing loss means the model is getting worse at fitting the data, which indicates a problem (e.g., learning rate too high, gradient explosion, or wrong gradient calculation). The goal of optimization is to minimize loss.\n",
    "- **B is FALSE**: Random fluctuation suggests instability in the optimization process. For batch gradient descent (using all training data), loss should decrease monotonically. Some fluctuation is normal for stochastic/mini-batch gradient descent (using subsets of data), but the overall trend should still be downward.\n",
    "- **C is TRUE**: A healthy loss curve shows: (1) Rapid decrease initially (gradient is large far from minimum), (2) Gradual slowdown (gradient becomes smaller near minimum), (3) Flattening/plateau (convergence - gradient ≈ 0 at minimum). This is the signature of successful optimization.\n",
    "- **D is FALSE**: Increasing oscillation amplitude indicates divergence, typically caused by a learning rate that's too large. The optimizer overshoots the minimum by increasing amounts, causing loss to bounce around wildly and potentially explode to infinity.\n",
    "\n",
    "**Key Insight**: Loss should decrease monotonically (batch GD) or with downward trend (mini-batch/SGD) and flatten at convergence. Any other pattern indicates a problem with hyperparameters or implementation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Dataset for Visualization\n",
    "\n",
    "Let's work with the same synthetic dataset from the Linear Regression lab to directly compare approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the same data as in Linear Regression Code Walk Through\n",
    "np.random.seed(42)\n",
    "X_train = np.arange(-9.5, 8.5, 0.1).reshape(-1, 1)\n",
    "y_train = X_train.ravel() + 1 + np.random.normal(0, 2, len(X_train))\n",
    "\n",
    "print(f\"Training data: {len(X_train)} points\")\n",
    "print(f\"X range: [{X_train.min():.1f}, {X_train.max():.1f}]\")\n",
    "print(f\"y range: [{y_train.min():.1f}, {y_train.max():.1f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Training Data: Linear Relationship with Noise', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your MyGradientDescentRegressor on the training data\n",
    "# Hint: model = MyGradientDescentRegressor(learning_rate=0.01, max_iter=100)\n",
    "#       model.fit(X_train, y_train)\n",
    "\n",
    "model = None  # Replace with your code\n",
    "\n",
    "print(f\"Learned weights: {model.weights_}\")\n",
    "print(f\"Model equation: y = {model.weights_[1]:.3f}x + {model.weights_[0]:.3f}\")\n",
    "print(f\"Converged in {model.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit\n",
    "x_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(x_line)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'GD fit: y={model.weights_[1]:.2f}x+{model.weights_[0]:.2f}')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Gradient Descent: Best Fit Line', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Convergence Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot loss curve\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(model.loss_history_) + 1), model.loss_history_, 'b-', linewidth=2)\nplt.xlabel('Iteration', fontsize=14)\nplt.ylabel('Loss (SSE)', fontsize=14)\nplt.title('Training Loss Over Iterations', fontsize=16)\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"Initial loss: {model.loss_history_[0]:.6f}\")\nprint(f\"Final loss:   {model.loss_history_[-1]:.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Learning Rate\n",
    "\n",
    "Let's experiment with different learning rates to see how they affect convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Try different learning rates\nlearning_rates = [0.001, 0.01, 0.1, 0.5]\ncolors = ['blue', 'green', 'red', 'orange']\n\nplt.figure(figsize=(12, 6))\n\nfor lr, color in zip(learning_rates, colors):\n    model_lr = MyGradientDescentRegressor(learning_rate=lr, max_iter=100)\n    model_lr.fit(X_train, y_train)\n    \n    plt.plot(range(1, len(model_lr.loss_history_) + 1), model_lr.loss_history_,\n            linewidth=2, color=color, label=f'α = {lr} ({model_lr.n_iter_} iter)')\n\nplt.xlabel('Iteration', fontsize=14)\nplt.ylabel('Loss (SSE)', fontsize=14)\nplt.title('Impact of Learning Rate on Convergence', fontsize=16)\nplt.legend(fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.yscale('log')  # Log scale to see all curves\nplt.show()\n\nprint(\"Observations:\")\nprint(\"- α = 0.001: Very slow convergence (needs more iterations)\")\nprint(\"- α = 0.01:  Good convergence speed\")\nprint(\"- α = 0.1:   Fast convergence\")\nprint(\"- α = 0.5:   May oscillate or diverge (too large)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You train gradient descent with α=0.001 for 100 iterations and the loss is still decreasing steadily. What should you do?\n",
    ">\n",
    "> A. Decrease the learning rate to α=0.0001 for more stable convergence\n",
    ">\n",
    "> B. Stop training immediately since 100 iterations should be sufficient for any model\n",
    ">\n",
    "> C. Increase max_iter to allow more iterations, or increase α for faster convergence\n",
    ">\n",
    "> D. Switch to the normal equation since gradient descent isn't working properly\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The learning rate α=0.001 is already quite small. Decreasing it further to 0.0001 would make convergence even SLOWER, requiring even MORE iterations. Since loss is steadily decreasing (not oscillating), there's no stability problem - the issue is just slow convergence.\n",
    "- **B is FALSE**: There's no universal \"sufficient\" number of iterations. The required iterations depend on: learning rate, data size, feature scales, initialization, and convergence tolerance. If loss is still decreasing steadily after 100 iterations, the model hasn't converged yet and needs more training.\n",
    "- **C is TRUE**: Steadily decreasing loss means gradient descent is working correctly but needs more time. Two solutions: (1) Increase max_iter (e.g., 1000 or 10000) to allow more iterations with the current learning rate, or (2) Increase α (e.g., to 0.01 or 0.1) to take bigger steps and converge faster. The second option is usually more efficient.\n",
    "- **D is FALSE**: \"Loss still decreasing steadily\" means gradient descent IS working properly - it just hasn't finished yet. This is not a failure case. The normal equation would give the same final result but doesn't provide insight into convergence behavior. For this small problem, either approach works.\n",
    "\n",
    "**Key Insight**: Steadily decreasing loss = working correctly but not converged. Solution: increase iterations or increase learning rate (carefully). Oscillating/increasing loss = problem with learning rate.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a Real Dataset: California Housing\n",
    "\n",
    "Now let's apply Gradient Descent to a real-world dataset and see how critical feature scaling is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=housing.feature_names)\n",
    "df['MedHouseVal'] = y\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the **huge differences in feature scales:**\n",
    "- MedInc: 0.5 to 15\n",
    "- Population: 3 to 35,000+\n",
    "- Latitude/Longitude: 32 to 42\n",
    "\n",
    "This will cause **major problems** for gradient descent without scaling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Split into Train (60%), Validation (20%), Test (20%)\n",
    "# Hint: First split into Train (60%) and Temp (40%)\n",
    "#       Then split Temp into equal halves for Validation and Test\n",
    "#       Use random_state=42 for reproducibility\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = None, None, None, None  # Replace with your code\n",
    "X_val, X_test, y_val, y_test = None, None, None, None  # Replace with your code\n",
    "\n",
    "print(f\"Training set:   {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set:       {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Gradient Descent WITHOUT Feature Scaling (FAILS!)\n",
    "\n",
    "Let's see what happens when we try to use gradient descent on unscaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Try gradient descent on UNSCALED features\nprint(\"Attempting gradient descent on UNSCALED features...\")\nprint(\"This will likely fail or converge very slowly!\\n\")\n\nmodel_unscaled = MyGradientDescentRegressor(learning_rate=0.01, max_iter=1000)\n\ntry:\n    model_unscaled.fit(X_train, y_train)\n    print(f\"Converged in {model_unscaled.n_iter_} iterations\")\n    print(f\"Final loss: {model_unscaled.loss_history_[-1]:.6f}\")\n    \n    # Plot loss\n    plt.figure(figsize=(10, 6))\n    plt.plot(model_unscaled.loss_history_)\n    plt.xlabel('Iteration', fontsize=14)\n    plt.ylabel('Loss (SSE)', fontsize=14)\n    plt.title('Gradient Descent on UNSCALED Features (Poor Convergence!)', fontsize=16)\n    plt.grid(True, alpha=0.3)\n    plt.show()\n    \n    if model_unscaled.loss_history_[0] < model_unscaled.loss_history_[-1]:\n        print(\"\\n⚠️ WARNING: Loss INCREASED! Gradient descent diverged!\")\n        print(\"This is because unscaled features create unstable gradients.\")\n    elif model_unscaled.n_iter_ == model_unscaled.max_iter:\n        print(\"\\n⚠️ WARNING: Reached max iterations without converging!\")\n        print(\"Unscaled features cause very slow convergence.\")\n        \nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"\\nGradient descent failed due to numerical instability!\")\n    print(\"This demonstrates why feature scaling is ESSENTIAL.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: The Solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Create and fit StandardScaler on training data ONLY\n",
    "# TODO: Transform train and validation sets\n",
    "# Hint: scaler = StandardScaler()\n",
    "#       scaler.fit(X_train)\n",
    "#       X_train_scaled = scaler.transform(X_train)\n",
    "#       X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "scaler = None  # Replace with your code\n",
    "X_train_scaled = None  # Replace with your code\n",
    "X_val_scaled = None  # Replace with your code\n",
    "\n",
    "print(\"Scaled training data statistics:\")\n",
    "print(f\"  Mean: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"  Std:  {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent WITH Feature Scaling (SUCCESS!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit MyGradientDescentRegressor on scaled training data\n",
    "# TODO: Predict on scaled validation set\n",
    "# TODO: Compute RMSE and R² scores\n",
    "\n",
    "model_scaled = None  # Replace with your code\n",
    "y_val_pred_scaled = None  # Replace with your code\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rmse_scaled = None  # Replace with your code (np.sqrt(mean_squared_error(...)))\n",
    "r2_scaled = None  # Replace with your code\n",
    "\n",
    "print(\"Performance on SCALED features:\")\n",
    "print(f\"  Validation RMSE: {rmse_scaled:.4f}\")\n",
    "print(f\"  Validation R²:   {r2_scaled:.4f}\")\n",
    "print(f\"  Converged in {model_scaled.n_iter_} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize convergence with scaling\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(model_scaled.loss_history_) + 1), model_scaled.loss_history_, 'g-', linewidth=2)\nplt.xlabel('Iteration', fontsize=14)\nplt.ylabel('Loss (SSE)', fontsize=14)\nplt.title('Gradient Descent on SCALED Features (Fast Convergence!)', fontsize=16)\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"Initial loss: {model_scaled.loss_history_[0]:.6f}\")\nprint(f\"Final loss:   {model_scaled.loss_history_[-1]:.6f}\")\nprint(f\"\\nFeature scaling enables fast, stable convergence!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Scikit-Learn's SGDRegressor\n",
    "\n",
    "Scikit-learn provides `SGDRegressor`, which uses gradient descent optimization. Let's compare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Fit sklearn model (uses stochastic gradient descent)\n",
    "sklearn_model = SGDRegressor(max_iter=1000, learning_rate='constant', eta0=0.01, random_state=42)\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_val_pred_sklearn = sklearn_model.predict(X_val_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_val, y_val_pred_sklearn))\n",
    "r2_sklearn = r2_score(y_val, y_val_pred_sklearn)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Custom Implementation vs Scikit-Learn\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Custom MyGradientDescent - RMSE: {rmse_scaled:.4f} | R²: {r2_scaled:.4f}\")\n",
    "print(f\"Sklearn SGDRegressor     - RMSE: {rmse_sklearn:.4f} | R²: {r2_sklearn:.4f}\")\n",
    "print(f\"\\nDifference in RMSE: {abs(rmse_scaled - rmse_sklearn):.6f}\")\n",
    "print(f\"Difference in R²:   {abs(r2_scaled - r2_sklearn):.6f}\")\n",
    "print(\"\\n✓ Results should be similar (our implementation uses batch GD, sklearn uses SGD)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Closed-Form Solution (Normal Equation)\n",
    "\n",
    "Let's verify that gradient descent converges to the same solution as the normal equation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit model using normal equation (closed-form solution)\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_val_pred_lr = lr_model.predict(X_val_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_val, y_val_pred_lr))\n",
    "r2_lr = r2_score(y_val, y_val_pred_lr)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: Gradient Descent vs Normal Equation\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Gradient Descent (iterative) - RMSE: {rmse_scaled:.4f} | R²: {r2_scaled:.4f}\")\n",
    "print(f\"Normal Equation (closed-form) - RMSE: {rmse_lr:.4f} | R²: {r2_lr:.4f}\")\n",
    "print(f\"\\nDifference in RMSE: {abs(rmse_scaled - rmse_lr):.6f}\")\n",
    "print(f\"Difference in R²:   {abs(r2_scaled - r2_lr):.6f}\")\n",
    "print(\"\\n✓ Both methods should converge to very similar solutions!\")\n",
    "print(\"\\nNormal equation: Instant, exact solution\")\n",
    "print(f\"Gradient descent: {model_scaled.n_iter_} iterations, approximate solution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: After standardizing features and running gradient descent for 1000 iterations, you find that your validation RMSE is 0.7342 while the normal equation achieves 0.7338. What does this indicate?\n",
    ">\n",
    "> A. Gradient descent has failed - you should always use the normal equation instead\n",
    ">\n",
    "> B. The features weren't properly standardized, causing numerical instability\n",
    ">\n",
    "> C. This is normal - gradient descent converged to essentially the same solution as the normal equation\n",
    ">\n",
    "> D. The learning rate was too high, causing the model to overshoot the optimal solution\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: A difference of 0.0004 (0.7342 vs 0.7338) is negligible - less than 0.06% difference! This tiny gap is completely normal and can come from: (1) Gradient descent stopping slightly before perfect convergence (based on tolerance), (2) Numerical precision differences in matrix operations, (3) Random weight initialization. This is NOT a failure - it's essentially the same solution.\n",
    "- **B is FALSE**: If features weren't properly standardized, gradient descent would either: (1) Diverge (loss increases), (2) Converge extremely slowly (needs 100,000+ iterations), or (3) Get stuck with very high loss. Here, GD achieved RMSE=0.7342, which is nearly identical to the optimal 0.7338, proving features were scaled correctly.\n",
    "- **C is TRUE**: For convex problems like linear regression with MSE loss, gradient descent is guaranteed to converge to the global minimum (same as normal equation). The 0.0004 difference is just numerical precision - both methods found essentially the same weights. This demonstrates that gradient descent works correctly when properly tuned.\n",
    "- **D is FALSE**: If learning rate were too high, we'd see: (1) Loss oscillating wildly, (2) Much worse RMSE (e.g., 2.0 or 5.0), or (3) Divergence to infinity. The fact that GD matched the normal equation's performance (0.7342 vs 0.7338) proves the learning rate was well-tuned.\n",
    "\n",
    "**Key Insight**: For convex problems, gradient descent and normal equation converge to the same solution. Small differences (< 0.1%) are normal and acceptable.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Predictions vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred_scaled, alpha=0.5, edgecolors='black', linewidths=0.5)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', linewidth=2, label='Perfect predictions')\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.title(f'Gradient Descent: Predictions vs Actual (R² = {r2_scaled:.3f})', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Points close to the red line indicate accurate predictions.\")\n",
    "print(\"Scatter away from the line shows prediction errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transform test set using the SAME scaler fitted on training data\n",
    "# TODO: Predict on test set\n",
    "# TODO: Compute final RMSE and R² scores\n",
    "\n",
    "X_test_scaled = None  # Replace with your code\n",
    "y_test_pred = None  # Replace with your code\n",
    "test_rmse = None  # Replace with your code\n",
    "test_r2 = None  # Replace with your code\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R²:   {test_r2:.4f}\")\n",
    "print(f\"\\nInterpretation: Our gradient descent model's predictions are on average\")\n",
    "print(f\"{test_rmse:.2f} × $100,000 = ${test_rmse*100000:.0f} away from actual house values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Understanding Different Gradient Descent Variants\n\nThere are three main variants of gradient descent:\n\n### 1. Batch Gradient Descent (What We Implemented)\n- Uses **ALL training data** in each iteration\n- Computes gradient using entire dataset: ∇w = -2Φᵀ(y - Φw)\n- **Pros:** Stable, smooth convergence, exact gradient\n- **Cons:** Slow for large datasets (must process all N samples per iteration)\n\n### 2. Stochastic Gradient Descent (SGD)\n- Uses **ONE random sample** in each iteration\n- Computes gradient using single example: ∇w ≈ -2(yᵢ - ŷᵢ)φᵢ\n- **Pros:** Very fast iterations, can escape local minima, online learning\n- **Cons:** Noisy updates, erratic convergence, requires learning rate decay\n\n### 3. Mini-Batch Gradient Descent (Most Popular!)\n- Uses **SMALL BATCH** (e.g., 32, 64, 128 samples) in each iteration\n- Computes gradient using batch: ∇w ≈ -2Σᵢ(yᵢ - ŷᵢ)φᵢ\n- **Pros:** Balance of speed and stability, GPU-friendly, works with large data\n- **Cons:** Adds batch size as hyperparameter\n\n### Comparison:\n\n| Aspect | Batch GD | Stochastic GD | Mini-Batch GD |\n|--------|----------|---------------|---------------|\n| **Samples per iter** | All N | 1 | B (e.g., 32) |\n| **Gradient accuracy** | Exact | Noisy | Approximate |\n| **Convergence** | Smooth | Erratic | Smooth-ish |\n| **Speed per iter** | Slow | Very fast | Fast |\n| **Memory usage** | High | Low | Medium |\n| **Use case** | Small data | Online learning | Large data, deep learning |\n\n**Note:** Scikit-learn's `SGDRegressor` uses Stochastic GD, which is why our results differ slightly!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You have a dataset with 10 million training examples and want to train a linear regression model. Which optimization approach is MOST practical?\n",
    ">\n",
    "> A. Normal equation (closed-form solution) for instant exact results\n",
    ">\n",
    "> B. Batch gradient descent using all 10 million samples per iteration\n",
    ">\n",
    "> C. Mini-batch gradient descent with batches of 128-256 samples\n",
    ">\n",
    "> D. Stochastic gradient descent using exactly 1 random sample per iteration\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: The normal equation requires computing (ΦᵀΦ)⁻¹Φᵀy, where Φ is 10M × d. This involves: (1) Matrix multiplication: O(Nd²) ≈ billions of operations, (2) Matrix inversion: O(d³), (3) Storing 10M × d matrix in memory (could be gigabytes). For N=10M, this is extremely slow and memory-intensive. Normal equation doesn't scale to large datasets.\n",
    "- **B is FALSE**: Batch GD must process all 10 million samples in EACH iteration. Even if each iteration takes 10 seconds, and you need 100 iterations, that's 1000 seconds (16 minutes) just for computation - extremely slow. Also requires loading all 10M samples into memory simultaneously.\n",
    "- **C is TRUE**: Mini-batch GD with batch size B=128 means: (1) Only 128 samples in memory at once (feasible), (2) Fast iterations (~milliseconds each), (3) Can process data in chunks from disk, (4) Parallelizes well on GPUs, (5) Gets good gradient estimates with much less computation than full batch. With B=128 and N=10M, each epoch is ~78,000 mini-batches, but each is very fast. This is the standard approach for large-scale ML.\n",
    "- **D is FALSE**: While SGD (B=1) has very fast iterations, it's TOO noisy for stable convergence. With 10M samples, you'd need many epochs for a stable gradient estimate. Mini-batch (B=128-256) provides a much better balance: more stable than SGD, much faster than batch GD.\n",
    "\n",
    "**Key Insight**: For large datasets (N > 100,000), mini-batch gradient descent is the practical choice. It balances computational efficiency, memory usage, and convergence stability. This is why deep learning uses mini-batch GD almost exclusively.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Gradient Descent is an iterative optimization algorithm**\n",
    "   - Updates weights in direction that reduces loss: w = w - α∇w L\n",
    "   - Converges to optimal solution through many small steps\n",
    "   - Foundation for training neural networks and deep learning\n",
    "\n",
    "2. **Learning rate (α) is critical**\n",
    "   - Too small → slow convergence (many iterations needed)\n",
    "   - Too large → divergence (loss increases or oscillates)\n",
    "   - Typical range: 0.001 to 0.1\n",
    "   - Monitor loss curve to diagnose issues\n",
    "\n",
    "3. **Feature scaling is ESSENTIAL for gradient descent**\n",
    "   - Unscaled features cause slow/unstable convergence\n",
    "   - Different features need different step sizes → impossible with one α\n",
    "   - Always use StandardScaler or MinMaxScaler\n",
    "   - Fit scaler on training data ONLY!\n",
    "\n",
    "4. **Convergence monitoring**\n",
    "   - Plot loss over iterations\n",
    "   - Healthy curve: decreasing and flattening\n",
    "   - Stop when loss change < tolerance\n",
    "   - Early stopping prevents wasted computation\n",
    "\n",
    "5. **Gradient descent vs Normal equation**\n",
    "   - Normal equation: Fast for small data, exact solution, no tuning\n",
    "   - Gradient descent: Scales to large data, works for any model, needs tuning\n",
    "   - Both converge to same solution for linear regression\n",
    "\n",
    "### When to Use Gradient Descent\n",
    "\n",
    "✅ **Use Gradient Descent when:**\n",
    "- Training neural networks (only option available)\n",
    "- Dataset is very large (N > 100,000)\n",
    "- Online learning (data arrives in streams)\n",
    "- Need mini-batch or stochastic variants\n",
    "- Working with distributed systems (can parallelize mini-batches)\n",
    "\n",
    "❌ **Use Normal Equation when:**\n",
    "- Small-medium dataset (N < 10,000)\n",
    "- Few features (d < 1,000)\n",
    "- Want exact solution without tuning\n",
    "- Simple linear regression\n",
    "\n",
    "### Gradient Descent Variants Summary\n",
    "\n",
    "| Variant | Samples/Iter | Best For |\n",
    "|---------|--------------|----------|\n",
    "| **Batch GD** | All N | Small datasets, smooth convergence |\n",
    "| **Stochastic GD** | 1 | Online learning, escaping local minima |\n",
    "| **Mini-Batch GD** | 32-256 | Large datasets, deep learning (MOST COMMON) |\n",
    "\n",
    "### Best Practices Checklist\n",
    "\n",
    "- ✅ Always standardize features using StandardScaler\n",
    "- ✅ Fit scaler on training data only (avoid data leakage)\n",
    "- ✅ Start with learning rate α = 0.01, adjust based on loss curve\n",
    "- ✅ Monitor loss over iterations to diagnose convergence\n",
    "- ✅ Use early stopping to prevent wasted computation\n",
    "- ✅ Initialize weights with small random values\n",
    "- ✅ For large data, use mini-batch variant (B=32-256)\n",
    "- ✅ Compare with closed-form solution when possible (validation)\n",
    "- ✅ Use learning rate decay for better convergence (advanced)\n",
    "- ✅ Visualize loss curves to understand convergence behavior\n",
    "\n",
    "### Debugging Gradient Descent\n",
    "\n",
    "| Problem | Likely Cause | Solution |\n",
    "|---------|--------------|----------|\n",
    "| Loss increasing | α too large | Decrease learning rate by 10× |\n",
    "| Loss oscillating | α too large | Decrease learning rate |\n",
    "| Very slow convergence | α too small OR unscaled features | Increase α or standardize features |\n",
    "| Loss stuck at high value | Poor initialization OR bad α | Try different random seed or α |\n",
    "| NaN/Inf values | Gradient explosion | Standardize features, decrease α |\n",
    "| Doesn't converge after 10k iter | Unscaled features | Standardize features! |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Final Question**: You're training a neural network and observe that the training loss decreases smoothly for 50 epochs, then suddenly starts increasing. What is the MOST likely explanation?\n",
    ">\n",
    "> A. The model has successfully converged and entered the optimal region\n",
    ">\n",
    "> B. The learning rate should be increased to speed up convergence\n",
    ">\n",
    "> C. The learning rate might be too high for later epochs and needs decay/reduction\n",
    ">\n",
    "> D. The features weren't properly standardized before training started\n",
    "\n",
    "<details><summary>Click to reveal answer</summary>\n",
    "\n",
    "**Correct Answer: C**\n",
    "\n",
    "**Explanation:**\n",
    "- **A is FALSE**: If the model had converged optimally, the loss would plateau (stay constant), not increase. Increasing loss means the model is moving AWAY from the optimal solution, which is the opposite of convergence. This indicates a problem with the optimization, not success.\n",
    "- **B is FALSE**: If loss is already increasing, making the learning rate LARGER will make the problem worse! The model is overshooting, so bigger steps would cause even more overshooting and potentially divergence to infinity.\n",
    "- **C is TRUE**: This is a classic pattern: initially, when weights are far from optimal, a larger learning rate (e.g., α=0.1) works well for fast progress. But as the model gets close to the minimum (after ~50 epochs), those large steps start overshooting. The loss surface becomes very narrow near the minimum, so the same learning rate that worked early now causes instability. Solution: learning rate decay/scheduling (reduce α over time, e.g., α = 0.1 → 0.01 → 0.001).\n",
    "- **D is FALSE**: If features weren't standardized, you'd see problems from the VERY FIRST epoch - extremely slow convergence, erratic behavior, or immediate divergence. The fact that loss decreased smoothly for 50 epochs proves features were scaled properly. This issue started LATER, indicating a learning rate problem specific to later training stages.\n",
    "\n",
    "**Key Insight**: Loss decreasing then increasing suggests the learning rate is too large for the current optimization stage. Use learning rate schedules/decay: start high for fast progress, reduce over time for stable convergence. This is standard practice in deep learning.\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}