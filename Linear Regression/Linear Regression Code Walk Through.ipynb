{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Linear%20Regression/Linear%20Regression%20Code%20Walk%20Through.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Code Walk Through\n",
    "\n",
    "This notebook walks through the **computational steps** of the Linear Regression algorithm from scratch.\n",
    "\n",
    "## What We'll Cover:\n",
    "1. **Visualize the data** - understand the dataset\n",
    "2. **Add bias term** - transform data to include intercept\n",
    "3. **Find best fit line** - compute optimal weights using closed-form solution\n",
    "4. **Make predictions** - use learned weights to predict new values\n",
    "\n",
    "We'll show **both manual calculation** (to understand the logic) and **vectorized matrix operations** (for efficiency).\n",
    "\n",
    "### Key Concept:\n",
    "- Linear regression finds the **best fit line** through the data\n",
    "- Uses **closed-form solution** (no iterative training needed!)\n",
    "- Formula: **y = w₁x + w₀** where w₀ is intercept and w₁ is slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "We need:\n",
    "- **NumPy** for numerical operations and matrix calculations\n",
    "- **Matplotlib** for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Training Data\n",
    "\n",
    "We have:\n",
    "- **10 training points** with **1 feature** each (simple 1D linear regression)\n",
    "- **Continuous target values** that roughly follow a linear trend\n",
    "- Our goal: find the line that best fits this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data: 10 points with 1 feature each\n",
    "X_train = np.array([[1.0],    # Point 0\n",
    "                    [1.5],    # Point 1\n",
    "                    [2.0],    # Point 2\n",
    "                    [2.5],    # Point 3\n",
    "                    [3.0],    # Point 4\n",
    "                    [3.5],    # Point 5\n",
    "                    [4.0],    # Point 6\n",
    "                    [4.5],    # Point 7\n",
    "                    [5.0],    # Point 8\n",
    "                    [5.5]])   # Point 9\n",
    "\n",
    "# Target values: continuous numbers with some noise\n",
    "y_train = np.array([2.104, 2.552, 3.136, 3.604, 4.035, \n",
    "                    4.569, 5.104, 5.736, 6.244, 6.704])\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)  # (10, 1) = 10 points, 1 feature\n",
    "print(\"Target values shape:\", y_train.shape)   # (10,) = 10 target values\n",
    "print(\"\\nFirst few training points:\")\n",
    "print(X_train[:3].ravel())\n",
    "print(\"\\nCorresponding target values:\")\n",
    "print(y_train[:3])\n",
    "print(f\"\\nTarget value range: [{y_train.min():.3f}, {y_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the Data\n",
    "\n",
    "Let's plot our training data to see the relationship between x and y.\n",
    "\n",
    "We can see the points roughly follow a **linear trend** - perfect for linear regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of training data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train,\n",
    "           c='steelblue', s=150, alpha=0.7,\n",
    "           edgecolors='black', linewidths=2,\n",
    "           label='Training data')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Training Data: Looking for Linear Relationship', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"We have {len(X_train)} training points\")\n",
    "print(f\"Goal: Find the line y = w₁x + w₀ that best fits this data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Column of Ones (Bias Term)\n",
    "\n",
    "To include an **intercept term** (bias) in our model, we need to add a column of 1s to our data.\n",
    "\n",
    "**Why?**\n",
    "- Our model is: **y = w₁x + w₀**\n",
    "- We can rewrite this as: **y = w₀(1) + w₁x**\n",
    "- In matrix form: **y = [1, x] × [w₀, w₁]ᵀ**\n",
    "\n",
    "**Transformation:**\n",
    "- Original: **[x⁽¹⁾, x⁽²⁾, ..., x⁽ᴺ⁾]**\n",
    "- With bias: **[[1, x⁽¹⁾], [1, x⁽²⁾], ..., [1, x⁽ᴺ⁾]]**\n",
    "\n",
    "This matrix is called **Φ** (Phi) or the **design matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Manual Construction (Understanding the Logic)\n",
    "\n",
    "Let's manually build the design matrix step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of ones manually\n",
    "N = len(X_train)  # Number of training points\n",
    "ones_column = np.ones((N, 1))  # Column of 1s with shape (10, 1)\n",
    "\n",
    "print(\"Original X_train shape:\", X_train.shape)\n",
    "print(\"Ones column shape:\", ones_column.shape)\n",
    "print(\"\\nOnes column:\")\n",
    "print(ones_column[:3])  # Show first 3\n",
    "\n",
    "# Concatenate: [ones column | X_train]\n",
    "Phi_manual = np.concatenate([ones_column, X_train], axis=1)\n",
    "\n",
    "print(\"\\nDesign matrix Φ (Phi) shape:\", Phi_manual.shape)  # (10, 2)\n",
    "print(\"\\nFirst few rows of Φ:\")\n",
    "print(Phi_manual[:5])\n",
    "print(\"\\nEach row is now: [1, x]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Using `np.c_[]` (Efficient)\n",
    "\n",
    "`np.c_[]` is a convenient way to concatenate arrays column-wise.\n",
    "\n",
    "This is more concise than manual concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column of ones using np.c_[]\n",
    "Phi = np.c_[np.ones(len(X_train)), X_train]\n",
    "\n",
    "print(\"Design matrix Φ shape:\", Phi.shape)  # (10, 2)\n",
    "print(\"\\nFirst few rows of Φ:\")\n",
    "print(Phi[:5])\n",
    "print()\n",
    "\n",
    "# Verify both approaches match\n",
    "print(\"Manual and np.c_[] results match:\", np.allclose(Phi_manual, Phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Find Best Fit Line (Closed-Form Solution)\n",
    "\n",
    "Now we compute the optimal weights using the **normal equation**:\n",
    "\n",
    "$$\\mathbf{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf{y}$$\n",
    "\n",
    "Where:\n",
    "- **Φ** is our design matrix (with bias column)\n",
    "- **y** is our target values\n",
    "- **w** = [w₀, w₁] are the weights (intercept and slope)\n",
    "\n",
    "This gives us the **exact solution** in one computation (no iterative training!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Down the Formula Step by Step\n",
    "\n",
    "Let's compute each part of the formula manually to understand what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Compute Φᵀ (Phi transpose)\")\n",
    "print(\"=\"*50)\n",
    "Phi_T = Phi.T\n",
    "print(f\"Φ shape: {Phi.shape}\")\n",
    "print(f\"Φᵀ shape: {Phi_T.shape}\")\n",
    "print(\"\\nΦᵀ:\")\n",
    "print(Phi_T)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 2: Compute Φᵀ Φ (matrix multiplication)\")\n",
    "print(\"=\"*50)\n",
    "Phi_T_Phi = Phi_T @ Phi  # Using @ for matrix multiplication\n",
    "print(f\"Φᵀ shape: {Phi_T.shape}\")\n",
    "print(f\"Φ shape: {Phi.shape}\")\n",
    "print(f\"Φᵀ Φ shape: {Phi_T_Phi.shape}\")\n",
    "print(\"\\nΦᵀ Φ:\")\n",
    "print(Phi_T_Phi)\n",
    "print(\"\\nThis is a 2×2 symmetric matrix\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 3: Compute (Φᵀ Φ)⁻¹ (matrix inverse)\")\n",
    "print(\"=\"*50)\n",
    "Phi_T_Phi_inv = np.linalg.inv(Phi_T_Phi)\n",
    "print(f\"(Φᵀ Φ)⁻¹ shape: {Phi_T_Phi_inv.shape}\")\n",
    "print(\"\\n(Φᵀ Φ)⁻¹:\")\n",
    "print(Phi_T_Phi_inv)\n",
    "print()\n",
    "\n",
    "# Verify it's actually the inverse\n",
    "identity = Phi_T_Phi @ Phi_T_Phi_inv\n",
    "print(\"Verification: Φᵀ Φ × (Φᵀ Φ)⁻¹ should equal identity matrix:\")\n",
    "print(np.round(identity, 10))  # Round to avoid floating point display issues\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 4: Compute Φᵀ y (matrix-vector multiplication)\")\n",
    "print(\"=\"*50)\n",
    "Phi_T_y = Phi_T @ y_train\n",
    "print(f\"Φᵀ shape: {Phi_T.shape}\")\n",
    "print(f\"y shape: {y_train.shape}\")\n",
    "print(f\"Φᵀ y shape: {Phi_T_y.shape}\")\n",
    "print(\"\\nΦᵀ y:\")\n",
    "print(Phi_T_y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 5: Compute weights w = (Φᵀ Φ)⁻¹ Φᵀ y\")\n",
    "print(\"=\"*50)\n",
    "weights_manual = Phi_T_Phi_inv @ Phi_T_y\n",
    "print(f\"Weights shape: {weights_manual.shape}\")\n",
    "print(\"\\nWeights [w₀, w₁]:\")\n",
    "print(weights_manual)\n",
    "print()\n",
    "print(f\"Intercept (w₀): {weights_manual[0]:.6f}\")\n",
    "print(f\"Slope (w₁):     {weights_manual[1]:.6f}\")\n",
    "print()\n",
    "print(f\"Our linear model: y = {weights_manual[1]:.3f}x + {weights_manual[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-in-One Computation (Efficient)\n",
    "\n",
    "Now let's compute the weights in one line using the full formula.\n",
    "\n",
    "This is how you'd typically implement it in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weights using the closed-form solution\n",
    "weights = np.linalg.inv(Phi.T @ Phi) @ Phi.T @ y_train\n",
    "\n",
    "print(\"Weights computed in one line:\")\n",
    "print(weights)\n",
    "print()\n",
    "print(f\"Intercept (w₀): {weights[0]:.6f}\")\n",
    "print(f\"Slope (w₁):     {weights[1]:.6f}\")\n",
    "print()\n",
    "\n",
    "# Verify both approaches match\n",
    "print(\"Manual and one-line results match:\", np.allclose(weights_manual, weights))\n",
    "print()\n",
    "print(f\"Final linear model: y = {weights[1]:.3f}x + {weights[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize the Best Fit Line\n",
    "\n",
    "Let's plot our learned line along with the training data to see how well it fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x values for plotting the line\n",
    "x_line = np.linspace(0, 6, 100)\n",
    "\n",
    "# Compute y values using our learned weights: y = w₁x + w₀\n",
    "y_line = weights[1] * x_line + weights[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Training data\n",
    "plt.scatter(X_train, y_train,\n",
    "           c='steelblue', s=150, alpha=0.7,\n",
    "           edgecolors='black', linewidths=2,\n",
    "           label='Training data', zorder=3)\n",
    "\n",
    "# Best fit line\n",
    "plt.plot(x_line, y_line,\n",
    "        'r-', linewidth=3, alpha=0.8,\n",
    "        label=f'Best fit line: y = {weights[1]:.3f}x + {weights[0]:.3f}')\n",
    "\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Linear Regression: Best Fit Line', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Model equation: y = {weights[1]:.3f}x + {weights[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions on Test Data\n",
    "\n",
    "Now let's use our trained model to predict a new value.\n",
    "\n",
    "**Example:** What is the predicted y value when x = 5?\n",
    "\n",
    "### Step 7a: Add Bias Term to Test Data\n",
    "\n",
    "Just like with training data, we need to add a column of 1s to our test data.\n",
    "\n",
    "**Transformation:** [5] → [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test point\n",
    "X_test = np.array([[5.0]])\n",
    "\n",
    "print(\"Original test point:\", X_test[0])\n",
    "print(\"Shape:\", X_test.shape)\n",
    "print()\n",
    "\n",
    "# Add bias term\n",
    "X_test_with_bias = np.c_[np.ones(len(X_test)), X_test]\n",
    "\n",
    "print(\"Test point with bias:\", X_test_with_bias[0])\n",
    "print(\"Shape:\", X_test_with_bias.shape)\n",
    "print()\n",
    "print(\"Now it has the form [1, x] to match our weights [w₀, w₁]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7b: Compute Prediction\n",
    "\n",
    "Prediction is simply a **dot product**:\n",
    "\n",
    "$$\\hat{y} = [1, x] \\cdot [w_0, w_1]^T = 1 \\times w_0 + x \\times w_1$$\n",
    "\n",
    "Let's compute it both manually and using NumPy operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual calculation\n",
    "x_value = X_test[0, 0]  # x = 5.0\n",
    "w0 = weights[0]  # Intercept\n",
    "w1 = weights[1]  # Slope\n",
    "\n",
    "print(\"Manual calculation:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"x = {x_value}\")\n",
    "print(f\"w₀ (intercept) = {w0:.6f}\")\n",
    "print(f\"w₁ (slope)     = {w1:.6f}\")\n",
    "print()\n",
    "print(f\"ŷ = w₀ + w₁ × x\")\n",
    "print(f\"ŷ = {w0:.6f} + {w1:.6f} × {x_value}\")\n",
    "print(f\"ŷ = {w0:.6f} + {w1 * x_value:.6f}\")\n",
    "\n",
    "prediction_manual = w0 + w1 * x_value\n",
    "print(f\"ŷ = {prediction_manual:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: Using Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using matrix multiplication\n",
    "prediction = X_test_with_bias @ weights\n",
    "\n",
    "print(\"Matrix multiplication approach:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"X_test with bias: {X_test_with_bias[0]}\")\n",
    "print(f\"Weights:          {weights}\")\n",
    "print()\n",
    "print(f\"Prediction = [1, {x_value}] @ [{w0:.3f}, {w1:.3f}]\")\n",
    "print(f\"Prediction = 1×{w0:.3f} + {x_value}×{w1:.3f}\")\n",
    "print(f\"Prediction = {prediction[0]:.3f}\")\n",
    "print()\n",
    "\n",
    "# Verify both approaches match\n",
    "print(f\"Manual and matrix predictions match: {np.isclose(prediction_manual, prediction[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize the Prediction\n",
    "\n",
    "Let's visualize our prediction on the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x values for plotting the line\n",
    "x_line = np.linspace(0, 6, 100)\n",
    "y_line = weights[1] * x_line + weights[0]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Training data\n",
    "plt.scatter(X_train, y_train,\n",
    "           c='steelblue', s=150, alpha=0.7,\n",
    "           edgecolors='black', linewidths=2,\n",
    "           label='Training data', zorder=3)\n",
    "\n",
    "# Best fit line\n",
    "plt.plot(x_line, y_line,\n",
    "        'r-', linewidth=3, alpha=0.8,\n",
    "        label=f'Best fit line: y = {weights[1]:.3f}x + {weights[0]:.3f}')\n",
    "\n",
    "# Test point and prediction\n",
    "plt.scatter(X_test, prediction,\n",
    "           c='red', s=400, marker='*',\n",
    "           edgecolors='black', linewidths=2,\n",
    "           label=f'Prediction: x={X_test[0,0]:.1f}, ŷ={prediction[0]:.3f}',\n",
    "           zorder=4)\n",
    "\n",
    "# Draw dashed lines to show prediction\n",
    "plt.plot([X_test[0,0], X_test[0,0]], [0, prediction[0]], \n",
    "        'k--', alpha=0.5, linewidth=1.5)\n",
    "plt.plot([0, X_test[0,0]], [prediction[0], prediction[0]], \n",
    "        'k--', alpha=0.5, linewidth=1.5)\n",
    "\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Linear Regression: Making a Prediction', fontsize=16)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(-0.2, 6)\n",
    "plt.ylim(0, 8)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFor test point x = {X_test[0,0]:.1f}:\")\n",
    "print(f\"Predicted value ŷ = {prediction[0]:.3f}\")\n",
    "print(f\"\\nCalculation: ŷ = {weights[1]:.3f} × {X_test[0,0]:.1f} + {weights[0]:.3f} = {prediction[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Make Predictions for Multiple Test Points\n",
    "\n",
    "Let's predict for several test points at once to see how vectorization works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple test points\n",
    "X_test_multiple = np.array([[1.0], [2.5], [4.0], [5.5], [6.0]])\n",
    "\n",
    "print(\"Test points:\")\n",
    "print(X_test_multiple.ravel())\n",
    "print()\n",
    "\n",
    "# Add bias term\n",
    "X_test_multiple_with_bias = np.c_[np.ones(len(X_test_multiple)), X_test_multiple]\n",
    "\n",
    "print(\"Test points with bias:\")\n",
    "print(X_test_multiple_with_bias)\n",
    "print()\n",
    "\n",
    "# Make predictions (vectorized operation!)\n",
    "predictions_multiple = X_test_multiple_with_bias @ weights\n",
    "\n",
    "print(\"Predictions:\")\n",
    "for i, (x, y_pred) in enumerate(zip(X_test_multiple, predictions_multiple)):\n",
    "    print(f\"  x = {x[0]:.1f}  →  ŷ = {y_pred:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've walked through all the computational steps of Linear Regression:\n",
    "\n",
    "1. ✅ **Visualized data** - saw training points showing linear trend\n",
    "2. ✅ **Added bias term** - transformed data by adding column of 1s to create design matrix Φ\n",
    "3. ✅ **Found best fit line** - used closed-form solution **w = (ΦᵀΦ)⁻¹Φᵀy** to compute optimal weights\n",
    "4. ✅ **Made predictions** - computed ŷ = [1, x] · [w₀, w₁] for new points\n",
    "\n",
    "### Key Linear Regression Concepts:\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Design Matrix (Φ)** | Training data with bias column: [[1, x⁽¹⁾], [1, x⁽²⁾], ...] |\n",
    "| **Weights (w)** | [w₀, w₁] where w₀ = intercept, w₁ = slope |\n",
    "| **Normal Equation** | w = (ΦᵀΦ)⁻¹Φᵀy gives optimal solution directly |\n",
    "| **Prediction** | ŷ = w₀ + w₁x (or [1,x] · w in matrix form) |\n",
    "\n",
    "### Key NumPy Operations Used:\n",
    "\n",
    "- **`np.c_[ones, X]`** - concatenate columns to add bias term\n",
    "- **`.T`** - transpose matrix (Φ → Φᵀ)\n",
    "- **`@`** - matrix multiplication operator\n",
    "- **`np.linalg.inv()`** - compute matrix inverse\n",
    "- **`Phi.T @ Phi`** - compute ΦᵀΦ (Gram matrix)\n",
    "- **`X @ w`** - compute predictions via matrix-vector multiplication\n",
    "\n",
    "### Linear Regression vs KNN Regression:\n",
    "\n",
    "| Aspect | Linear Regression | KNN Regression |\n",
    "|--------|------------------|----------------|\n",
    "| **Model** | Parametric (learns fixed weights) | Non-parametric (uses training data directly) |\n",
    "| **Training** | Closed-form solution (instant) | No training needed |\n",
    "| **Prediction** | Fast (just w₀ + w₁x) | Slower (must find K neighbors) |\n",
    "| **Assumes** | Linear relationship | Local similarity |\n",
    "| **Memory** | Only stores weights | Must store all training data |\n",
    "\n",
    "### Why Both Approaches?\n",
    "\n",
    "- **Manual calculations** help you understand the mathematical steps\n",
    "- **Vectorized matrix operations** are efficient and concise for implementation\n",
    "\n",
    "In practice, use vectorized operations, but understanding the step-by-step computation helps you know what's happening under the hood!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
