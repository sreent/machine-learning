{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sreent/machine-learning/blob/main/Linear%20Regression/Linear%20Regression%20Hands-On%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Hands-On Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will implement a Linear Regression model from scratch, understand the mathematics behind it, and apply it to real data. Along the way, you'll answer conceptual questions and create visualizations to deepen your understanding.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the mathematics of Linear Regression\n",
    "- Implement a custom Linear Regression class from scratch\n",
    "- Visualize regression lines and prediction errors\n",
    "- Apply feature scaling and understand its importance\n",
    "- Tune models using train/validation/test splits\n",
    "- Compare custom implementation with scikit-learn\n",
    "- Analyze model performance and errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a **parametric supervised learning algorithm** used for **regression tasks** (predicting continuous values).\n",
    "\n",
    "**Key Idea:**\n",
    "- Find a **linear function** that best fits the training data\n",
    "- Model: **y = w\u2081x + w\u2080** (for single feature) or **y = w\u2080 + w\u2081x\u2081 + w\u2082x\u2082 + ... + w\u2099x\u2099** (for multiple features)\n",
    "- **w\u2080** is the intercept (bias term)\n",
    "- **w\u2081, w\u2082, ..., w\u2099** are the slopes (weights)\n",
    "\n",
    "**How it works:**\n",
    "1. **Training:** Find optimal weights **w** using the **normal equation**: **w = (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y**\n",
    "2. **Prediction:** Compute **\u0177 = \u03a6w** where \u03a6 is the design matrix with bias column\n",
    "\n",
    "**Advantages:**\n",
    "- Simple and interpretable\n",
    "- Fast training (closed-form solution)\n",
    "- Fast prediction\n",
    "- Works well when relationships are linear\n",
    "\n",
    "**Disadvantages:**\n",
    "- Assumes linear relationship\n",
    "- Sensitive to outliers\n",
    "- Can't capture complex non-linear patterns (without feature engineering)\n",
    "- Matrix inversion can be computationally expensive for very large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: Linear Regression finds the best fit line by:\n>\n> A. Computing the closed-form solution using the normal equation w = (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y\n>\n> B. Iteratively searching through all possible lines  \n> C. Using the K nearest neighbors to draw a line\n>\n> D. Randomly selecting weights until a good fit is found\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nLinear Regression uses the normal equation to compute the optimal weights directly in one step, without any iterative training.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Complexity: From Simple to Complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While basic Linear Regression fits a straight line, we can create more complex models using **polynomial features**.\n",
    "\n",
    "**Examples:**\n",
    "- **Degree 1 (Linear):** y = w\u2080 + w\u2081x\n",
    "- **Degree 2 (Quadratic):** y = w\u2080 + w\u2081x + w\u2082x\u00b2\n",
    "- **Degree 3 (Cubic):** y = w\u2080 + w\u2081x + w\u2082x\u00b2 + w\u2083x\u00b3\n",
    "\n",
    "As model complexity increases:\n",
    "- **Low complexity (underfit):** Model is too simple, high bias, misses patterns\n",
    "- **Right complexity:** Model generalizes well, balanced bias-variance\n",
    "- **High complexity (overfit):** Model is too complex, high variance, memorizes noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.linspace(-3, 3, 50).reshape(-1, 1)\n",
    "y = 0.5 * X.ravel()**2 + X.ravel() + 2 + np.random.normal(0, 1, 50)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "degrees = [1, 2, 9]\n",
    "titles = ['Underfitting (Degree 1)', 'Good Fit (Degree 2)', 'Overfitting (Degree 9)']\n",
    "\n",
    "for ax, degree, title in zip(axes, degrees, titles):\n",
    "    # Fit polynomial regression\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "    \n",
    "    # Plot\n",
    "    X_plot = np.linspace(-3, 3, 200).reshape(-1, 1)\n",
    "    X_plot_poly = poly.transform(X_plot)\n",
    "    y_plot = model.predict(X_plot_poly)\n",
    "    \n",
    "    ax.scatter(X, y, c='lightblue', s=50, edgecolors='black', label='Data')\n",
    "    ax.plot(X_plot, y_plot, 'r-', linewidth=2, label=f'Degree {degree}')\n",
    "    ax.set_xlabel('x', fontsize=12)\n",
    "    ax.set_ylabel('y', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off in Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias** = Error from overly simplistic assumptions\n",
    "- High bias \u2192 Underfitting \u2192 Model too simple\n",
    "- Example: Fitting a line to quadratic data\n",
    "\n",
    "**Variance** = Error from sensitivity to small fluctuations in training data\n",
    "- High variance \u2192 Overfitting \u2192 Model too complex\n",
    "- Example: High-degree polynomial that memorizes noise\n",
    "\n",
    "**Goal:** Find the sweet spot that minimizes **total error = bias\u00b2 + variance + irreducible error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: A linear regression model with polynomial degree 1 has high training and validation error. This indicates:\n>\n> A. High bias (underfitting) - the model is too simple\n>\n> B. High variance (overfitting) - the model is too complex  \n> C. Perfect fit - the model generalizes well\n>\n> D. The data has too much noise\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nWhen both training and validation errors are high, the model is underfitting - it's too simple to capture the underlying pattern.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling in Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Linear Regression's predictions aren't affected by feature scaling (unlike KNN), scaling is still important because:\n",
    "\n",
    "1. **Numerical Stability:** Computing (\u03a6\u1d40\u03a6)\u207b\u00b9 can be numerically unstable when features have very different scales\n",
    "2. **Regularization:** If using Ridge or Lasso regression, unscaled features will be penalized unfairly\n",
    "3. **Optimization:** When using gradient descent instead of the normal equation, convergence is much faster with scaled features\n",
    "4. **Interpretability:** Standardized coefficients can be compared to determine feature importance\n",
    "\n",
    "**Best Practice:** Always scale features for regression tasks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Z-Score Formula\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- **x** = original value\n",
    "- **\u03bc** = mean of the feature\n",
    "- **\u03c3** = standard deviation of the feature\n",
    "- **z** = standardized value\n",
    "\n",
    "### What This Does\n",
    "- Centers data around 0 (mean = 0)\n",
    "- Scales to unit variance (std = 1)\n",
    "- Preserves the distribution shape\n",
    "- Makes features comparable\n",
    "\n",
    "### Critical Rule for Train/Validation/Test Splits\n",
    "```python\n",
    "# 1. Fit scaler on training data ONLY\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Compute \u03bc and \u03c3 from training data\n",
    "\n",
    "# 2. Transform all sets using SAME parameters\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)      # Use training \u03bc and \u03c3\n",
    "X_test_scaled = scaler.transform(X_test)    # Use training \u03bc and \u03c3\n",
    "```\n",
    "\n",
    "**Why?** To prevent **data leakage** - the model should not have any information about validation/test sets during training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: When using StandardScaler with train/validation/test splits, what is the correct approach?\n>\n> A. Fit the scaler on training data only, then transform all sets using those parameters\n>\n> B. Fit and transform each set independently  \n> C. Fit the scaler on all data first, then split\n>\n> D. Scaling is not needed for Linear Regression\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nTo avoid data leakage, always fit the scaler on training data only, then use those same parameters (mean and std) to transform validation and test sets.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocode for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Pseudocode\n",
    "\n",
    "```\n",
    "============================================\n",
    "Inputs\n",
    "============================================\n",
    "X       \u2190 training features (N \u00d7 d matrix)\n",
    "y       \u2190 training targets (N \u00d7 1 vector)\n",
    "X_query \u2190 examples to predict\n",
    "\n",
    "============================================\n",
    "----- fit -----\n",
    "============================================\n",
    "1. Store X and y\n",
    "2. Add bias column: \u03a6 \u2190 [1, X]  # (N \u00d7 (d+1))\n",
    "3. Compute weights using normal equation:\n",
    "   w \u2190 (\u03a6\u1d40\u03a6)\u207b\u00b9\u03a6\u1d40y\n",
    "4. Store w\n",
    "\n",
    "============================================\n",
    "----- predict -----\n",
    "============================================\n",
    "For each query point in X_query:\n",
    "1. Add bias: \u03a6_query \u2190 [1, X_query]\n",
    "2. Compute prediction: \u0177 \u2190 \u03a6_query \u00b7 w\n",
    "3. Return \u0177\n",
    "```\n",
    "\n",
    "### Key Observations\n",
    "- **No iterations needed:** One-step solution via normal equation\n",
    "- **Fast prediction:** Just matrix multiplication\n",
    "- **Memory efficient:** Only stores weights (not all training data like KNN)\n",
    "- **Global model:** Learns one function for entire space (unlike local KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Custom Linear Regression Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a scaffold of the `MyLinearRegressor` class. Fill in the TODO sections to complete the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class MyLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom Linear Regression implementation using the normal equation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    weights_ : array of shape (n_features + 1,)\n",
    "        Learned weights including bias term\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the linear regression model using the normal equation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        self\n",
    "        \"\"\"\n",
    "        # TODO: Add column of ones for bias term\n",
    "        # Hint: Use np.c_[np.ones(len(X)), X] to create design matrix Phi\n",
    "        Phi = None  # Replace with your code\n",
    "        \n",
    "        # TODO: Compute weights using normal equation: w = (Phi^T Phi)^{-1} Phi^T y\n",
    "        # Hint: Use @ for matrix multiplication, .T for transpose, np.linalg.inv() for inverse\n",
    "        self.weights_ = None  # Replace with your code\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the linear model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples to predict\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : array of shape (n_samples,)\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        # TODO: Add column of ones for bias term\n",
    "        Phi = None  # Replace with your code\n",
    "        \n",
    "        # TODO: Compute predictions: y_pred = Phi @ weights\n",
    "        y_pred = None  # Replace with your code\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementation\n",
    "\n",
    "Once you have filled in the implementation, let's test our custom regressor on a simple dataset to ensure it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple test data\n",
    "np.random.seed(42)\n",
    "X_simple = np.array([[1], [2], [3], [4], [5]])\n",
    "y_simple = np.array([2, 4, 6, 8, 10])  # Perfect linear relationship: y = 2x\n",
    "\n",
    "# Fit model\n",
    "model = MyLinearRegressor()\n",
    "model.fit(X_simple, y_simple)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_simple)\n",
    "\n",
    "print(\"Learned weights (w0=intercept, w1=slope):\", model.weights_)\n",
    "print(\"Expected: [0, 2] or very close to it\")\n",
    "print(\"\\nPredictions:\", predictions)\n",
    "print(\"Actual:     \", y_simple)\n",
    "print(\"\\nMean Squared Error:\", np.mean((predictions - y_simple)**2))\n",
    "print(\"Expected: ~0 (perfect fit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: Unlike algorithms such as KNN, Linear Regression has very fast prediction time even with large datasets. Why?\n>\n> A. Linear Regression learns a parametric model (weights) during training. Prediction is just a simple matrix multiplication, regardless of training set size.\n>\n> B. Linear Regression stores fewer training examples than KNN.  \n> C. Linear Regression uses a faster distance metric.\n>\n> D. Linear Regression approximates predictions rather than computing exact values.\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nLinear Regression learns fixed weights during training. At prediction time, it only needs to compute \u0177 = \u03a6w, which is O(d) where d is the number of features. KNN needs to compute distances to all N training points, which is O(Nd).\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Dataset for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with the same synthetic dataset from the Code Walk Through to visualize how Linear Regression works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the same data as in Code Walk Through\n",
    "np.random.seed(42)\n",
    "X_train = np.arange(-9.5, 8.5, 0.1).reshape(-1, 1)\n",
    "y_train = X_train.ravel() + 1 + np.random.normal(0, 2, len(X_train))\n",
    "\n",
    "print(f\"Training data: {len(X_train)} points\")\n",
    "print(f\"X range: [{X_train.min():.1f}, {X_train.max():.1f}]\")\n",
    "print(f\"y range: [{y_train.min():.1f}, {y_train.max():.1f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Training Data: Linear Relationship with Noise', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Visualizing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your MyLinearRegressor on the training data\n",
    "# Hint: model = MyLinearRegressor()\n",
    "#       model.fit(X_train, y_train)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(f\"Learned weights: {model.weights_}\")\n",
    "print(f\"Model equation: y = {model.weights_[1]:.3f}x + {model.weights_[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fit\n",
    "x_line = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "y_line = model.predict(x_line)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "plt.plot(x_line, y_line, 'r-', linewidth=2, label=f'Best fit: y={model.weights_[1]:.2f}x+{model.weights_[0]:.2f}')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Linear Regression: Best Fit Line', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Predictions: Step-by-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how the model makes a prediction for a single test point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a prediction for x = 5.0\n",
    "# Hint: X_test = np.array([[5.0]])\n",
    "#       y_pred = model.predict(X_test)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(f\"For x = {X_test[0, 0]:.1f}:\")\n",
    "print(f\"Predicted y = {y_pred[0]:.3f}\")\n",
    "print(f\"Calculation: y = {model.weights_[1]:.3f} \u00d7 {X_test[0, 0]:.1f} + {model.weights_[0]:.3f} = {y_pred[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prediction\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train, y_train, c='lightblue', alpha=0.6, label='Training data')\n",
    "plt.plot(x_line, y_line, 'k-', linewidth=2, label='Best fit line')\n",
    "plt.scatter(X_test, y_pred, c='red', s=200, marker='*', edgecolors='black', linewidths=2, \n",
    "           label=f'Prediction: x={X_test[0,0]:.1f}, \u0177={y_pred[0]:.2f}', zorder=5)\n",
    "plt.plot([X_train.min(), X_test[0,0]], [y_pred[0], y_pred[0]], 'r--', alpha=0.5, linewidth=1)\n",
    "plt.plot([X_test[0,0], X_test[0,0]], [y_train.min(), y_pred[0]], 'r--', alpha=0.5, linewidth=1)\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Linear Regression: Making a Prediction', fontsize=16)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics: MSE and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- Measures average squared difference between actual and predicted values\n",
    "- Units are squared (e.g., if y is in dollars, MSE is in dollars\u00b2)\n",
    "- Heavily penalizes large errors (due to squaring)\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\text{MSE}}$$\n",
    "\n",
    "- Same units as the target variable\n",
    "- Easier to interpret (e.g., \"average error of $5000\")\n",
    "- Commonly used for regression evaluation\n",
    "\n",
    "### R\u00b2 Score (Coefficient of Determination)\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{N} (y_i - \\bar{y})^2}$$\n",
    "\n",
    "- Ranges from -\u221e to 1 (1 is perfect, 0 means model is no better than predicting mean)\n",
    "- Represents proportion of variance explained by the model\n",
    "- Scale-independent (can compare across different datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Compute metrics on training data\n",
    "y_train_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Training Metrics:\")\n",
    "print(f\"  MSE:  {mse:.3f}\")\n",
    "print(f\"  RMSE: {rmse:.3f}\")\n",
    "print(f\"  R\u00b2:   {r2:.3f}\")\n",
    "print(f\"\\nInterpretation: The model's predictions are on average {rmse:.2f} units away from actual values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a Real Dataset: California Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply Linear Regression to a real-world dataset. We'll use the California Housing dataset, which contains information about California districts and median house values.\n",
    "\n",
    "**Dataset Features:**\n",
    "- MedInc: Median income in block group\n",
    "- HouseAge: Median house age in block group  \n",
    "- AveRooms: Average number of rooms per household\n",
    "- AveBedrms: Average number of bedrooms per household\n",
    "- Population: Block group population\n",
    "- AveOccup: Average number of household members\n",
    "- Latitude: Block group latitude\n",
    "- Longitude: Block group longitude\n",
    "\n",
    "**Target:** Median house value (in $100,000s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=housing.feature_names)\n",
    "df['MedHouseVal'] = y\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how features have **very different scales:**\n",
    "- MedInc ranges from ~0.5 to ~15\n",
    "- Population ranges from ~3 to ~35,000+\n",
    "- Latitude/Longitude are coordinates\n",
    "\n",
    "This is why feature scaling is important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why 3 splits?**\n",
    "- **Training set (60%):** Fit the model\n",
    "- **Validation set (20%):** Tune hyperparameters / compare models\n",
    "- **Test set (20%):** Final evaluation (touch only once!)\n",
    "\n",
    "**Important:** Test set simulates real-world unseen data. Never use it for model selection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Split into Train (60%), Validation (20%), Test (20%)\n",
    "# Hint: First split into Train (60%) and Temp (40%)\n",
    "#       Then split Temp into equal halves for Validation and Test\n",
    "#       Use random_state=42 for reproducibility\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(f\"Training set:   {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set:       {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling: Comparing Unscaled vs Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression on Unscaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit MyLinearRegressor on unscaled training data\n",
    "# TODO: Predict on validation set\n",
    "# TODO: Compute RMSE and R\u00b2 scores\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(\"Performance on UNSCALED features:\")\n",
    "print(f\"  Validation RMSE: {rmse_unscaled:.4f}\")\n",
    "print(f\"  Validation R\u00b2:   {r2_unscaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Regression on Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Create and fit StandardScaler on training data ONLY\n",
    "# TODO: Transform train and validation sets\n",
    "# Hint: scaler = StandardScaler()\n",
    "#       scaler.fit(X_train)\n",
    "#       X_train_scaled = scaler.transform(X_train)\n",
    "#       X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(\"Scaled training data statistics:\")\n",
    "print(f\"  Mean: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"  Std:  {X_train_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit MyLinearRegressor on scaled training data\n",
    "# TODO: Predict on scaled validation set\n",
    "# TODO: Compute RMSE and R\u00b2 scores\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(\"Performance on SCALED features:\")\n",
    "print(f\"  Validation RMSE: {rmse_scaled:.4f}\")\n",
    "print(f\"  Validation R\u00b2:   {r2_scaled:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPARISON: Unscaled vs Scaled Features\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Unscaled - RMSE: {rmse_unscaled:.4f} | R\u00b2: {r2_unscaled:.4f}\")\n",
    "print(f\"Scaled   - RMSE: {rmse_scaled:.4f} | R\u00b2: {r2_scaled:.4f}\")\n",
    "print(\"\\nNote: For Linear Regression with normal equation, scaling doesn't change predictions.\")\n",
    "print(\"However, it improves numerical stability and is essential for regularization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You observe that a Linear Regression model has RMSE of 0.5 on training data but 0.75 on validation data. What does this suggest?\n>\n> A. The model generalizes reasonably well - some gap between train and validation error is expected due to overfitting\n>\n> B. The model is severely underfitting  \n> C. There is data leakage from validation to training\n>\n> D. Feature scaling is needed\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nA moderate gap between training and validation error is normal - the model fits the training data slightly better than unseen data. The gap indicates some overfitting but not severe. If the gap were very large (e.g., 0.1 vs 2.0), that would indicate serious overfitting.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Scikit-Learn's Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our implementation matches scikit-learn's LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as SklearnLR\n",
    "\n",
    "# Fit sklearn model\n",
    "sklearn_model = SklearnLR()\n",
    "sklearn_model.fit(X_train_scaled, y_train)\n",
    "y_val_pred_sklearn = sklearn_model.predict(X_val_scaled)\n",
    "\n",
    "# Compute metrics\n",
    "rmse_sklearn = np.sqrt(mean_squared_error(y_val, y_val_pred_sklearn))\n",
    "r2_sklearn = r2_score(y_val, y_val_pred_sklearn)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Custom Implementation vs Scikit-Learn\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Custom MyLinearRegressor - RMSE: {rmse_scaled:.4f} | R\u00b2: {r2_scaled:.4f}\")\n",
    "print(f\"Sklearn LinearRegression - RMSE: {rmse_sklearn:.4f} | R\u00b2: {r2_sklearn:.4f}\")\n",
    "print(f\"\\nDifference in RMSE: {abs(rmse_scaled - rmse_sklearn):.6f}\")\n",
    "print(f\"Difference in R\u00b2:   {abs(r2_scaled - r2_sklearn):.6f}\")\n",
    "print(\"\\n\u2713 Results should match (within numerical precision)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Predictions vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred_scaled, alpha=0.5, edgecolors='black', linewidths=0.5)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', linewidth=2, label='Perfect predictions')\n",
    "plt.xlabel('Actual Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.title(f'Predictions vs Actual (R\u00b2 = {r2_scaled:.3f})', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Points close to the red line indicate accurate predictions.\")\n",
    "print(\"Scatter away from the line shows prediction errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Prediction Errors: Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals (errors)\n",
    "residuals = y_val - y_val_pred_scaled\n",
    "\n",
    "# Create residual plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Residuals vs Predicted Values\n",
    "axes[0].scatter(y_val_pred_scaled, residuals, alpha=0.5, edgecolors='black', linewidths=0.5)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Predicted Values', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals (Actual - Predicted)', fontsize=12)\n",
    "axes[0].set_title('Residual Plot', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram of Residuals\n",
    "axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residuals', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Distribution of Residuals', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Good residual plots should show:\")\n",
    "print(\"  1. Residuals randomly scattered around 0 (no patterns)\")\n",
    "print(\"  2. Approximately normal distribution\")\n",
    "print(\"  3. Constant variance across all predicted values (homoscedasticity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Outliers on Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is **sensitive to outliers** because it uses the **sum of squared errors** as its objective function. Outliers can significantly distort the regression line by pulling it towards themselves, leading to:\n\n",
    "- **Biased coefficient estimates**: The model tries to minimize error for all points, including outliers\n",
    "- **Reduced model accuracy**: The regression line may not represent the true relationship for most data points\n",
    "- **Poor generalization**: The model fits extreme points rather than the overall trend\n\n",
    "**Key Principle**: Our ML model should perform well in most cases. Therefore, outliers should often be detected and handled appropriately (removed, capped, or modeled separately) before training.\n\n",
    "Let's demonstrate the impact of outliers with a visual example:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate clean data with a linear relationship\n",
    "np.random.seed(42)\n",
    "X_clean = np.linspace(0, 10, 50).reshape(-1, 1)\n",
    "y_clean = 2 * X_clean.ravel() + 1 + np.random.normal(0, 1, 50)\n",
    "\n",
    "# Add an outlier\n",
    "X_with_outlier = np.vstack([X_clean, [[8.0]]])\n",
    "y_with_outlier = np.append(y_clean, [5.0])  # This point is far below the trend\n",
    "\n",
    "# Fit models\n",
    "model_clean = MyLinearRegressor()\n",
    "model_clean.fit(X_clean, y_clean)\n",
    "\n",
    "model_with_outlier = MyLinearRegressor()\n",
    "model_with_outlier.fit(X_with_outlier, y_with_outlier)\n",
    "\n",
    "# Create predictions for plotting\n",
    "X_plot = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_plot_clean = model_clean.predict(X_plot)\n",
    "y_plot_with_outlier = model_with_outlier.predict(X_plot)\n",
    "\n",
    "# Visualize the impact\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot without outlier\n",
    "ax1.scatter(X_clean, y_clean, alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "ax1.plot(X_plot, y_plot_clean, 'r-', linewidth=2, \n",
    "         label=f'Fit: y={model_clean.weights_[1]:.2f}x+{model_clean.weights_[0]:.2f}')\n",
    "ax1.set_xlabel('X', fontsize=12)\n",
    "ax1.set_ylabel('y', fontsize=12)\n",
    "ax1.set_title('Linear Regression WITHOUT Outlier', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot with outlier\n",
    "ax2.scatter(X_clean, y_clean, alpha=0.6, edgecolors='black', linewidths=0.5, label='Training data')\n",
    "ax2.scatter([8.0], [5.0], color='red', s=200, marker='*', edgecolors='black', \n",
    "           linewidths=2, label='Outlier', zorder=5)\n",
    "ax2.plot(X_plot, y_plot_clean, 'g--', linewidth=2, alpha=0.5, label='Original fit (without outlier)')\n",
    "ax2.plot(X_plot, y_plot_with_outlier, 'r-', linewidth=2, \n",
    "         label=f'Fit WITH outlier: y={model_with_outlier.weights_[1]:.2f}x+{model_with_outlier.weights_[0]:.2f}')\n",
    "ax2.set_xlabel('X', fontsize=12)\n",
    "ax2.set_ylabel('y', fontsize=12)\n",
    "ax2.set_title('Linear Regression WITH Outlier', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImpact of the outlier:\")\n",
    "print(f\"  Slope changed from {model_clean.weights_[1]:.3f} to {model_with_outlier.weights_[1]:.3f}\")\n",
    "print(f\"  Intercept changed from {model_clean.weights_[0]:.3f} to {model_with_outlier.weights_[0]:.3f}\")\n",
    "print(f\"\\nThe regression line is 'pulled' toward the outlier, affecting predictions for all points!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: You notice one data point in your training set has an extremely high target value compared to similar inputs. What is the likely impact on your linear regression model?\n>\n",
    "> A. No impact - linear regression automatically ignores outliers during training\n>\n",
    "> B. The regression line will be pulled toward the outlier, potentially degrading predictions for typical data points\n>\n",
    "> C. The model will fit better because it has more diverse training examples\n>\n",
    "> D. Only the intercept will be affected, not the slope\n",
    "<details><summary>Click to reveal answer</summary>\n\n",
    "**Answer: B**\n\n",
    "Linear regression minimizes the sum of squared errors across all points. Because outliers have large errors, the model shifts the regression line to reduce their error, which can worsen predictions for the majority of normal points. This is why outlier detection and handling is crucial in linear regression.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've finalized our approach (using scaled features), let's evaluate on the test set **one time only**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Transform test set using the SAME scaler fitted on training data\n",
    "# TODO: Predict on test set\n",
    "# TODO: Compute final RMSE and R\u00b2 scores\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test R\u00b2:   {test_r2:.4f}\")\n",
    "print(f\"\\nInterpretation: Our model's predictions are on average\")\n",
    "print(f\"{test_rmse:.2f} \u00d7 $100,000 = ${test_rmse*100000:.0f} away from actual house values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we standardized our features, we can compare the magnitude of learned weights to understand feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature weights (excluding bias)\n",
    "feature_weights = model_scaled.weights_[1:]  # Skip bias term\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': housing.feature_names,\n",
    "    'Weight': feature_weights\n",
    "}).sort_values('Weight', key=abs, ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in importance_df['Weight']]\n",
    "plt.barh(importance_df['Feature'], importance_df['Weight'], color=colors, edgecolor='black')\n",
    "plt.xlabel('Standardized Weight', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance (Standardized Weights)', fontsize=14)\n",
    "plt.axvline(x=0, color='black', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df.to_string(index=False))\n",
    "print(\"\\nGreen = Positive correlation (\u2191 feature \u2192 \u2191 house value)\")\n",
    "print(\"Red   = Negative correlation (\u2191 feature \u2192 \u2193 house value)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**: In the California Housing dataset, the MedInc feature has a large positive weight. This means:\n>\n> A. Higher median income in a block group is associated with higher house values\n>\n> B. Median income causes house values to increase  \n> C. Median income is the only important feature\n>\n> D. The model is overfitting on median income\n\n<details><summary>Click to reveal answer</summary>\n**Answer: A**\n\nCorrelation does not imply causation. A large positive weight indicates a strong positive association, but we cannot conclude causation from this alone. The model considers all features together.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Linear Regression is parametric and efficient**\n",
    "   - Learns fixed weights during training\n",
    "   - Fast prediction (just matrix multiplication)\n",
    "   - Closed-form solution via normal equation\n",
    "\n",
    "2. **Always scale your features**\n",
    "   - Fit scaler on training data ONLY\n",
    "   - Transform all sets using same parameters\n",
    "   - Essential for regularization and numerical stability\n",
    "\n",
    "3. **Use proper train/validation/test splits**\n",
    "   - Training: Fit the model\n",
    "   - Validation: Tune hyperparameters/compare models\n",
    "   - Test: Final evaluation (touch once!)\n",
    "\n",
    "4. **Understand bias-variance tradeoff**\n",
    "   - Simple models (low degree) \u2192 high bias (underfit)\n",
    "   - Complex models (high degree) \u2192 high variance (overfit)\n",
    "   - Find the sweet spot using validation set\n",
    "\n",
    "5. **Analyze residuals**\n",
    "   - Check for patterns in residual plots\n",
    "   - Validate assumptions (normality, homoscedasticity)\n",
    "   - Identify areas where model struggles\n",
    "\n",
    "### When to Use Linear Regression\n",
    "\n",
    "\u2705 **Good for:**\n",
    "- Relationships that are approximately linear\n",
    "- When interpretability is important\n",
    "- Baseline model for comparison\n",
    "- Large datasets (very efficient)\n",
    "\n",
    "\u274c **Not ideal for:**\n",
    "- Highly non-linear relationships (without feature engineering)\n",
    "- Data with many outliers (consider robust regression)\n",
    "- When features are highly collinear (consider Ridge/Lasso)\n",
    "\n",
    "### Linear Regression vs KNN Regression\n",
    "\n",
    "| Aspect | Linear Regression | KNN Regression |\n",
    "|--------|------------------|----------------|\n",
    "| **Model Type** | Parametric (learns weights) | Non-parametric (instance-based) |\n",
    "| **Training Time** | Fast (closed-form) | Instant (lazy learner) |\n",
    "| **Prediction Time** | Very fast O(d) | Slower O(Nd) |\n",
    "| **Memory** | Stores only weights | Stores all training data |\n",
    "| **Assumes** | Linear relationship | Local similarity |\n",
    "| **Interpretability** | High (can analyze weights) | Low (black box) |\n",
    "| **Handles Non-linearity** | Requires feature engineering | Naturally handles it |\n",
    "| **Outlier Sensitivity** | High | Medium (depends on K) |\n",
    "\n",
    "### Best Practices Checklist\n",
    "\n",
    "- \u2705 Always split data into train/validation/test\n",
    "- \u2705 Standardize features (fit on train, transform all)\n",
    "- \u2705 Analyze residuals to validate assumptions\n",
    "- \u2705 Check for multicollinearity (VIF scores)\n",
    "- \u2705 Compare with baseline models\n",
    "- \u2705 Use cross-validation for robust evaluation\n",
    "- \u2705 Interpret feature weights (if features are scaled)\n",
    "- \u2705 Watch for data leakage (never fit on validation/test)\n",
    "- \u2705 Consider regularization (Ridge/Lasso) for many features\n",
    "- \u2705 Evaluate on multiple metrics (RMSE, R\u00b2, MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Final Question**: You trained a Linear Regression model and achieved R\u00b2 = 0.85 on validation set. What does this mean?\n>\n> A. The model explains 85% of the variance in the target variable  \n> B. The model is 85% accurate  \n> C. 85% of predictions are correct  \n> D. The RMSE is 0.85\n>\n> <details>\n> <summary>Click to reveal answer</summary>\n> <b>Answer: A</b><br>\n> R\u00b2 = 0.85 means the model explains 85% of the variance in the target variable. The remaining 15% is due to irreducible error (noise) or unmodeled patterns. R\u00b2 is not the same as accuracy (which is for classification) or RMSE.\n</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've completed the Linear Regression Hands-On Lab! You now understand:\n",
    "\n",
    "- \u2705 The mathematics behind Linear Regression\n",
    "- \u2705 How to implement it from scratch\n",
    "- \u2705 The importance of feature scaling\n",
    "- \u2705 How to properly split and evaluate models\n",
    "- \u2705 Bias-variance tradeoff concepts\n",
    "- \u2705 Residual analysis and diagnostics\n",
    "- \u2705 When to use Linear Regression vs other algorithms\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore regularization (Ridge and Lasso regression)\n",
    "- Learn about polynomial regression for non-linear relationships\n",
    "- Study logistic regression for classification tasks\n",
    "- Practice with different datasets to build intuition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}